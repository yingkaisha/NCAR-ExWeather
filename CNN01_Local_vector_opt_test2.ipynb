{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35ec06d-99e2-426d-8350-28623a7ed5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:23:15.031706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from keras_unet_collection import utils as k_utils\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "import re\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('lead1', help='lead')\n",
    "# parser.add_argument('lead2', help='lead')\n",
    "# parser.add_argument('lead3', help='lead')\n",
    "# parser.add_argument('lead4', help='lead')\n",
    "# parser.add_argument('lead_name', help='lead')\n",
    "# parser.add_argument('model_tag', help='lead')\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "lead1 = 2 #int(args['lead1'])\n",
    "lead2 = 3 #int(args['lead2'])\n",
    "\n",
    "lead_name = 2 #int(args['lead_name'])\n",
    "model_tag = 'alt' #args['model_tag']\n",
    "\n",
    "filepath_vec = \"/glade/work/ksha/NCAR/\"\n",
    "\n",
    "if (lead1 < 9) or (lead1 > 18):\n",
    "    path_name1 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name1 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "if (lead2 < 9) or (lead2 > 18):\n",
    "    path_name2 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name2 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "    \n",
    "# if (lead3 < 9) or (lead3 > 18):\n",
    "#     path_name3 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "# else:\n",
    "#     path_name3 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "    \n",
    "# if (lead4 < 9) or (lead4 > 18):\n",
    "#     path_name4 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "# else:\n",
    "#     path_name4 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred, ref):\n",
    "    BS = np.mean((VALID_target.ravel() - Y_pred.ravel())**2)\n",
    "    metric = BS\n",
    "    return metric / ref\n",
    "\n",
    "def feature_extract(filenames, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max):\n",
    "    \n",
    "    lon_out = []\n",
    "    lat_out = []\n",
    "    elev_out = []\n",
    "    mon_out = []\n",
    "    \n",
    "    base_v3_s = datetime(2018, 7, 15)\n",
    "    base_v3_e = datetime(2020, 12, 2)\n",
    "\n",
    "    base_v4_s = datetime(2020, 12, 3)\n",
    "    base_v4_e = datetime(2022, 7, 15)\n",
    "\n",
    "    base_ref = datetime(2010, 1, 1)\n",
    "    \n",
    "    date_list_v3 = [base_v3_s + timedelta(days=day) for day in range(365+365+142)]\n",
    "    date_list_v4 = [base_v4_s + timedelta(days=day) for day in range(365+180-151)]\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        if 'v4' in name:\n",
    "            date_list = date_list_v4\n",
    "        else:\n",
    "            date_list = date_list_v3\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "        day = date_list[day]\n",
    "        month = day.month\n",
    "        \n",
    "        month_norm = (month - 1)/(12-1)\n",
    "        \n",
    "        lon = lon_80km[indx, indy]\n",
    "        lat = lat_80km[indx, indy]\n",
    "\n",
    "        lon = (lon - lon_minmax[0])/(lon_minmax[1] - lon_minmax[0])\n",
    "        lat = (lat - lat_minmax[0])/(lat_minmax[1] - lat_minmax[0])\n",
    "\n",
    "        elev = elev_80km[indx, indy]\n",
    "        elev = elev / elev_max\n",
    "        \n",
    "        lon_out.append(lon)\n",
    "        lat_out.append(lat)\n",
    "        elev_out.append(elev)\n",
    "        mon_out.append(month_norm)\n",
    "        \n",
    "    return np.array(lon_out), np.array(lat_out), np.array(elev_out), np.array(mon_out)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    \n",
    "    IN_vec = keras.Input((256,))    \n",
    "    IN_elev = keras.Input((3,))\n",
    "    IN = keras.layers.Concatenate()([IN_vec, IN_elev])\n",
    "    \n",
    "    X = IN\n",
    "    #\n",
    "    X = keras.layers.Dense(1024, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(512, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(128, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    OUT = X\n",
    "    OUT = keras.layers.Dense(1, activation='sigmoid', bias_initializer=keras.initializers.Constant(-10))(OUT)\n",
    "\n",
    "    model = keras.models.Model(inputs=[IN_vec, IN_elev], outputs=OUT)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f933e6-fcb7-4e02-9bb6-c3d33b4ff170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]\n",
    "    elev_3km = h5io['elev_3km'][...]\n",
    "    land_mask_80km = h5io['land_mask_80km'][...]\n",
    "    \n",
    "grid_shape = land_mask_80km.shape\n",
    "\n",
    "elev_80km = du.interp2d_wraper(lon_3km, lat_3km, elev_3km, lon_80km, lat_80km, method='linear')\n",
    "\n",
    "elev_80km[np.isnan(elev_80km)] = 0\n",
    "elev_80km[elev_80km<0] = 0\n",
    "elev_max = np.max(elev_80km)\n",
    "\n",
    "lon_80km_mask = lon_80km[land_mask_80km]\n",
    "lat_80km_mask = lat_80km[land_mask_80km]\n",
    "\n",
    "lon_minmax = [np.min(lon_80km_mask), np.max(lon_80km_mask)]\n",
    "lat_minmax = [np.min(lat_80km_mask), np.max(lat_80km_mask)]\n",
    "\n",
    "filename_train_lead1 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_train_lead2 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name2, lead2)))\n",
    "# filename_train_lead3 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name3, lead3)))\n",
    "# filename_train_lead4 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name4, lead4)))\n",
    "\n",
    "IND_TRAIN_lead = np.load('/glade/work/ksha/NCAR/IND_TRAIN_lead_full.npy', allow_pickle=True)[()]\n",
    "TRAIN_ind1 = IND_TRAIN_lead['lead{}'.format(lead1)]\n",
    "TRAIN_ind2 = IND_TRAIN_lead['lead{}'.format(lead2)]\n",
    "# TRAIN_ind3 = IND_TRAIN_lead['lead{}'.format(lead3)]\n",
    "# TRAIN_ind4 = IND_TRAIN_lead['lead{}'.format(lead4)]\n",
    "\n",
    "data_lead1_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "data_lead2_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "# data_lead3_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# data_lead3_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# data_lead3_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "# data_lead4_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "# data_lead4_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "# data_lead4_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "TRAIN_lead1 = np.concatenate((data_lead1_p0['y_vector'], data_lead1_p1['y_vector'], data_lead1_p2['y_vector']), axis=0)\n",
    "TRAIN_lead2 = np.concatenate((data_lead2_p0['y_vector'], data_lead2_p1['y_vector'], data_lead2_p2['y_vector']), axis=0)\n",
    "# TRAIN_lead3 = np.concatenate((data_lead3_p0['y_vector'], data_lead3_p1['y_vector'], data_lead3_p2['y_vector']), axis=0)\n",
    "# TRAIN_lead4 = np.concatenate((data_lead4_p0['y_vector'], data_lead4_p1['y_vector'], data_lead4_p2['y_vector']), axis=0)\n",
    "\n",
    "TRAIN_lead1_y = np.concatenate((data_lead1_p0['y_true'], data_lead1_p1['y_true'], data_lead1_p2['y_true']), axis=0)\n",
    "TRAIN_lead2_y = np.concatenate((data_lead2_p0['y_true'], data_lead2_p1['y_true'], data_lead2_p2['y_true']), axis=0)\n",
    "# TRAIN_lead3_y = np.concatenate((data_lead3_p0['y_true'], data_lead3_p1['y_true'], data_lead3_p2['y_true']), axis=0)\n",
    "# TRAIN_lead4_y = np.concatenate((data_lead4_p0['y_true'], data_lead4_p1['y_true'], data_lead4_p2['y_true']), axis=0)\n",
    "\n",
    "L = len(TRAIN_ind1)\n",
    "\n",
    "filename_train1_pick = []\n",
    "filename_train2_pick = []\n",
    "# filename_train3_pick = []\n",
    "# filename_train4_pick = []\n",
    "\n",
    "TRAIN_X = np.empty((L, 256))\n",
    "TRAIN_Y = np.empty(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(TRAIN_ind1[i])\n",
    "    ind_lead2 = int(TRAIN_ind2[i])\n",
    "    # ind_lead3 = int(TRAIN_ind3[i])\n",
    "    # ind_lead4 = int(TRAIN_ind4[i])\n",
    "    \n",
    "    filename_train1_pick.append(filename_train_lead1[ind_lead1])\n",
    "    filename_train2_pick.append(filename_train_lead2[ind_lead2])\n",
    "    # filename_train3_pick.append(filename_train_lead3[ind_lead3])\n",
    "    # filename_train4_pick.append(filename_train_lead4[ind_lead4])\n",
    "    \n",
    "    TRAIN_X[i, 0:128]   = TRAIN_lead1[ind_lead1, :]\n",
    "    TRAIN_X[i, 128:256] = TRAIN_lead2[ind_lead2, :]\n",
    "    # TRAIN_X[i, 256:384] = TRAIN_lead3[ind_lead3, :]\n",
    "    # TRAIN_X[i, 384:512] = TRAIN_lead4[ind_lead4, :]\n",
    "    \n",
    "    TRAIN_Y[i] = TRAIN_lead1_y[ind_lead1]\n",
    "    \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_train1_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "\n",
    "TRAIN_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "TRAIN_merge = TRAIN_stn\n",
    "\n",
    "TRAIN_256_pos = TRAIN_X[TRAIN_Y==1, :]\n",
    "TRAIN_256_neg = TRAIN_X[TRAIN_Y==0, :]\n",
    "\n",
    "TRAIN_stn_pos = TRAIN_merge[TRAIN_Y==1]\n",
    "TRAIN_stn_neg = TRAIN_merge[TRAIN_Y==0]\n",
    "\n",
    "filename_valid_lead1 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_valid_lead2 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name2, lead2)))\n",
    "# filename_valid_lead3 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name3, lead3)))\n",
    "# filename_valid_lead4 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name4, lead4)))\n",
    "\n",
    "valid_lead1 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "valid_lead2 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "# valid_lead3 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# valid_lead4 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "VALID_lead1 = valid_lead1['y_vector']\n",
    "VALID_lead2 = valid_lead2['y_vector']\n",
    "# VALID_lead3 = valid_lead3['y_vector']\n",
    "# VALID_lead4 = valid_lead4['y_vector']\n",
    "\n",
    "VALID_lead1_y = valid_lead1['y_true']\n",
    "VALID_lead2_y = valid_lead2['y_true']\n",
    "# VALID_lead3_y = valid_lead3['y_true']\n",
    "# VALID_lead4_y = valid_lead4['y_true']\n",
    "\n",
    "IND_VALID_lead = np.load('/glade/work/ksha/NCAR/IND_VALID_lead_full.npy', allow_pickle=True)[()]\n",
    "\n",
    "VALID_ind1 = IND_VALID_lead['lead{}'.format(lead1)]\n",
    "VALID_ind2 = IND_VALID_lead['lead{}'.format(lead2)]\n",
    "# VALID_ind3 = IND_VALID_lead['lead{}'.format(lead3)]\n",
    "# VALID_ind4 = IND_VALID_lead['lead{}'.format(lead4)]\n",
    "\n",
    "L = len(VALID_ind1)\n",
    "\n",
    "filename_valid1_pick = []\n",
    "filename_valid2_pick = []\n",
    "# filename_valid3_pick = []\n",
    "# filename_valid4_pick = []\n",
    "\n",
    "VALID_X = np.empty((L, 256))\n",
    "VALID_Y = np.zeros(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(VALID_ind1[i])\n",
    "    ind_lead2 = int(VALID_ind2[i])\n",
    "    # ind_lead3 = int(VALID_ind3[i])\n",
    "    # ind_lead4 = int(VALID_ind4[i])\n",
    "    \n",
    "    filename_valid1_pick.append(filename_valid_lead1[ind_lead1])\n",
    "    filename_valid2_pick.append(filename_valid_lead2[ind_lead2])\n",
    "    # filename_valid3_pick.append(filename_valid_lead3[ind_lead3])\n",
    "    # filename_valid4_pick.append(filename_valid_lead4[ind_lead4])\n",
    "    \n",
    "    VALID_X[i, 0:128]   = VALID_lead1[ind_lead1, :]\n",
    "    VALID_X[i, 128:256] = VALID_lead2[ind_lead2, :]\n",
    "    # VALID_X[i, 256:384] = VALID_lead3[ind_lead3, :]\n",
    "    # VALID_X[i, 384:512] = VALID_lead4[ind_lead4, :]\n",
    "    \n",
    "    if 'pos' in filename_valid_lead1[ind_lead1]:\n",
    "        if VALID_lead1_y[ind_lead1] == 1.0:\n",
    "            VALID_Y[i] = 1.0\n",
    "        else:\n",
    "            egwrshat\n",
    "        \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_valid1_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "        \n",
    "VALID_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "VALID_merge = VALID_stn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f1cceb-d21e-402f-995b-16ad8f3b8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record: 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:24:10.331737: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-23 16:24:10.333205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-23 16:24:10.380832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-01-23 16:24:10.380877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-23 16:24:10.385151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-23 16:24:10.385211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-23 16:24:10.388938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-23 16:24:10.390218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-23 16:24:10.394294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-23 16:24:10.396118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-23 16:24:10.403543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-23 16:24:10.404167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-23 16:24:10.404645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 16:24:10.404849: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-23 16:24:10.405229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-01-23 16:24:10.405251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-23 16:24:10.405268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-23 16:24:10.405278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-23 16:24:10.405288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-23 16:24:10.405297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-23 16:24:10.405306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-23 16:24:10.405315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-23 16:24:10.405325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-23 16:24:10.405830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-23 16:24:10.405877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-23 16:24:10.990554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-23 16:24:10.990596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-01-23 16:24:10.990610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-01-23 16:24:10.991638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:24:11.911859: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-23 16:24:11.916697: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2023-01-23 16:24:12.043116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.1 to 0.9997231544259452\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:24:18.141629: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 7.6265270709991455 seconds ---\n",
      "Validation loss 0.9998057967334414 NOT improved\n",
      "Validation loss 0.9998410423733967 NOT improved\n",
      "Validation loss 0.9998723195197171 NOT improved\n",
      "Validation loss 0.9998880962285506 NOT improved\n",
      "Validation loss 0.9998992563603664 NOT improved\n",
      "Validation loss 0.9998958737293233 NOT improved\n",
      "Validation loss 0.9998997590222193 NOT improved\n",
      "Validation loss 0.9999027474971393 NOT improved\n",
      "Validation loss 0.999891314262639 NOT improved\n",
      "Validation loss 0.9998861750373692 NOT improved\n",
      "Validation loss 0.9998844976942055 NOT improved\n",
      "Validation loss 0.9998866704412893 NOT improved\n",
      "Validation loss 0.9998523585154201 NOT improved\n",
      "Validation loss 0.9998445757433482 NOT improved\n",
      "Validation loss 0.9998275245437913 NOT improved\n",
      "Validation loss 0.9997925028160044 NOT improved\n",
      "Validation loss 0.9997462561029669 NOT improved\n",
      "Validation loss 0.9997301447585021 NOT improved\n",
      "Validation loss improved from 0.9997231544259452 to 0.9996986618584291\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.586511135101318 seconds ---\n",
      "Validation loss improved from 0.9996986618584291 to 0.9993181874309515\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.601675271987915 seconds ---\n",
      "Validation loss 0.9994755240788069 NOT improved\n",
      "Validation loss improved from 0.9993181874309515 to 0.9989872293425096\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.312701225280762 seconds ---\n",
      "Validation loss improved from 0.9989872293425096 to 0.9984748504843572\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.6426708698272705 seconds ---\n",
      "Validation loss improved from 0.9984748504843572 to 0.9969865667199249\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.325136423110962 seconds ---\n",
      "Validation loss 0.9986023621616344 NOT improved\n",
      "Validation loss improved from 0.9969865667199249 to 0.993863222036067\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.613269805908203 seconds ---\n",
      "Validation loss 0.9943733896997181 NOT improved\n",
      "Validation loss 0.996895341443035 NOT improved\n",
      "Validation loss 0.9951199509266914 NOT improved\n",
      "Validation loss improved from 0.993863222036067 to 0.9887804034070912\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.685156583786011 seconds ---\n",
      "Validation loss 0.9966678269477275 NOT improved\n",
      "Validation loss 0.9932511680814962 NOT improved\n",
      "Validation loss 0.9912698664926165 NOT improved\n",
      "Validation loss improved from 0.9887804034070912 to 0.9357278157961024\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.5352113246917725 seconds ---\n",
      "Validation loss improved from 0.9357278157961024 to 0.9332434587892084\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.290551424026489 seconds ---\n",
      "Validation loss 1.0734743250651861 NOT improved\n",
      "Early stopping\n",
      "Training round 1\n",
      "Validation loss 0.9997769175771262 NOT improved\n",
      "Validation loss 0.9997865107402919 NOT improved\n",
      "Validation loss 0.9998294914225455 NOT improved\n",
      "Validation loss 0.9998494913733166 NOT improved\n",
      "Validation loss 0.9998686411262024 NOT improved\n",
      "Validation loss 0.9998739519012567 NOT improved\n",
      "Validation loss 0.9998800342888007 NOT improved\n",
      "Validation loss 0.9998845001151793 NOT improved\n",
      "Validation loss 0.9998775673931061 NOT improved\n",
      "Validation loss 0.999884733906659 NOT improved\n",
      "Validation loss 0.9998684531278161 NOT improved\n",
      "Validation loss 0.9998799264805831 NOT improved\n",
      "Validation loss 0.9998157378243808 NOT improved\n",
      "Validation loss 0.9998507169933553 NOT improved\n",
      "Validation loss 0.9997981043565597 NOT improved\n",
      "Validation loss 0.9997535284654934 NOT improved\n",
      "Validation loss 0.9997977241450996 NOT improved\n",
      "Validation loss 0.9995356438931768 NOT improved\n",
      "Validation loss 0.9996831286419656 NOT improved\n",
      "Validation loss 0.999671184339516 NOT improved\n",
      "Validation loss 0.9995210072639223 NOT improved\n",
      "Validation loss 0.9995816286976499 NOT improved\n",
      "Validation loss 0.9990038544071571 NOT improved\n",
      "Validation loss 0.9982498273131863 NOT improved\n",
      "Validation loss 0.9987864642002452 NOT improved\n",
      "Validation loss 0.9965615790744703 NOT improved\n",
      "Validation loss 0.9956849435910268 NOT improved\n",
      "Validation loss 0.9928236595494134 NOT improved\n",
      "Validation loss 0.9980233782773649 NOT improved\n",
      "Validation loss 0.9919653066219976 NOT improved\n",
      "Validation loss 0.9897401653050729 NOT improved\n",
      "Validation loss 0.9833100671676929 NOT improved\n",
      "Validation loss 0.9851481302469676 NOT improved\n",
      "Validation loss 0.9654392200658279 NOT improved\n",
      "Validation loss improved from 0.9332434587892084 to 0.9188148854715122\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.616058111190796 seconds ---\n",
      "Validation loss 0.9477969476553114 NOT improved\n",
      "Validation loss improved from 0.9188148854715122 to 0.8336368994618724\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.337433576583862 seconds ---\n",
      "Validation loss 0.9871939174346857 NOT improved\n",
      "Validation loss 0.9707169488827284 NOT improved\n",
      "Validation loss 0.9113428624575873 NOT improved\n",
      "Validation loss 0.9335822279152083 NOT improved\n",
      "Validation loss 0.8503147526192861 NOT improved\n",
      "Validation loss 0.8680919687613395 NOT improved\n",
      "Validation loss 0.8497146112821735 NOT improved\n",
      "Validation loss 0.9838096869645102 NOT improved\n",
      "Validation loss 0.8654455326709046 NOT improved\n",
      "Validation loss 0.987687010631409 NOT improved\n",
      "Validation loss 0.9921690905486493 NOT improved\n",
      "Validation loss 0.8846090352454015 NOT improved\n",
      "Validation loss 0.9817419194877656 NOT improved\n",
      "Validation loss 2.18998573033519 NOT improved\n",
      "Early stopping\n",
      "Training round 2\n",
      "Validation loss 0.9997735064185086 NOT improved\n",
      "Validation loss 0.999816639541585 NOT improved\n",
      "Validation loss 0.9998300783742974 NOT improved\n",
      "Validation loss 0.9998443308407936 NOT improved\n",
      "Validation loss 0.9998601436818554 NOT improved\n",
      "Validation loss 0.999867440671812 NOT improved\n",
      "Validation loss 0.9998498247958769 NOT improved\n",
      "Validation loss 0.9998462149093856 NOT improved\n",
      "Validation loss 0.9998437136167092 NOT improved\n",
      "Validation loss 0.999832692285042 NOT improved\n",
      "Validation loss 0.9998216289762373 NOT improved\n",
      "Validation loss 0.9998192865573522 NOT improved\n",
      "Validation loss 0.9997703338356951 NOT improved\n",
      "Validation loss 0.9997732699570365 NOT improved\n",
      "Validation loss 0.9997274997902703 NOT improved\n",
      "Validation loss 0.9996711299445843 NOT improved\n",
      "Validation loss 0.9996588471112969 NOT improved\n",
      "Validation loss 0.9995257182642567 NOT improved\n",
      "Validation loss 0.9995579558317251 NOT improved\n",
      "Validation loss 0.9995031014434784 NOT improved\n",
      "Validation loss 0.9993574531231096 NOT improved\n",
      "Validation loss 0.9989367192147115 NOT improved\n",
      "Validation loss 0.9986669700844509 NOT improved\n",
      "Validation loss 0.9985481090151535 NOT improved\n",
      "Validation loss 0.9975592715309797 NOT improved\n",
      "Validation loss 0.9964406386528002 NOT improved\n",
      "Validation loss 0.9977818592006269 NOT improved\n",
      "Validation loss 0.9972500052876829 NOT improved\n",
      "Validation loss 0.9857114569083659 NOT improved\n",
      "Validation loss 0.9942775944725858 NOT improved\n",
      "Validation loss 0.9926249422315522 NOT improved\n",
      "Validation loss 0.984905364892415 NOT improved\n",
      "Validation loss 0.9784756357912664 NOT improved\n",
      "Validation loss 0.9637608018231032 NOT improved\n",
      "Validation loss 0.9725308656616215 NOT improved\n",
      "Validation loss 0.959432269940006 NOT improved\n",
      "Validation loss 0.859882780348126 NOT improved\n",
      "Validation loss 0.9698400876746719 NOT improved\n",
      "Validation loss 0.9249917288572934 NOT improved\n",
      "Validation loss 0.9813920132958266 NOT improved\n",
      "Validation loss 0.8458393422333575 NOT improved\n",
      "Validation loss 0.9411212767410922 NOT improved\n",
      "Validation loss 0.8523770324644572 NOT improved\n",
      "Validation loss 0.9520482378163766 NOT improved\n",
      "Validation loss 0.9675081772433004 NOT improved\n",
      "Validation loss 0.8977206894094358 NOT improved\n",
      "Validation loss 0.910338067289459 NOT improved\n",
      "Validation loss 0.8457700660639035 NOT improved\n",
      "Validation loss 0.9304640205575118 NOT improved\n",
      "Validation loss 0.8845229567490478 NOT improved\n",
      "Validation loss 0.9760869454650067 NOT improved\n",
      "Validation loss 0.9675134041008117 NOT improved\n",
      "Validation loss 1.7733755005154022 NOT improved\n",
      "Early stopping\n",
      "Training round 3\n",
      "Validation loss 0.9995971644722125 NOT improved\n",
      "Validation loss 0.9997648024407964 NOT improved\n",
      "Validation loss 0.9998398693749484 NOT improved\n",
      "Validation loss 0.9998732379691012 NOT improved\n",
      "Validation loss 0.9998859729258454 NOT improved\n",
      "Validation loss 0.9998993361654654 NOT improved\n",
      "Validation loss 0.9998987607197154 NOT improved\n",
      "Validation loss 0.9998990027523494 NOT improved\n",
      "Validation loss 0.9998980540131671 NOT improved\n",
      "Validation loss 0.9998905181788426 NOT improved\n",
      "Validation loss 0.9998942098543971 NOT improved\n",
      "Validation loss 0.9998672107166974 NOT improved\n",
      "Validation loss 0.9998650223153621 NOT improved\n",
      "Validation loss 0.9998496447321074 NOT improved\n",
      "Validation loss 0.9998212765940471 NOT improved\n",
      "Validation loss 0.9997104326598744 NOT improved\n",
      "Validation loss 0.9997841571314702 NOT improved\n",
      "Validation loss 0.9997400603033513 NOT improved\n",
      "Validation loss 0.9996964057202748 NOT improved\n",
      "Validation loss 0.9994693326891713 NOT improved\n",
      "Validation loss 0.9995806005104211 NOT improved\n",
      "Validation loss 0.9989232696257485 NOT improved\n",
      "Validation loss 0.998662459109702 NOT improved\n",
      "Validation loss 0.9984489465493659 NOT improved\n",
      "Validation loss 0.9975815136925217 NOT improved\n",
      "Validation loss 0.9990807246869652 NOT improved\n",
      "Validation loss 0.9968781623419253 NOT improved\n",
      "Validation loss 0.9812417224861546 NOT improved\n",
      "Validation loss 0.9975609992099753 NOT improved\n",
      "Validation loss 0.9943632290862697 NOT improved\n",
      "Validation loss 0.9924750473165596 NOT improved\n",
      "Validation loss 0.9879967070540048 NOT improved\n",
      "Validation loss 0.9893854779898748 NOT improved\n",
      "Validation loss 0.9826183780977126 NOT improved\n",
      "Validation loss 0.9565602508758746 NOT improved\n",
      "Validation loss 0.9789223110147368 NOT improved\n",
      "Validation loss 0.9813888633734605 NOT improved\n",
      "Validation loss 0.9291677851861234 NOT improved\n",
      "Validation loss 0.9198141347901607 NOT improved\n",
      "Validation loss 0.8532394020281971 NOT improved\n",
      "Validation loss 0.8907800289761695 NOT improved\n",
      "Validation loss 0.8908138656157383 NOT improved\n",
      "Validation loss 0.9549204569744683 NOT improved\n",
      "Validation loss 0.8627340385725809 NOT improved\n",
      "Validation loss 0.9460548365388467 NOT improved\n",
      "Validation loss 0.9006306421710584 NOT improved\n",
      "Validation loss 0.9235898630829494 NOT improved\n",
      "Validation loss 1.186511470343164 NOT improved\n",
      "Early stopping\n",
      "Training round 4\n",
      "Validation loss 0.9997191882287362 NOT improved\n",
      "Validation loss 0.9998138740419875 NOT improved\n",
      "Validation loss 0.999852229869619 NOT improved\n",
      "Validation loss 0.9998679271510957 NOT improved\n",
      "Validation loss 0.9998782478831552 NOT improved\n",
      "Validation loss 0.9998786704028885 NOT improved\n",
      "Validation loss 0.9998825650522274 NOT improved\n",
      "Validation loss 0.9998861796101091 NOT improved\n",
      "Validation loss 0.9998782440054704 NOT improved\n",
      "Validation loss 0.9998727015820157 NOT improved\n",
      "Validation loss 0.9998490940228844 NOT improved\n",
      "Validation loss 0.9998646698357705 NOT improved\n",
      "Validation loss 0.9998473546999741 NOT improved\n",
      "Validation loss 0.9998552050802159 NOT improved\n",
      "Validation loss 0.9997847012190597 NOT improved\n",
      "Validation loss 0.9996124521948239 NOT improved\n",
      "Validation loss 0.9996920989388057 NOT improved\n",
      "Validation loss 0.9995782033920891 NOT improved\n",
      "Validation loss 0.99945246848513 NOT improved\n",
      "Validation loss 0.9990791515810551 NOT improved\n",
      "Validation loss 0.9989503255269985 NOT improved\n",
      "Validation loss 0.9993136399036396 NOT improved\n",
      "Validation loss 0.999106755194985 NOT improved\n",
      "Validation loss 0.9985390909682661 NOT improved\n",
      "Validation loss 0.9969730782877333 NOT improved\n",
      "Validation loss 0.9935248793805185 NOT improved\n",
      "Validation loss 0.9978954454905502 NOT improved\n",
      "Validation loss 0.9878196953995071 NOT improved\n",
      "Validation loss 0.9967834645539956 NOT improved\n",
      "Validation loss 0.9888913678910535 NOT improved\n",
      "Validation loss 0.9820332971066323 NOT improved\n",
      "Validation loss 0.9641565987741588 NOT improved\n",
      "Validation loss 0.9643152904314853 NOT improved\n",
      "Validation loss 0.9783051155209257 NOT improved\n",
      "Validation loss 0.9843219986593603 NOT improved\n",
      "Validation loss 0.9355197828832745 NOT improved\n",
      "Validation loss 0.9314905980881485 NOT improved\n",
      "Validation loss 0.9605073185643399 NOT improved\n",
      "Validation loss 0.9752288820528006 NOT improved\n",
      "Validation loss 0.9873421359425718 NOT improved\n",
      "Validation loss 0.9506481655237432 NOT improved\n",
      "Validation loss 0.9488676177101333 NOT improved\n",
      "Validation loss 0.9058116995647589 NOT improved\n",
      "Validation loss 0.9521407295677584 NOT improved\n",
      "Validation loss 0.9444840291746164 NOT improved\n",
      "Validation loss 0.8880675526819812 NOT improved\n",
      "Validation loss 0.9783751603614487 NOT improved\n",
      "Validation loss 0.9744371763943934 NOT improved\n",
      "Validation loss 0.9572728840234557 NOT improved\n",
      "Validation loss 1.7772181298887595 NOT improved\n",
      "Early stopping\n",
      "Training round 5\n",
      "Validation loss 0.9995438792741493 NOT improved\n",
      "Validation loss 0.999709346760348 NOT improved\n",
      "Validation loss 0.9998037434986512 NOT improved\n",
      "Validation loss 0.9998545531546729 NOT improved\n",
      "Validation loss 0.9998763918694488 NOT improved\n",
      "Validation loss 0.9998878414002954 NOT improved\n",
      "Validation loss 0.9998997256652551 NOT improved\n",
      "Validation loss 0.9999072114098769 NOT improved\n",
      "Validation loss 0.9999030776351923 NOT improved\n",
      "Validation loss 0.9998931225402534 NOT improved\n",
      "Validation loss 0.9998981703158476 NOT improved\n",
      "Validation loss 0.9998870476041002 NOT improved\n",
      "Validation loss 0.9998604563353201 NOT improved\n",
      "Validation loss 0.9998471139466518 NOT improved\n",
      "Validation loss 0.9998252297444297 NOT improved\n",
      "Validation loss 0.9997817856536475 NOT improved\n",
      "Validation loss 0.9997360197723147 NOT improved\n",
      "Validation loss 0.9997853087523972 NOT improved\n",
      "Validation loss 0.9997246418106017 NOT improved\n",
      "Validation loss 0.9995427596247118 NOT improved\n",
      "Validation loss 0.9995573797351809 NOT improved\n",
      "Validation loss 0.9992782740337087 NOT improved\n",
      "Validation loss 0.9988015863423518 NOT improved\n",
      "Validation loss 0.9984639409837451 NOT improved\n",
      "Validation loss 0.9984289047543805 NOT improved\n",
      "Validation loss 0.9977921529797852 NOT improved\n",
      "Validation loss 0.9953336229689307 NOT improved\n",
      "Validation loss 0.998361079638871 NOT improved\n",
      "Validation loss 0.9767966050042811 NOT improved\n",
      "Validation loss 0.9904021454929631 NOT improved\n",
      "Validation loss 0.9875213819089297 NOT improved\n",
      "Validation loss 0.9944580028738643 NOT improved\n",
      "Validation loss 0.9769679896095668 NOT improved\n",
      "Validation loss 0.9965307084061682 NOT improved\n",
      "Validation loss 0.9857623386550983 NOT improved\n",
      "Validation loss 0.9118785832229233 NOT improved\n",
      "Validation loss 0.9915325194285736 NOT improved\n",
      "Validation loss 0.8542721014184017 NOT improved\n",
      "Validation loss 0.9635651817741446 NOT improved\n",
      "Validation loss 0.8478643361083239 NOT improved\n",
      "Validation loss 0.9365643797346772 NOT improved\n",
      "Validation loss 0.8903711070980665 NOT improved\n",
      "Validation loss 0.8477592931938385 NOT improved\n",
      "Validation loss 0.8588428607907829 NOT improved\n",
      "Validation loss 0.9269448490020858 NOT improved\n",
      "Validation loss 0.8653105765183644 NOT improved\n",
      "Validation loss 0.8882843587583814 NOT improved\n",
      "Validation loss 0.9272793693264352 NOT improved\n",
      "Validation loss 0.876980754295304 NOT improved\n",
      "Validation loss 1.0423979874591098 NOT improved\n",
      "Early stopping\n",
      "Training round 6\n",
      "Validation loss 0.9994236476954602 NOT improved\n",
      "Validation loss 0.9996131556879305 NOT improved\n",
      "Validation loss 0.9997402584011243 NOT improved\n",
      "Validation loss 0.9998121552773586 NOT improved\n",
      "Validation loss 0.9998454610251352 NOT improved\n",
      "Validation loss 0.999868394998671 NOT improved\n",
      "Validation loss 0.9998875156719775 NOT improved\n",
      "Validation loss 0.9998918622401403 NOT improved\n",
      "Validation loss 0.9998854219429877 NOT improved\n",
      "Validation loss 0.9998813724451465 NOT improved\n",
      "Validation loss 0.9998749725714566 NOT improved\n",
      "Validation loss 0.9998564895088173 NOT improved\n",
      "Validation loss 0.999861262408937 NOT improved\n",
      "Validation loss 0.9998545985711683 NOT improved\n",
      "Validation loss 0.9998007174363784 NOT improved\n",
      "Validation loss 0.9997749248890038 NOT improved\n",
      "Validation loss 0.9997404666716591 NOT improved\n",
      "Validation loss 0.9997091134920782 NOT improved\n",
      "Validation loss 0.9994819947058647 NOT improved\n",
      "Validation loss 0.9991892154784877 NOT improved\n",
      "Validation loss 0.9994702790986407 NOT improved\n",
      "Validation loss 0.9991980117748308 NOT improved\n",
      "Validation loss 0.9980998216990126 NOT improved\n",
      "Validation loss 0.9990050799518745 NOT improved\n",
      "Validation loss 0.9977964716653697 NOT improved\n",
      "Validation loss 0.997239598407478 NOT improved\n",
      "Validation loss 0.9984293675039664 NOT improved\n",
      "Validation loss 0.987990622030964 NOT improved\n",
      "Validation loss 0.9925769169734736 NOT improved\n",
      "Validation loss 0.9915431739878863 NOT improved\n",
      "Validation loss 0.9925389770952003 NOT improved\n",
      "Validation loss 0.9782901555541555 NOT improved\n",
      "Validation loss 0.988146042877529 NOT improved\n",
      "Validation loss 0.9661320707181769 NOT improved\n",
      "Validation loss 0.9181365671461702 NOT improved\n",
      "Validation loss 0.9539127065761768 NOT improved\n",
      "Validation loss 0.858840467688431 NOT improved\n",
      "Validation loss 0.9205463498604147 NOT improved\n",
      "Validation loss 0.9116557927922972 NOT improved\n",
      "Validation loss 0.9314215560983229 NOT improved\n",
      "Validation loss 0.9025992591441401 NOT improved\n",
      "Validation loss 1.1879912323451407 NOT improved\n",
      "Early stopping\n",
      "Training round 7\n",
      "Validation loss 0.9997333333537203 NOT improved\n",
      "Validation loss 0.9997560624505449 NOT improved\n",
      "Validation loss 0.9998233852943047 NOT improved\n",
      "Validation loss 0.9998546619328199 NOT improved\n",
      "Validation loss 0.9998726043477641 NOT improved\n",
      "Validation loss 0.9998780469386881 NOT improved\n",
      "Validation loss 0.9998716588209967 NOT improved\n",
      "Validation loss 0.9998649926470818 NOT improved\n",
      "Validation loss 0.9998675882053848 NOT improved\n",
      "Validation loss 0.9998708086056869 NOT improved\n",
      "Validation loss 0.9998374643392015 NOT improved\n",
      "Validation loss 0.9998189791608587 NOT improved\n",
      "Validation loss 0.9998205787180173 NOT improved\n",
      "Validation loss 0.9997727054033271 NOT improved\n",
      "Validation loss 0.999777900748534 NOT improved\n",
      "Validation loss 0.9996595942572243 NOT improved\n",
      "Validation loss 0.9996860743032042 NOT improved\n",
      "Validation loss 0.9996057094194156 NOT improved\n",
      "Validation loss 0.99937744038292 NOT improved\n",
      "Validation loss 0.9988552544381849 NOT improved\n",
      "Validation loss 0.998375153181991 NOT improved\n",
      "Validation loss 0.9990144431723104 NOT improved\n",
      "Validation loss 0.997884954204832 NOT improved\n",
      "Validation loss 0.9940282488700576 NOT improved\n",
      "Validation loss 0.9986146137548535 NOT improved\n",
      "Validation loss 0.9964454812641388 NOT improved\n",
      "Validation loss 0.9863031632501442 NOT improved\n",
      "Validation loss 0.9910473119788115 NOT improved\n",
      "Validation loss 0.9831810740928489 NOT improved\n",
      "Validation loss 0.968022167248459 NOT improved\n",
      "Validation loss 0.9166250159139215 NOT improved\n",
      "Validation loss 0.9827180930087749 NOT improved\n",
      "Validation loss 0.94657175546403 NOT improved\n",
      "Validation loss 0.9753603144516868 NOT improved\n",
      "Validation loss 0.9875580341422254 NOT improved\n",
      "Validation loss improved from 0.8336368994618724 to 0.8280119062518958\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead2/assets\n",
      "--- 6.591400623321533 seconds ---\n",
      "Validation loss 0.9182504958093602 NOT improved\n",
      "Validation loss 0.9951357879424773 NOT improved\n",
      "Validation loss 0.9769297401594964 NOT improved\n",
      "Validation loss 0.8535598886131125 NOT improved\n",
      "Validation loss 0.9816747147197936 NOT improved\n",
      "Validation loss 0.8757367707539822 NOT improved\n",
      "Validation loss 0.8775216097175617 NOT improved\n",
      "Validation loss 0.9040362753463322 NOT improved\n",
      "Validation loss 0.8929251404881982 NOT improved\n",
      "Validation loss 0.9521023059942213 NOT improved\n",
      "Validation loss 2.650599697319223 NOT improved\n",
      "Early stopping\n",
      "Training round 8\n",
      "Validation loss 0.9995883821620395 NOT improved\n",
      "Validation loss 0.9997376988596876 NOT improved\n",
      "Validation loss 0.9998094333569526 NOT improved\n",
      "Validation loss 0.9998478083772933 NOT improved\n",
      "Validation loss 0.9998679355371983 NOT improved\n",
      "Validation loss 0.9998904744267624 NOT improved\n",
      "Validation loss 0.9999001113419486 NOT improved\n",
      "Validation loss 0.9998931922089866 NOT improved\n",
      "Validation loss 0.9998832804020463 NOT improved\n",
      "Validation loss 0.9999010848101577 NOT improved\n",
      "Validation loss 0.9998914685599115 NOT improved\n",
      "Validation loss 0.9998798706189312 NOT improved\n",
      "Validation loss 0.9998832475061844 NOT improved\n",
      "Validation loss 0.9998364771841777 NOT improved\n",
      "Validation loss 0.9998354205408708 NOT improved\n",
      "Validation loss 0.9997661683070485 NOT improved\n",
      "Validation loss 0.9997607589443833 NOT improved\n",
      "Validation loss 0.9996734027493153 NOT improved\n",
      "Validation loss 0.9994514621152668 NOT improved\n",
      "Validation loss 0.9996637337779313 NOT improved\n",
      "Validation loss 0.9989799526089566 NOT improved\n",
      "Validation loss 0.9987264701838822 NOT improved\n",
      "Validation loss 0.9993216026273586 NOT improved\n",
      "Validation loss 0.9979121521021893 NOT improved\n",
      "Validation loss 0.9984790714741643 NOT improved\n",
      "Validation loss 0.9989023022955777 NOT improved\n",
      "Validation loss 0.9970984692067558 NOT improved\n",
      "Validation loss 0.9956230101168344 NOT improved\n",
      "Validation loss 0.991721349891717 NOT improved\n",
      "Validation loss 0.9854234601859895 NOT improved\n",
      "Validation loss 0.9914463851943321 NOT improved\n",
      "Validation loss 0.992303642122136 NOT improved\n",
      "Validation loss 0.9825373899464841 NOT improved\n",
      "Validation loss 0.9692217912169683 NOT improved\n",
      "Validation loss 0.963582808701857 NOT improved\n",
      "Validation loss 0.9445582681625658 NOT improved\n",
      "Validation loss 0.9149974703599696 NOT improved\n",
      "Validation loss 0.9306580109610267 NOT improved\n",
      "Validation loss 0.9630546208921287 NOT improved\n",
      "Validation loss 0.967759428528111 NOT improved\n",
      "Validation loss 0.9172043160843969 NOT improved\n",
      "Validation loss 0.8669852824133086 NOT improved\n",
      "Validation loss 2.7708252042239034 NOT improved\n",
      "Early stopping\n",
      "Training round 9\n",
      "Validation loss 0.999715620379121 NOT improved\n",
      "Validation loss 0.999758312965296 NOT improved\n",
      "Validation loss 0.9998198746061898 NOT improved\n",
      "Validation loss 0.9998620917468821 NOT improved\n",
      "Validation loss 0.9998766924782854 NOT improved\n",
      "Validation loss 0.9998762134994187 NOT improved\n",
      "Validation loss 0.9998786395016466 NOT improved\n",
      "Validation loss 0.999890133305339 NOT improved\n",
      "Validation loss 0.9998585778597284 NOT improved\n",
      "Validation loss 0.9998715156047885 NOT improved\n",
      "Validation loss 0.9998371299854548 NOT improved\n",
      "Validation loss 0.9998243431466052 NOT improved\n",
      "Validation loss 0.9998494917481876 NOT improved\n",
      "Validation loss 0.999793239043081 NOT improved\n",
      "Validation loss 0.9997877903769825 NOT improved\n",
      "Validation loss 0.9997548826805138 NOT improved\n",
      "Validation loss 0.9996667805565854 NOT improved\n",
      "Validation loss 0.9996473262626031 NOT improved\n",
      "Validation loss 0.9996379244152312 NOT improved\n",
      "Validation loss 0.9994282832850461 NOT improved\n",
      "Validation loss 0.9994459419704285 NOT improved\n",
      "Validation loss 0.9987833249063931 NOT improved\n",
      "Validation loss 0.9985486891948211 NOT improved\n",
      "Validation loss 0.9985279715079586 NOT improved\n",
      "Validation loss 0.9979259926915768 NOT improved\n",
      "Validation loss 0.9985085852083054 NOT improved\n",
      "Validation loss 0.9973410837977814 NOT improved\n",
      "Validation loss 0.9817091406279506 NOT improved\n",
      "Validation loss 0.995765934757641 NOT improved\n",
      "Validation loss 0.9520435502295179 NOT improved\n",
      "Validation loss 0.9319386653184325 NOT improved\n",
      "Validation loss 0.9934037760511567 NOT improved\n",
      "Validation loss 0.9846161257511185 NOT improved\n",
      "Validation loss 0.9732030060385486 NOT improved\n",
      "Validation loss 0.9874471065748148 NOT improved\n",
      "Validation loss 0.9840261166139166 NOT improved\n",
      "Validation loss 0.9369344012007755 NOT improved\n",
      "Validation loss 0.9960685529665726 NOT improved\n",
      "Validation loss 0.9887729990364492 NOT improved\n",
      "Validation loss 0.9423511539636105 NOT improved\n",
      "Validation loss 0.8435435815146555 NOT improved\n",
      "Validation loss 0.886527870938625 NOT improved\n",
      "Validation loss 0.9149340121781891 NOT improved\n",
      "Validation loss 0.9760455821080177 NOT improved\n",
      "Validation loss 0.9285782895501665 NOT improved\n",
      "Validation loss 1.0290735765547758 NOT improved\n",
      "Early stopping\n",
      "Training round 10\n",
      "Validation loss 0.9995921870215342 NOT improved\n",
      "Validation loss 0.9997520105155219 NOT improved\n",
      "Validation loss 0.9998448094432838 NOT improved\n",
      "Validation loss 0.9998770166019464 NOT improved\n",
      "Validation loss 0.9998996307086727 NOT improved\n",
      "Validation loss 0.9999009750715886 NOT improved\n",
      "Validation loss 0.9999010166246883 NOT improved\n",
      "Validation loss 0.9999037980910709 NOT improved\n",
      "Validation loss 0.9998974048704012 NOT improved\n",
      "Validation loss 0.9998980443266503 NOT improved\n",
      "Validation loss 0.999889995959606 NOT improved\n",
      "Validation loss 0.999892972743981 NOT improved\n",
      "Validation loss 0.9998663332108346 NOT improved\n",
      "Validation loss 0.9998063672200148 NOT improved\n",
      "Validation loss 0.9997627310900625 NOT improved\n",
      "Validation loss 0.9997242800772163 NOT improved\n",
      "Validation loss 0.9997657633811019 NOT improved\n",
      "Validation loss 0.9996135410284462 NOT improved\n",
      "Validation loss 0.9994067109012653 NOT improved\n",
      "Validation loss 0.9993879530566514 NOT improved\n",
      "Validation loss 0.9990561717909583 NOT improved\n",
      "Validation loss 0.9991871117779497 NOT improved\n",
      "Validation loss 0.9986874460770346 NOT improved\n",
      "Validation loss 0.9984975653223687 NOT improved\n",
      "Validation loss 0.998610537898071 NOT improved\n",
      "Validation loss 0.9958721447545755 NOT improved\n",
      "Validation loss 0.9941757504971259 NOT improved\n",
      "Validation loss 0.9952953157734267 NOT improved\n",
      "Validation loss 0.9959933231676772 NOT improved\n",
      "Validation loss 0.9896011747277993 NOT improved\n",
      "Validation loss 0.9820562178121235 NOT improved\n",
      "Validation loss 0.9923007925477646 NOT improved\n",
      "Validation loss 0.9853371933997722 NOT improved\n",
      "Validation loss 0.9607795708444278 NOT improved\n",
      "Validation loss 0.9910463547778455 NOT improved\n",
      "Validation loss 0.9917110493717605 NOT improved\n",
      "Validation loss 0.9927056342291288 NOT improved\n",
      "Validation loss 0.987023674105089 NOT improved\n",
      "Validation loss 0.963092567249505 NOT improved\n",
      "Validation loss 0.9764741630099733 NOT improved\n",
      "Validation loss 0.9164380248743249 NOT improved\n",
      "Validation loss 0.860010407435214 NOT improved\n",
      "Validation loss 0.9313759837931542 NOT improved\n",
      "Validation loss 0.8570070749978823 NOT improved\n",
      "Validation loss 0.8396444655946159 NOT improved\n",
      "Validation loss 0.8626149057017539 NOT improved\n",
      "Validation loss 0.9349239497879798 NOT improved\n",
      "Validation loss 0.9374049617274861 NOT improved\n",
      "Validation loss 0.8842911256085094 NOT improved\n",
      "Validation loss 0.958185824575104 NOT improved\n",
      "Validation loss 0.9112003731276072 NOT improved\n",
      "Validation loss 0.9440248776972072 NOT improved\n",
      "Validation loss 0.8596436963882995 NOT improved\n",
      "Validation loss 1.0278653434356804 NOT improved\n",
      "Early stopping\n",
      "Training round 11\n",
      "Validation loss 0.9994928033425979 NOT improved\n",
      "Validation loss 0.9997164801642655 NOT improved\n",
      "Validation loss 0.9998132828080321 NOT improved\n",
      "Validation loss 0.9998557183094151 NOT improved\n",
      "Validation loss 0.9998759231765753 NOT improved\n",
      "Validation loss 0.99989192541855 NOT improved\n",
      "Validation loss 0.9998935282004462 NOT improved\n",
      "Validation loss 0.9998941734306042 NOT improved\n",
      "Validation loss 0.9998918300166894 NOT improved\n",
      "Validation loss 0.9998929481461931 NOT improved\n",
      "Validation loss 0.9998688517596429 NOT improved\n",
      "Validation loss 0.9998840504188391 NOT improved\n",
      "Validation loss 0.9998493761649354 NOT improved\n",
      "Validation loss 0.9998488184171493 NOT improved\n",
      "Validation loss 0.9998190325208848 NOT improved\n",
      "Validation loss 0.99985716470223 NOT improved\n",
      "Validation loss 0.9997759618115752 NOT improved\n",
      "Validation loss 0.9996331118944034 NOT improved\n",
      "Validation loss 0.9992411034375774 NOT improved\n",
      "Validation loss 0.999369420391644 NOT improved\n",
      "Validation loss 0.9994009474579476 NOT improved\n",
      "Validation loss 0.9991796884084463 NOT improved\n",
      "Validation loss 0.9988658542143681 NOT improved\n",
      "Validation loss 0.9984961855171552 NOT improved\n",
      "Validation loss 0.9977282158267484 NOT improved\n",
      "Validation loss 0.995046217919205 NOT improved\n",
      "Validation loss 0.9878647878944677 NOT improved\n",
      "Validation loss 0.9960689268389629 NOT improved\n",
      "Validation loss 0.9938414802483816 NOT improved\n",
      "Validation loss 0.9931313832353235 NOT improved\n",
      "Validation loss 0.9918625064049287 NOT improved\n",
      "Validation loss 0.9871797778186433 NOT improved\n",
      "Validation loss 0.973070431843243 NOT improved\n",
      "Validation loss 0.986422307904278 NOT improved\n",
      "Validation loss 0.9346642416103591 NOT improved\n",
      "Validation loss 0.9666600258717675 NOT improved\n",
      "Validation loss 0.8651823021223541 NOT improved\n",
      "Validation loss 0.8938975423616651 NOT improved\n",
      "Validation loss 0.9569870441021947 NOT improved\n",
      "Validation loss 0.9477337715482219 NOT improved\n",
      "Validation loss 0.869005970890615 NOT improved\n",
      "Validation loss 0.8980152539674019 NOT improved\n",
      "Validation loss 1.2307874382795394 NOT improved\n",
      "Early stopping\n",
      "Training round 12\n",
      "Validation loss 0.9996698221829255 NOT improved\n",
      "Validation loss 0.9997814804330225 NOT improved\n",
      "Validation loss 0.9998520286858431 NOT improved\n",
      "Validation loss 0.9998819587184749 NOT improved\n",
      "Validation loss 0.9998994406882885 NOT improved\n",
      "Validation loss 0.99990325678823 NOT improved\n",
      "Validation loss 0.9999059262112291 NOT improved\n",
      "Validation loss 0.9999065073912876 NOT improved\n",
      "Validation loss 0.9998982529578174 NOT improved\n",
      "Validation loss 0.9998868832649809 NOT improved\n",
      "Validation loss 0.9998663302995304 NOT improved\n",
      "Validation loss 0.9998674993481151 NOT improved\n",
      "Validation loss 0.9998690398753052 NOT improved\n",
      "Validation loss 0.9998359568374674 NOT improved\n",
      "Validation loss 0.9998402911054002 NOT improved\n",
      "Validation loss 0.9997993324631627 NOT improved\n",
      "Validation loss 0.9996359862617802 NOT improved\n",
      "Validation loss 0.9996313485729909 NOT improved\n",
      "Validation loss 0.9996133442540454 NOT improved\n",
      "Validation loss 0.9995714273687191 NOT improved\n",
      "Validation loss 0.9994535995378943 NOT improved\n",
      "Validation loss 0.9994832011742386 NOT improved\n",
      "Validation loss 0.9989429898608946 NOT improved\n",
      "Validation loss 0.9990047737472656 NOT improved\n",
      "Validation loss 0.9984234643573955 NOT improved\n",
      "Validation loss 0.9986588056956465 NOT improved\n",
      "Validation loss 0.9959330096819776 NOT improved\n",
      "Validation loss 0.9970643099616782 NOT improved\n",
      "Validation loss 0.9915931306455233 NOT improved\n",
      "Validation loss 0.9946477887425355 NOT improved\n",
      "Validation loss 0.9932425974510134 NOT improved\n",
      "Validation loss 0.9899515262141424 NOT improved\n",
      "Validation loss 0.9871222926685531 NOT improved\n",
      "Validation loss 0.9946130705961396 NOT improved\n",
      "Validation loss 0.9715295079556094 NOT improved\n",
      "Validation loss 0.9102041676539143 NOT improved\n",
      "Validation loss 0.9380581348854924 NOT improved\n",
      "Validation loss 0.8617424544230673 NOT improved\n",
      "Validation loss 0.9453699584655013 NOT improved\n",
      "Validation loss 0.9754175512251676 NOT improved\n",
      "Validation loss 0.9732138506802964 NOT improved\n",
      "Validation loss 0.884361105778713 NOT improved\n",
      "Validation loss 0.8681624785742709 NOT improved\n",
      "Validation loss 0.8804901257593898 NOT improved\n",
      "Validation loss 0.8755458262736545 NOT improved\n",
      "Validation loss 0.9179494589596872 NOT improved\n",
      "Validation loss 0.8927875260402385 NOT improved\n",
      "Validation loss 0.8712407885395159 NOT improved\n",
      "Validation loss 0.8682385810628688 NOT improved\n",
      "Validation loss 0.8875496571882227 NOT improved\n",
      "Validation loss 3.15063459936213 NOT improved\n",
      "Early stopping\n",
      "Training round 13\n",
      "Validation loss 0.9996463633676648 NOT improved\n",
      "Validation loss 0.9997634135935396 NOT improved\n",
      "Validation loss 0.9998297636188311 NOT improved\n",
      "Validation loss 0.9998545837343356 NOT improved\n",
      "Validation loss 0.9998676403462258 NOT improved\n",
      "Validation loss 0.999885621099197 NOT improved\n",
      "Validation loss 0.9998908501870948 NOT improved\n",
      "Validation loss 0.9998958334057648 NOT improved\n",
      "Validation loss 0.9998888430421046 NOT improved\n",
      "Validation loss 0.9998799740672142 NOT improved\n",
      "Validation loss 0.9998755799627073 NOT improved\n",
      "Validation loss 0.9998661533537356 NOT improved\n",
      "Validation loss 0.9998552195848096 NOT improved\n",
      "Validation loss 0.9998396364493488 NOT improved\n",
      "Validation loss 0.9998037681130196 NOT improved\n",
      "Validation loss 0.9997919471731412 NOT improved\n",
      "Validation loss 0.9996919269565983 NOT improved\n",
      "Validation loss 0.9997811292208023 NOT improved\n",
      "Validation loss 0.9996907484311542 NOT improved\n",
      "Validation loss 0.999534134239753 NOT improved\n",
      "Validation loss 0.9991645325646409 NOT improved\n",
      "Validation loss 0.9988922366980688 NOT improved\n",
      "Validation loss 0.998506093038432 NOT improved\n",
      "Validation loss 0.9989757997181073 NOT improved\n",
      "Validation loss 0.9974771088944687 NOT improved\n",
      "Validation loss 0.9982649279727628 NOT improved\n",
      "Validation loss 0.9974865571213433 NOT improved\n",
      "Validation loss 0.9946281418586789 NOT improved\n",
      "Validation loss 0.993668478170357 NOT improved\n",
      "Validation loss 0.992262008490121 NOT improved\n",
      "Validation loss 0.9856734447169676 NOT improved\n",
      "Validation loss 0.9689978005771764 NOT improved\n",
      "Validation loss 0.9858751587624033 NOT improved\n",
      "Validation loss 0.9936388248978206 NOT improved\n",
      "Validation loss 0.9866713354334447 NOT improved\n",
      "Validation loss 0.9638673665398534 NOT improved\n",
      "Validation loss 0.91123674263924 NOT improved\n",
      "Validation loss 0.9804795474350849 NOT improved\n",
      "Validation loss 0.9700843038806015 NOT improved\n",
      "Validation loss 0.9635181356232492 NOT improved\n",
      "Validation loss 0.8294213632334514 NOT improved\n",
      "Validation loss 0.956974446049327 NOT improved\n",
      "Validation loss 0.9928389498132187 NOT improved\n",
      "Validation loss 0.9903250351181324 NOT improved\n",
      "Validation loss 0.9828273846937735 NOT improved\n",
      "Validation loss 2.480165295887685 NOT improved\n",
      "Early stopping\n",
      "Training round 14\n",
      "Validation loss 0.9996596274103298 NOT improved\n",
      "Validation loss 0.9997625712796456 NOT improved\n",
      "Validation loss 0.9998133410689005 NOT improved\n",
      "Validation loss 0.9998509418460553 NOT improved\n",
      "Validation loss 0.999873686180584 NOT improved\n",
      "Validation loss 0.9998870637463135 NOT improved\n",
      "Validation loss 0.9998996576589323 NOT improved\n",
      "Validation loss 0.9998903492102252 NOT improved\n",
      "Validation loss 0.9999022026525769 NOT improved\n",
      "Validation loss 0.9998901733311293 NOT improved\n",
      "Validation loss 0.9999033059764013 NOT improved\n",
      "Validation loss 0.9998925634919263 NOT improved\n",
      "Validation loss 0.9998692986587424 NOT improved\n",
      "Validation loss 0.9998257198045075 NOT improved\n",
      "Validation loss 0.999844146886508 NOT improved\n",
      "Validation loss 0.9998347836497101 NOT improved\n",
      "Validation loss 0.999803820981605 NOT improved\n",
      "Validation loss 0.9997162117310271 NOT improved\n",
      "Validation loss 0.9996279060740062 NOT improved\n",
      "Validation loss 0.9994709238440467 NOT improved\n",
      "Validation loss 0.9989040202132569 NOT improved\n",
      "Validation loss 0.999144008469136 NOT improved\n",
      "Validation loss 0.9988652908965412 NOT improved\n",
      "Validation loss 0.9988118809381203 NOT improved\n",
      "Validation loss 0.9982937833628093 NOT improved\n",
      "Validation loss 0.9974667354689556 NOT improved\n",
      "Validation loss 0.9973829881494117 NOT improved\n",
      "Validation loss 0.9973486775124712 NOT improved\n",
      "Validation loss 0.9947796651748693 NOT improved\n",
      "Validation loss 0.9965436232982207 NOT improved\n",
      "Validation loss 0.935454552223885 NOT improved\n",
      "Validation loss 0.9897157337562399 NOT improved\n",
      "Validation loss 0.8717651913572263 NOT improved\n",
      "Validation loss 0.9574326019273978 NOT improved\n",
      "Validation loss 0.9206370412142315 NOT improved\n",
      "Validation loss 0.9017918599673208 NOT improved\n",
      "Validation loss 0.9666583755736489 NOT improved\n",
      "Validation loss 0.968448786634058 NOT improved\n",
      "Validation loss 0.9719180305063162 NOT improved\n",
      "Validation loss 0.9702821121143899 NOT improved\n",
      "Validation loss 1.2297034733152297 NOT improved\n",
      "Early stopping\n",
      "Training round 15\n",
      "Validation loss 0.9994247023070554 NOT improved\n",
      "Validation loss 0.9996696028489448 NOT improved\n",
      "Validation loss 0.9998002170198905 NOT improved\n",
      "Validation loss 0.9998482425325808 NOT improved\n",
      "Validation loss 0.9998756659007616 NOT improved\n",
      "Validation loss 0.9998912904293596 NOT improved\n",
      "Validation loss 0.9999051221200265 NOT improved\n",
      "Validation loss 0.999911666125298 NOT improved\n",
      "Validation loss 0.9999075768662065 NOT improved\n",
      "Validation loss 0.9999036916542875 NOT improved\n",
      "Validation loss 0.9999001984581157 NOT improved\n",
      "Validation loss 0.9998852617601368 NOT improved\n",
      "Validation loss 0.9998527653238102 NOT improved\n",
      "Validation loss 0.9998359211407208 NOT improved\n",
      "Validation loss 0.9998523227163446 NOT improved\n",
      "Validation loss 0.9998009101043172 NOT improved\n",
      "Validation loss 0.9997037140510889 NOT improved\n",
      "Validation loss 0.9997501763851318 NOT improved\n",
      "Validation loss 0.999646191178008 NOT improved\n",
      "Validation loss 0.9995427524918324 NOT improved\n",
      "Validation loss 0.9996286819820447 NOT improved\n",
      "Validation loss 0.9992744448243205 NOT improved\n",
      "Validation loss 0.9978468826623473 NOT improved\n",
      "Validation loss 0.9977119428096154 NOT improved\n",
      "Validation loss 0.9976194485668933 NOT improved\n",
      "Validation loss 0.9923156876976952 NOT improved\n",
      "Validation loss 0.9951564895898483 NOT improved\n",
      "Validation loss 0.9975319992444263 NOT improved\n",
      "Validation loss 0.9962609141417732 NOT improved\n",
      "Validation loss 0.9902284734521002 NOT improved\n",
      "Validation loss 0.9792454896687869 NOT improved\n",
      "Validation loss 0.9813615440652322 NOT improved\n",
      "Validation loss 0.9322399902521443 NOT improved\n",
      "Validation loss 0.9649487102336888 NOT improved\n",
      "Validation loss 0.9448890379592757 NOT improved\n",
      "Validation loss 0.9828107226794162 NOT improved\n",
      "Validation loss 0.9174674796984832 NOT improved\n",
      "Validation loss 0.9014113130778867 NOT improved\n",
      "Validation loss 0.8693936054388469 NOT improved\n",
      "Validation loss 0.9862877617272404 NOT improved\n",
      "Validation loss 0.9669916169130516 NOT improved\n",
      "Validation loss 0.8624462149179281 NOT improved\n",
      "Validation loss 0.9080625180497846 NOT improved\n",
      "Validation loss 1.802195521498073 NOT improved\n",
      "Early stopping\n",
      "Training round 16\n",
      "Validation loss 0.9996672551202017 NOT improved\n",
      "Validation loss 0.9997965744239631 NOT improved\n",
      "Validation loss 0.9998326480820809 NOT improved\n",
      "Validation loss 0.9998676242741259 NOT improved\n",
      "Validation loss 0.9998690056565878 NOT improved\n",
      "Validation loss 0.9998725454631939 NOT improved\n",
      "Validation loss 0.9998804879332073 NOT improved\n",
      "Validation loss 0.9998815101077649 NOT improved\n",
      "Validation loss 0.9998848106188627 NOT improved\n",
      "Validation loss 0.9998556517154149 NOT improved\n",
      "Validation loss 0.9998535251546117 NOT improved\n",
      "Validation loss 0.9998568455152289 NOT improved\n",
      "Validation loss 0.9998227235568395 NOT improved\n",
      "Validation loss 0.9997799525632913 NOT improved\n",
      "Validation loss 0.9998224920765186 NOT improved\n",
      "Validation loss 0.9997407837782354 NOT improved\n",
      "Validation loss 0.999643468275584 NOT improved\n",
      "Validation loss 0.9994211970770133 NOT improved\n",
      "Validation loss 0.999480432427047 NOT improved\n",
      "Validation loss 0.9993072079061179 NOT improved\n",
      "Validation loss 0.9990037720940003 NOT improved\n",
      "Validation loss 0.9979179896120466 NOT improved\n",
      "Validation loss 0.9980861207194222 NOT improved\n",
      "Validation loss 0.9986779855856933 NOT improved\n",
      "Validation loss 0.9963033246018067 NOT improved\n",
      "Validation loss 0.9960498148170905 NOT improved\n",
      "Validation loss 0.9874745221492557 NOT improved\n",
      "Validation loss 0.9844849461062595 NOT improved\n",
      "Validation loss 0.9809104882762942 NOT improved\n",
      "Validation loss 0.981322727848903 NOT improved\n",
      "Validation loss 0.9781293365097314 NOT improved\n",
      "Validation loss 0.9731727507326398 NOT improved\n",
      "Validation loss 0.9770738726482902 NOT improved\n",
      "Validation loss 0.9869814600866568 NOT improved\n",
      "Validation loss 0.9826164576258679 NOT improved\n",
      "Validation loss 0.9858311677761579 NOT improved\n",
      "Validation loss 0.9711782254087754 NOT improved\n",
      "Validation loss 0.9735850430234352 NOT improved\n",
      "Validation loss 0.9888929999106032 NOT improved\n",
      "Validation loss 0.8405392025367957 NOT improved\n",
      "Validation loss 0.8558611367999029 NOT improved\n",
      "Validation loss 0.8861015211450177 NOT improved\n",
      "Validation loss 0.9181724601627599 NOT improved\n",
      "Validation loss 1.2041660868449706 NOT improved\n",
      "Early stopping\n",
      "Training round 17\n",
      "Validation loss 0.9995288453372372 NOT improved\n",
      "Validation loss 0.9997844588943713 NOT improved\n",
      "Validation loss 0.9998433529064751 NOT improved\n",
      "Validation loss 0.9998658623381006 NOT improved\n",
      "Validation loss 0.9998806686654604 NOT improved\n",
      "Validation loss 0.9998873029816226 NOT improved\n",
      "Validation loss 0.9998870861447825 NOT improved\n",
      "Validation loss 0.9998850356275769 NOT improved\n",
      "Validation loss 0.9998834655298467 NOT improved\n",
      "Validation loss 0.9998769444284737 NOT improved\n",
      "Validation loss 0.9998762531243438 NOT improved\n",
      "Validation loss 0.9998486905858432 NOT improved\n",
      "Validation loss 0.9998316791684476 NOT improved\n",
      "Validation loss 0.9997630012616265 NOT improved\n",
      "Validation loss 0.9997001264335813 NOT improved\n",
      "Validation loss 0.9996045677381138 NOT improved\n",
      "Validation loss 0.9997185747533456 NOT improved\n",
      "Validation loss 0.9995436764491956 NOT improved\n",
      "Validation loss 0.9993329514915934 NOT improved\n",
      "Validation loss 0.99929856655511 NOT improved\n",
      "Validation loss 0.9989766676835629 NOT improved\n",
      "Validation loss 0.9989622425496848 NOT improved\n",
      "Validation loss 0.9990567625821803 NOT improved\n",
      "Validation loss 0.997457999441352 NOT improved\n",
      "Validation loss 0.9925668204438027 NOT improved\n",
      "Validation loss 0.9969118396695713 NOT improved\n",
      "Validation loss 0.9961753736054761 NOT improved\n",
      "Validation loss 0.9824891679746628 NOT improved\n",
      "Validation loss 0.9933471722308256 NOT improved\n",
      "Validation loss 0.9961205076335657 NOT improved\n",
      "Validation loss 0.9889892414331318 NOT improved\n",
      "Validation loss 0.9789613115267357 NOT improved\n",
      "Validation loss 0.9934271466902377 NOT improved\n",
      "Validation loss 0.9775304306263236 NOT improved\n",
      "Validation loss 0.9525395454471594 NOT improved\n",
      "Validation loss 0.9767588692203228 NOT improved\n",
      "Validation loss 0.9504389485486273 NOT improved\n",
      "Validation loss 0.9109102172750495 NOT improved\n",
      "Validation loss 0.8760536097191027 NOT improved\n",
      "Validation loss 0.8823578739708517 NOT improved\n",
      "Validation loss 0.9164028275476386 NOT improved\n",
      "Validation loss 0.9236507334746522 NOT improved\n",
      "Validation loss 2.027793739355159 NOT improved\n",
      "Early stopping\n",
      "Training round 18\n",
      "Validation loss 0.9996130044081372 NOT improved\n",
      "Validation loss 0.9997702356037546 NOT improved\n",
      "Validation loss 0.9998450157577411 NOT improved\n",
      "Validation loss 0.999866071362081 NOT improved\n",
      "Validation loss 0.9998815795170768 NOT improved\n",
      "Validation loss 0.999893359775774 NOT improved\n",
      "Validation loss 0.9998936797089104 NOT improved\n",
      "Validation loss 0.9998987710072723 NOT improved\n",
      "Validation loss 0.9999048173910726 NOT improved\n",
      "Validation loss 0.9999102771076406 NOT improved\n",
      "Validation loss 0.9999046535195223 NOT improved\n",
      "Validation loss 0.9999073494308354 NOT improved\n",
      "Validation loss 0.9998794411820213 NOT improved\n",
      "Validation loss 0.999853901099437 NOT improved\n",
      "Validation loss 0.9998618406972939 NOT improved\n",
      "Validation loss 0.999778118149981 NOT improved\n",
      "Validation loss 0.9998135349725814 NOT improved\n",
      "Validation loss 0.9997242447572914 NOT improved\n",
      "Validation loss 0.9996369587871027 NOT improved\n",
      "Validation loss 0.9995844563231868 NOT improved\n",
      "Validation loss 0.9996127206323243 NOT improved\n",
      "Validation loss 0.9994926203715063 NOT improved\n",
      "Validation loss 0.9993848744567175 NOT improved\n",
      "Validation loss 0.9990420211382489 NOT improved\n",
      "Validation loss 0.997758530331005 NOT improved\n",
      "Validation loss 0.9983984231995705 NOT improved\n",
      "Validation loss 0.9974798821069725 NOT improved\n",
      "Validation loss 0.9962861797301246 NOT improved\n",
      "Validation loss 0.995852777816237 NOT improved\n",
      "Validation loss 0.9838222667316575 NOT improved\n",
      "Validation loss 0.9901054283491885 NOT improved\n",
      "Validation loss 0.8940734799194072 NOT improved\n",
      "Validation loss 0.9498155772674368 NOT improved\n",
      "Validation loss 0.9139781089529403 NOT improved\n",
      "Validation loss 0.9791517365646913 NOT improved\n",
      "Validation loss 0.9514556497378056 NOT improved\n",
      "Validation loss 0.870600506884299 NOT improved\n",
      "Validation loss 0.9544961489508674 NOT improved\n",
      "Validation loss 0.8361097967088843 NOT improved\n",
      "Validation loss 0.9469397969966709 NOT improved\n",
      "Validation loss 0.8440894963847733 NOT improved\n",
      "Validation loss 1.3814438426437432 NOT improved\n",
      "Early stopping\n",
      "Training round 19\n",
      "Validation loss 0.9996774415809536 NOT improved\n",
      "Validation loss 0.9997777443602417 NOT improved\n",
      "Validation loss 0.9998585500517476 NOT improved\n",
      "Validation loss 0.999889122959099 NOT improved\n",
      "Validation loss 0.9999040607155891 NOT improved\n",
      "Validation loss 0.9999125443772147 NOT improved\n",
      "Validation loss 0.9999170235570959 NOT improved\n",
      "Validation loss 0.999923823870509 NOT improved\n",
      "Validation loss 0.9999211194234756 NOT improved\n",
      "Validation loss 0.9999183667824877 NOT improved\n",
      "Validation loss 0.9999131186187411 NOT improved\n",
      "Validation loss 0.9999150229759991 NOT improved\n",
      "Validation loss 0.9998907451776688 NOT improved\n",
      "Validation loss 0.9998952233719786 NOT improved\n",
      "Validation loss 0.9998464030445955 NOT improved\n",
      "Validation loss 0.9998119908151061 NOT improved\n",
      "Validation loss 0.9998424544663806 NOT improved\n",
      "Validation loss 0.9997434398902006 NOT improved\n",
      "Validation loss 0.9996902008555133 NOT improved\n",
      "Validation loss 0.9996645825550775 NOT improved\n",
      "Validation loss 0.999528101511267 NOT improved\n",
      "Validation loss 0.9990803394147435 NOT improved\n",
      "Validation loss 0.9991733097889964 NOT improved\n",
      "Validation loss 0.9989053327733916 NOT improved\n",
      "Validation loss 0.9978963538586602 NOT improved\n",
      "Validation loss 0.9967602489945249 NOT improved\n",
      "Validation loss 0.997310436520556 NOT improved\n",
      "Validation loss 0.9975469483150925 NOT improved\n",
      "Validation loss 0.9890524164764627 NOT improved\n",
      "Validation loss 0.9923194270077698 NOT improved\n",
      "Validation loss 0.9824301212817493 NOT improved\n",
      "Validation loss 0.9963316054594665 NOT improved\n",
      "Validation loss 0.9918072688833026 NOT improved\n",
      "Validation loss 0.9768416650236919 NOT improved\n",
      "Validation loss 0.9650192323027453 NOT improved\n",
      "Validation loss 0.97976143428154 NOT improved\n",
      "Validation loss 0.9850936549651681 NOT improved\n",
      "Validation loss 0.9185041234793319 NOT improved\n",
      "Validation loss 1.4084091402187522 NOT improved\n",
      "Early stopping\n",
      "Training round 20\n",
      "Validation loss 0.9996184738767938 NOT improved\n",
      "Validation loss 0.9997730574363403 NOT improved\n",
      "Validation loss 0.999840170505613 NOT improved\n",
      "Validation loss 0.9998786222995005 NOT improved\n",
      "Validation loss 0.9998951628096114 NOT improved\n",
      "Validation loss 0.999909324419378 NOT improved\n",
      "Validation loss 0.9999155266218144 NOT improved\n",
      "Validation loss 0.999919559652981 NOT improved\n",
      "Validation loss 0.9999002795510504 NOT improved\n",
      "Validation loss 0.9999085695191178 NOT improved\n",
      "Validation loss 0.9998987274335833 NOT improved\n",
      "Validation loss 0.999880017193682 NOT improved\n",
      "Validation loss 0.9998699677834092 NOT improved\n",
      "Validation loss 0.999843139888577 NOT improved\n",
      "Validation loss 0.9998485899627244 NOT improved\n",
      "Validation loss 0.9997956107199473 NOT improved\n",
      "Validation loss 0.9997248436513817 NOT improved\n",
      "Validation loss 0.9995981256853178 NOT improved\n",
      "Validation loss 0.9993280344363193 NOT improved\n",
      "Validation loss 0.9994504494055202 NOT improved\n",
      "Validation loss 0.9992181503241325 NOT improved\n",
      "Validation loss 0.9991816238594246 NOT improved\n",
      "Validation loss 0.9990643659182198 NOT improved\n",
      "Validation loss 0.9953833703262883 NOT improved\n",
      "Validation loss 0.99653307230422 NOT improved\n",
      "Validation loss 0.9963705790253002 NOT improved\n",
      "Validation loss 0.9988095243300518 NOT improved\n",
      "Validation loss 0.996790736641007 NOT improved\n",
      "Validation loss 0.9952402018144215 NOT improved\n",
      "Validation loss 0.991794692124653 NOT improved\n",
      "Validation loss 0.9730083619463239 NOT improved\n",
      "Validation loss 0.9920563864366254 NOT improved\n",
      "Validation loss 0.9894663385481228 NOT improved\n",
      "Validation loss 0.9298049452048256 NOT improved\n",
      "Validation loss 0.9658688241436912 NOT improved\n",
      "Validation loss 0.9431140042795463 NOT improved\n",
      "Validation loss 0.9646480956201968 NOT improved\n",
      "Validation loss 1.0461347854026963 NOT improved\n",
      "Early stopping\n",
      "Training round 21\n",
      "Validation loss 0.9996688943844934 NOT improved\n",
      "Validation loss 0.9997730243106977 NOT improved\n",
      "Validation loss 0.9998314718857938 NOT improved\n",
      "Validation loss 0.9998526922013949 NOT improved\n",
      "Validation loss 0.9998664893527905 NOT improved\n",
      "Validation loss 0.9998753454165932 NOT improved\n",
      "Validation loss 0.9998870146970756 NOT improved\n",
      "Validation loss 0.9998873731514922 NOT improved\n",
      "Validation loss 0.9998786835361572 NOT improved\n",
      "Validation loss 0.9998877228270735 NOT improved\n",
      "Validation loss 0.999885313706801 NOT improved\n",
      "Validation loss 0.9998937850402787 NOT improved\n",
      "Validation loss 0.9998392910433374 NOT improved\n",
      "Validation loss 0.9998073940545392 NOT improved\n",
      "Validation loss 0.9997945928648123 NOT improved\n",
      "Validation loss 0.9997812741915441 NOT improved\n",
      "Validation loss 0.9997981758177273 NOT improved\n",
      "Validation loss 0.9997237725047189 NOT improved\n",
      "Validation loss 0.999685310022732 NOT improved\n",
      "Validation loss 0.9994100544571649 NOT improved\n",
      "Validation loss 0.9993301607933767 NOT improved\n",
      "Validation loss 0.9992364905425623 NOT improved\n",
      "Validation loss 0.998613729717657 NOT improved\n",
      "Validation loss 0.9984714675539743 NOT improved\n",
      "Validation loss 0.9970549760006865 NOT improved\n",
      "Validation loss 0.9975812167407103 NOT improved\n",
      "Validation loss 0.9961331996633486 NOT improved\n",
      "Validation loss 0.9896796112253567 NOT improved\n",
      "Validation loss 0.9892805805750018 NOT improved\n",
      "Validation loss 0.9951615753052923 NOT improved\n",
      "Validation loss 0.9705755279673244 NOT improved\n",
      "Validation loss 0.9811271884791849 NOT improved\n",
      "Validation loss 0.976099228090015 NOT improved\n",
      "Validation loss 0.9124823445504197 NOT improved\n",
      "Validation loss 0.957532095170441 NOT improved\n",
      "Validation loss 0.9411003242267971 NOT improved\n",
      "Validation loss 0.9696836074441305 NOT improved\n",
      "Validation loss 0.9411662364595216 NOT improved\n",
      "Validation loss 0.9545823878404944 NOT improved\n",
      "Validation loss 0.8696869385311721 NOT improved\n",
      "Validation loss 0.9870984773361555 NOT improved\n",
      "Validation loss 0.9252072505998694 NOT improved\n",
      "Validation loss 0.906897551237512 NOT improved\n",
      "Validation loss 0.9552129907736199 NOT improved\n",
      "Validation loss 0.9579237279862629 NOT improved\n",
      "Validation loss 1.6909612133502474 NOT improved\n",
      "Early stopping\n",
      "Training round 22\n",
      "Validation loss 0.9996005375100968 NOT improved\n",
      "Validation loss 0.9997508177110409 NOT improved\n",
      "Validation loss 0.9998252925193823 NOT improved\n",
      "Validation loss 0.9998637943070124 NOT improved\n",
      "Validation loss 0.9998857261254858 NOT improved\n",
      "Validation loss 0.9998963745422256 NOT improved\n",
      "Validation loss 0.9998898847177733 NOT improved\n",
      "Validation loss 0.9998873368948477 NOT improved\n",
      "Validation loss 0.9998865566125186 NOT improved\n",
      "Validation loss 0.9998775332190495 NOT improved\n",
      "Validation loss 0.9998716119317084 NOT improved\n",
      "Validation loss 0.999876702861647 NOT improved\n",
      "Validation loss 0.9998518814329375 NOT improved\n",
      "Validation loss 0.9998680662102634 NOT improved\n",
      "Validation loss 0.9998297595618091 NOT improved\n",
      "Validation loss 0.9997331410781204 NOT improved\n",
      "Validation loss 0.9997855306485208 NOT improved\n",
      "Validation loss 0.9996819520762656 NOT improved\n",
      "Validation loss 0.9997195124064155 NOT improved\n",
      "Validation loss 0.9991360728066203 NOT improved\n",
      "Validation loss 0.999460857670411 NOT improved\n",
      "Validation loss 0.9989615964004757 NOT improved\n",
      "Validation loss 0.9982600402270525 NOT improved\n",
      "Validation loss 0.9954237636228932 NOT improved\n",
      "Validation loss 0.9950300677737703 NOT improved\n",
      "Validation loss 0.9966116651866843 NOT improved\n",
      "Validation loss 0.9980560434472495 NOT improved\n",
      "Validation loss 0.9939700634835652 NOT improved\n",
      "Validation loss 0.99308232213608 NOT improved\n",
      "Validation loss 0.9819295255007001 NOT improved\n",
      "Validation loss 0.9887642191759861 NOT improved\n",
      "Validation loss 0.9959381457341341 NOT improved\n",
      "Validation loss 0.9925128130469246 NOT improved\n",
      "Validation loss 0.995844570477553 NOT improved\n",
      "Validation loss 0.9824834197488451 NOT improved\n",
      "Validation loss 0.9930139953935568 NOT improved\n",
      "Validation loss 0.98937979805715 NOT improved\n",
      "Validation loss 0.9847419977991313 NOT improved\n",
      "Validation loss 0.9284332644582522 NOT improved\n",
      "Validation loss 0.9873308489077427 NOT improved\n",
      "Validation loss 0.8409314996893565 NOT improved\n",
      "Validation loss 1.4681796320739622 NOT improved\n",
      "Early stopping\n",
      "Training round 23\n",
      "Validation loss 0.9997558329476927 NOT improved\n",
      "Validation loss 0.9997798557528312 NOT improved\n",
      "Validation loss 0.9998354612029895 NOT improved\n",
      "Validation loss 0.9998592823762777 NOT improved\n",
      "Validation loss 0.9998756656926299 NOT improved\n",
      "Validation loss 0.9998874266445185 NOT improved\n",
      "Validation loss 0.9998911447076602 NOT improved\n",
      "Validation loss 0.9998921174141043 NOT improved\n",
      "Validation loss 0.9998882991973416 NOT improved\n",
      "Validation loss 0.9998738829606096 NOT improved\n",
      "Validation loss 0.9998802140827466 NOT improved\n",
      "Validation loss 0.9998693107662147 NOT improved\n",
      "Validation loss 0.9998259043556277 NOT improved\n",
      "Validation loss 0.999846627560221 NOT improved\n",
      "Validation loss 0.9998047650678177 NOT improved\n",
      "Validation loss 0.9997926265515898 NOT improved\n",
      "Validation loss 0.9997034594194456 NOT improved\n",
      "Validation loss 0.9997398772726241 NOT improved\n",
      "Validation loss 0.9996384371660526 NOT improved\n",
      "Validation loss 0.9992189775794277 NOT improved\n",
      "Validation loss 0.9991761610392916 NOT improved\n",
      "Validation loss 0.9988744701796968 NOT improved\n",
      "Validation loss 0.9990322492555207 NOT improved\n",
      "Validation loss 0.9988444095633635 NOT improved\n",
      "Validation loss 0.9979206428679166 NOT improved\n",
      "Validation loss 0.9980047726605448 NOT improved\n",
      "Validation loss 0.9961603909285125 NOT improved\n",
      "Validation loss 0.9956448253784036 NOT improved\n",
      "Validation loss 0.9931980531036991 NOT improved\n",
      "Validation loss 0.9834817524367305 NOT improved\n",
      "Validation loss 0.9947632829246814 NOT improved\n",
      "Validation loss 0.9816061111956585 NOT improved\n",
      "Validation loss 0.9940906558923646 NOT improved\n",
      "Validation loss 0.9541989043959739 NOT improved\n",
      "Validation loss 0.9149766175668854 NOT improved\n",
      "Validation loss 0.9446422790689223 NOT improved\n",
      "Validation loss 0.9276387843541819 NOT improved\n",
      "Validation loss 0.9269101510211297 NOT improved\n",
      "Validation loss 0.9913750224317526 NOT improved\n",
      "Validation loss 0.9205530746772007 NOT improved\n",
      "Validation loss 0.9533781493586737 NOT improved\n",
      "Validation loss 0.9753586183933742 NOT improved\n",
      "Validation loss 0.9579368169709777 NOT improved\n",
      "Validation loss 0.9799652999895742 NOT improved\n",
      "Validation loss 0.9266136638845505 NOT improved\n",
      "Validation loss 0.9802988571438025 NOT improved\n",
      "Validation loss 0.9890265173250598 NOT improved\n",
      "Validation loss 0.9222185749380545 NOT improved\n",
      "Validation loss 1.7311741305842423 NOT improved\n",
      "Early stopping\n",
      "Training round 24\n",
      "Validation loss 0.9992994853926754 NOT improved\n",
      "Validation loss 0.9997007336364501 NOT improved\n",
      "Validation loss 0.9998261477982361 NOT improved\n",
      "Validation loss 0.999872214726811 NOT improved\n",
      "Validation loss 0.9998865576710778 NOT improved\n",
      "Validation loss 0.9998986919354983 NOT improved\n",
      "Validation loss 0.9999035742084174 NOT improved\n",
      "Validation loss 0.9999044132038762 NOT improved\n",
      "Validation loss 0.999903278754221 NOT improved\n",
      "Validation loss 0.9999045161033024 NOT improved\n",
      "Validation loss 0.9999083710324577 NOT improved\n",
      "Validation loss 0.9998919686060134 NOT improved\n",
      "Validation loss 0.999855485218194 NOT improved\n",
      "Validation loss 0.9998452302650626 NOT improved\n",
      "Validation loss 0.9998228341600489 NOT improved\n",
      "Validation loss 0.9998219846682433 NOT improved\n",
      "Validation loss 0.9998191234755235 NOT improved\n",
      "Validation loss 0.9997873268580898 NOT improved\n",
      "Validation loss 0.9995399787483453 NOT improved\n",
      "Validation loss 0.9994013999841955 NOT improved\n",
      "Validation loss 0.999417670984724 NOT improved\n",
      "Validation loss 0.9987930437336621 NOT improved\n",
      "Validation loss 0.9971883315374649 NOT improved\n",
      "Validation loss 0.9986683666460016 NOT improved\n",
      "Validation loss 0.9975807275186276 NOT improved\n",
      "Validation loss 0.9966714739053442 NOT improved\n",
      "Validation loss 0.9976005918891032 NOT improved\n",
      "Validation loss 0.992955989961895 NOT improved\n",
      "Validation loss 0.9747591833483205 NOT improved\n",
      "Validation loss 0.9899570632080926 NOT improved\n",
      "Validation loss 0.9863131832084923 NOT improved\n",
      "Validation loss 0.9966015378912759 NOT improved\n",
      "Validation loss 0.9760098242099257 NOT improved\n",
      "Validation loss 0.9731441746125788 NOT improved\n",
      "Validation loss 0.9939223804735196 NOT improved\n",
      "Validation loss 0.9476123662102279 NOT improved\n",
      "Validation loss 0.9388698146595617 NOT improved\n",
      "Validation loss 0.97589231292794 NOT improved\n",
      "Validation loss 0.9642974614778266 NOT improved\n",
      "Validation loss 0.8730352910483952 NOT improved\n",
      "Validation loss 1.1256365276725486 NOT improved\n",
      "Early stopping\n",
      "Training round 25\n",
      "Validation loss 0.999728633453519 NOT improved\n",
      "Validation loss 0.9997591880525518 NOT improved\n",
      "Validation loss 0.9998093889749212 NOT improved\n",
      "Validation loss 0.9998329132346381 NOT improved\n",
      "Validation loss 0.9998431129861843 NOT improved\n",
      "Validation loss 0.9998691619519795 NOT improved\n",
      "Validation loss 0.9998718961158094 NOT improved\n",
      "Validation loss 0.9998667124609797 NOT improved\n",
      "Validation loss 0.9998485001596427 NOT improved\n",
      "Validation loss 0.9998397167133249 NOT improved\n",
      "Validation loss 0.9998469718948121 NOT improved\n",
      "Validation loss 0.9998339367259643 NOT improved\n",
      "Validation loss 0.999808579197462 NOT improved\n",
      "Validation loss 0.9998018442063197 NOT improved\n",
      "Validation loss 0.9997470095798529 NOT improved\n",
      "Validation loss 0.9997227484634934 NOT improved\n",
      "Validation loss 0.9996416224372627 NOT improved\n",
      "Validation loss 0.9996918251508036 NOT improved\n",
      "Validation loss 0.9995907511322536 NOT improved\n",
      "Validation loss 0.9993503954187157 NOT improved\n",
      "Validation loss 0.9987859814079633 NOT improved\n",
      "Validation loss 0.9990833535150431 NOT improved\n",
      "Validation loss 0.998643323026961 NOT improved\n",
      "Validation loss 0.9985914613482639 NOT improved\n",
      "Validation loss 0.9954300194378362 NOT improved\n",
      "Validation loss 0.994281755802004 NOT improved\n",
      "Validation loss 0.9965875296751417 NOT improved\n",
      "Validation loss 0.9943495390480181 NOT improved\n",
      "Validation loss 0.9694646008271953 NOT improved\n",
      "Validation loss 0.9722727840604496 NOT improved\n",
      "Validation loss 0.9827111058026742 NOT improved\n",
      "Validation loss 0.9908878922309818 NOT improved\n",
      "Validation loss 0.9448166147307424 NOT improved\n",
      "Validation loss 0.9927907365145496 NOT improved\n",
      "Validation loss 0.9919729512710721 NOT improved\n",
      "Validation loss 0.991703413698388 NOT improved\n",
      "Validation loss 0.9905417347298773 NOT improved\n",
      "Validation loss 0.9865251170873056 NOT improved\n",
      "Validation loss 0.9596024659361779 NOT improved\n",
      "Validation loss 0.9095155107233941 NOT improved\n",
      "Validation loss 0.8333162003535334 NOT improved\n",
      "Validation loss 0.88355467882015 NOT improved\n",
      "Validation loss 0.8529418445395129 NOT improved\n",
      "Validation loss 0.9317513967749353 NOT improved\n",
      "Validation loss 0.8784988213696467 NOT improved\n",
      "Validation loss 3.858038590939359 NOT improved\n",
      "Early stopping\n",
      "Training round 26\n",
      "Validation loss 0.9995831062236368 NOT improved\n",
      "Validation loss 0.9997601118582544 NOT improved\n",
      "Validation loss 0.9998206873660154 NOT improved\n",
      "Validation loss 0.9998561741747807 NOT improved\n",
      "Validation loss 0.9998781881806421 NOT improved\n",
      "Validation loss 0.9998928388587954 NOT improved\n",
      "Validation loss 0.9998917044575566 NOT improved\n",
      "Validation loss 0.9998926159659266 NOT improved\n",
      "Validation loss 0.9998914356304972 NOT improved\n",
      "Validation loss 0.9998825573290011 NOT improved\n",
      "Validation loss 0.9998778762903731 NOT improved\n",
      "Validation loss 0.9998719352379828 NOT improved\n",
      "Validation loss 0.9998603612288747 NOT improved\n",
      "Validation loss 0.9998187890470803 NOT improved\n",
      "Validation loss 0.9998276392964391 NOT improved\n",
      "Validation loss 0.9998102360484108 NOT improved\n",
      "Validation loss 0.9997281069388465 NOT improved\n",
      "Validation loss 0.9996703322419824 NOT improved\n",
      "Validation loss 0.9996320735074424 NOT improved\n",
      "Validation loss 0.999527844120774 NOT improved\n",
      "Validation loss 0.9994800746066017 NOT improved\n",
      "Validation loss 0.9992991042072943 NOT improved\n",
      "Validation loss 0.9987858116465942 NOT improved\n",
      "Validation loss 0.9992407118621104 NOT improved\n",
      "Validation loss 0.9980896774905019 NOT improved\n",
      "Validation loss 0.9946229341250574 NOT improved\n",
      "Validation loss 0.9969400080634568 NOT improved\n",
      "Validation loss 0.9947305539203721 NOT improved\n",
      "Validation loss 0.9964286509924168 NOT improved\n",
      "Validation loss 0.9801736264500016 NOT improved\n",
      "Validation loss 0.9765806386874984 NOT improved\n",
      "Validation loss 0.9853091590515913 NOT improved\n",
      "Validation loss 0.9717685109106207 NOT improved\n",
      "Validation loss 0.9779552695927877 NOT improved\n",
      "Validation loss 0.9576942368186628 NOT improved\n",
      "Validation loss 0.9842875809068261 NOT improved\n",
      "Validation loss 0.9725514240096242 NOT improved\n",
      "Validation loss 0.9637126491081371 NOT improved\n",
      "Validation loss 0.9422274289131158 NOT improved\n",
      "Validation loss 0.9352548006451684 NOT improved\n",
      "Validation loss 0.900705537594258 NOT improved\n",
      "Validation loss 0.912471833151066 NOT improved\n",
      "Validation loss 0.9207646171884913 NOT improved\n",
      "Validation loss 0.9404738359830805 NOT improved\n",
      "Validation loss 0.8810499498201241 NOT improved\n",
      "Validation loss 0.931256103855359 NOT improved\n",
      "Validation loss 1.510162019967359 NOT improved\n",
      "Early stopping\n",
      "Training round 27\n",
      "Validation loss 0.9997206607147229 NOT improved\n",
      "Validation loss 0.9998005062688122 NOT improved\n",
      "Validation loss 0.9998453834684541 NOT improved\n",
      "Validation loss 0.9998698283962418 NOT improved\n",
      "Validation loss 0.999882891709019 NOT improved\n",
      "Validation loss 0.9998894632306782 NOT improved\n",
      "Validation loss 0.9998984924899551 NOT improved\n",
      "Validation loss 0.9998975382467981 NOT improved\n",
      "Validation loss 0.9999001676713226 NOT improved\n",
      "Validation loss 0.9998933303644271 NOT improved\n",
      "Validation loss 0.9998885150577149 NOT improved\n",
      "Validation loss 0.9998792428537197 NOT improved\n",
      "Validation loss 0.9998643269799732 NOT improved\n",
      "Validation loss 0.9998446409556783 NOT improved\n",
      "Validation loss 0.9998566474704498 NOT improved\n",
      "Validation loss 0.9998005332130776 NOT improved\n",
      "Validation loss 0.9997744637327173 NOT improved\n",
      "Validation loss 0.9997326904489252 NOT improved\n",
      "Validation loss 0.9995543414524319 NOT improved\n",
      "Validation loss 0.9995785862396287 NOT improved\n",
      "Validation loss 0.9995423956219052 NOT improved\n",
      "Validation loss 0.9990998626277331 NOT improved\n",
      "Validation loss 0.9989680494332035 NOT improved\n",
      "Validation loss 0.9987274900074561 NOT improved\n",
      "Validation loss 0.9978147020794504 NOT improved\n",
      "Validation loss 0.9966107254829719 NOT improved\n",
      "Validation loss 0.9967694732629149 NOT improved\n",
      "Validation loss 0.9918361249562143 NOT improved\n",
      "Validation loss 0.993930630729211 NOT improved\n",
      "Validation loss 0.9971258607821499 NOT improved\n",
      "Validation loss 0.9934889869947846 NOT improved\n",
      "Validation loss 0.9847390983666504 NOT improved\n",
      "Validation loss 0.9898876661076124 NOT improved\n",
      "Validation loss 0.9489031153016024 NOT improved\n",
      "Validation loss 0.9327674965931677 NOT improved\n",
      "Validation loss 0.9477452702401683 NOT improved\n",
      "Validation loss 0.9856937735544921 NOT improved\n",
      "Validation loss 0.9566208819582085 NOT improved\n",
      "Validation loss 0.9765511171489935 NOT improved\n",
      "Validation loss 0.9349088428835838 NOT improved\n",
      "Validation loss 0.980499864740319 NOT improved\n",
      "Validation loss 0.955675731597336 NOT improved\n",
      "Validation loss 0.8699876221791552 NOT improved\n",
      "Validation loss 0.8628428385026158 NOT improved\n",
      "Validation loss 0.9566562526528454 NOT improved\n",
      "Validation loss 0.919389723885333 NOT improved\n",
      "Validation loss 0.8678601624176085 NOT improved\n",
      "Validation loss 0.9917528423602845 NOT improved\n",
      "Validation loss 0.9032639839439993 NOT improved\n",
      "Validation loss 0.9250896702353862 NOT improved\n",
      "Validation loss 0.8937722951061965 NOT improved\n",
      "Validation loss 1.8344356659502608 NOT improved\n",
      "Early stopping\n",
      "Training round 28\n",
      "Validation loss 0.9997338552447966 NOT improved\n",
      "Validation loss 0.999803215248312 NOT improved\n",
      "Validation loss 0.9998513414492647 NOT improved\n",
      "Validation loss 0.9998685327366595 NOT improved\n",
      "Validation loss 0.9998762538217734 NOT improved\n",
      "Validation loss 0.9998956578950229 NOT improved\n",
      "Validation loss 0.9998990978001429 NOT improved\n",
      "Validation loss 0.9999097170125557 NOT improved\n",
      "Validation loss 0.9998873422041535 NOT improved\n",
      "Validation loss 0.9998936104499316 NOT improved\n",
      "Validation loss 0.9998896544352966 NOT improved\n",
      "Validation loss 0.999867950610043 NOT improved\n",
      "Validation loss 0.9998460774484794 NOT improved\n",
      "Validation loss 0.9998437890004509 NOT improved\n",
      "Validation loss 0.9998002133220568 NOT improved\n",
      "Validation loss 0.9997824850900402 NOT improved\n",
      "Validation loss 0.9996483999780214 NOT improved\n",
      "Validation loss 0.9996607074462928 NOT improved\n",
      "Validation loss 0.9994229148353363 NOT improved\n",
      "Validation loss 0.9991942428937614 NOT improved\n",
      "Validation loss 0.9993350509937283 NOT improved\n",
      "Validation loss 0.9995151687039494 NOT improved\n",
      "Validation loss 0.9984003810571918 NOT improved\n",
      "Validation loss 0.9990424988133861 NOT improved\n",
      "Validation loss 0.9976412170758499 NOT improved\n",
      "Validation loss 0.9968264041072065 NOT improved\n",
      "Validation loss 0.99667645072676 NOT improved\n",
      "Validation loss 0.9931142981893161 NOT improved\n",
      "Validation loss 0.9540484415461633 NOT improved\n",
      "Validation loss 0.9966331692929526 NOT improved\n",
      "Validation loss 0.9906029149129996 NOT improved\n",
      "Validation loss 0.991465771964197 NOT improved\n",
      "Validation loss 0.9563329008462927 NOT improved\n",
      "Validation loss 0.9850730568038727 NOT improved\n",
      "Validation loss 0.9870262614251984 NOT improved\n",
      "Validation loss 0.9816629744577711 NOT improved\n",
      "Validation loss 0.9883130079869059 NOT improved\n",
      "Validation loss 0.9487475072467739 NOT improved\n",
      "Validation loss 0.9685732849194206 NOT improved\n",
      "Validation loss 0.9834825706230081 NOT improved\n",
      "Validation loss 0.8575894770833469 NOT improved\n",
      "Validation loss 0.9156533981906079 NOT improved\n",
      "Validation loss 0.8524555983392036 NOT improved\n",
      "Validation loss 0.843207083735094 NOT improved\n",
      "Validation loss 0.84985991586045 NOT improved\n",
      "Validation loss 0.9159724775709112 NOT improved\n",
      "Validation loss 0.9839449480174749 NOT improved\n",
      "Validation loss 3.925617733024324 NOT improved\n",
      "Early stopping\n",
      "Training round 29\n",
      "Validation loss 0.9995436080205992 NOT improved\n",
      "Validation loss 0.9996857089826665 NOT improved\n",
      "Validation loss 0.9998052191554364 NOT improved\n",
      "Validation loss 0.9998588392877912 NOT improved\n",
      "Validation loss 0.9998897749403601 NOT improved\n",
      "Validation loss 0.9998978093607082 NOT improved\n",
      "Validation loss 0.9998969537862128 NOT improved\n",
      "Validation loss 0.9998984129826749 NOT improved\n",
      "Validation loss 0.999901185035492 NOT improved\n",
      "Validation loss 0.9998937582793004 NOT improved\n",
      "Validation loss 0.9998831723749193 NOT improved\n",
      "Validation loss 0.9998681646947839 NOT improved\n",
      "Validation loss 0.9998455700602796 NOT improved\n",
      "Validation loss 0.9998452851419471 NOT improved\n",
      "Validation loss 0.9997792924849892 NOT improved\n",
      "Validation loss 0.9997095257434815 NOT improved\n",
      "Validation loss 0.9996298791350106 NOT improved\n",
      "Validation loss 0.9994539797217795 NOT improved\n",
      "Validation loss 0.9996393375403132 NOT improved\n",
      "Validation loss 0.9993132484545123 NOT improved\n",
      "Validation loss 0.9987564971764954 NOT improved\n",
      "Validation loss 0.9988660299811497 NOT improved\n",
      "Validation loss 0.9990146244255821 NOT improved\n",
      "Validation loss 0.9973578402158124 NOT improved\n",
      "Validation loss 0.9989951654606001 NOT improved\n",
      "Validation loss 0.9972901951426808 NOT improved\n",
      "Validation loss 0.9983216617486644 NOT improved\n",
      "Validation loss 0.99659577456307 NOT improved\n",
      "Validation loss 0.9895357254906023 NOT improved\n",
      "Validation loss 0.9830881238650258 NOT improved\n",
      "Validation loss 0.9775062006704306 NOT improved\n",
      "Validation loss 0.9869269965326366 NOT improved\n",
      "Validation loss 0.9579221629116534 NOT improved\n",
      "Validation loss 0.9720978372382756 NOT improved\n",
      "Validation loss 0.9189301384677627 NOT improved\n",
      "Validation loss 0.9756970762746312 NOT improved\n",
      "Validation loss 0.9802348972551403 NOT improved\n",
      "Validation loss 0.9636830558404555 NOT improved\n",
      "Validation loss 0.9409619214974763 NOT improved\n",
      "Validation loss 0.970968718427322 NOT improved\n",
      "Validation loss 0.9601528466332179 NOT improved\n",
      "Validation loss 0.8831766889177964 NOT improved\n",
      "Validation loss 0.8443069504282926 NOT improved\n",
      "Validation loss 0.9238185340964734 NOT improved\n",
      "Validation loss 0.9575442881279745 NOT improved\n",
      "Validation loss 0.8972594933352052 NOT improved\n",
      "Validation loss 0.8804255490537622 NOT improved\n",
      "Validation loss 0.906196319433829 NOT improved\n",
      "Validation loss 0.9832224583880571 NOT improved\n",
      "Validation loss 2.192073856040568 NOT improved\n",
      "Early stopping\n",
      "Training round 30\n",
      "Validation loss 0.9996246030909398 NOT improved\n",
      "Validation loss 0.9997699409424655 NOT improved\n",
      "Validation loss 0.9998428056297988 NOT improved\n",
      "Validation loss 0.9998810980641047 NOT improved\n",
      "Validation loss 0.9998929679974707 NOT improved\n",
      "Validation loss 0.999898313839575 NOT improved\n",
      "Validation loss 0.9999082262743773 NOT improved\n",
      "Validation loss 0.9999099887938281 NOT improved\n",
      "Validation loss 0.9999053742158833 NOT improved\n",
      "Validation loss 0.9998911246511363 NOT improved\n",
      "Validation loss 0.9998866048817342 NOT improved\n",
      "Validation loss 0.9998643063049075 NOT improved\n",
      "Validation loss 0.9998725445924806 NOT improved\n",
      "Validation loss 0.9998451384110182 NOT improved\n",
      "Validation loss 0.9998438775645607 NOT improved\n",
      "Validation loss 0.9997451761073061 NOT improved\n",
      "Validation loss 0.9996450343721975 NOT improved\n",
      "Validation loss 0.9995834019846774 NOT improved\n",
      "Validation loss 0.9996707241708152 NOT improved\n",
      "Validation loss 0.9993700481344293 NOT improved\n",
      "Validation loss 0.9992838258738691 NOT improved\n",
      "Validation loss 0.9988023676152928 NOT improved\n",
      "Validation loss 0.9980716251298984 NOT improved\n",
      "Validation loss 0.9989546877637887 NOT improved\n",
      "Validation loss 0.9989944957677217 NOT improved\n",
      "Validation loss 0.9976079845816401 NOT improved\n",
      "Validation loss 0.9930291871311882 NOT improved\n",
      "Validation loss 0.996859384542145 NOT improved\n",
      "Validation loss 0.9890278952549659 NOT improved\n",
      "Validation loss 0.9938235172401536 NOT improved\n",
      "Validation loss 0.9858120073585254 NOT improved\n",
      "Validation loss 0.8452055039695171 NOT improved\n",
      "Validation loss 0.9813981517607779 NOT improved\n",
      "Validation loss 0.9472949230240765 NOT improved\n",
      "Validation loss 0.9857363988635512 NOT improved\n",
      "Validation loss 0.9599720806228844 NOT improved\n",
      "Validation loss 0.9920029067498668 NOT improved\n",
      "Validation loss 0.9903997368783598 NOT improved\n",
      "Validation loss 0.9838700563686824 NOT improved\n",
      "Validation loss 0.9546287629536425 NOT improved\n",
      "Validation loss 0.8954263886743928 NOT improved\n",
      "Validation loss 0.8615838776527459 NOT improved\n",
      "Validation loss 0.9715630388874951 NOT improved\n",
      "Validation loss 0.8925592678535683 NOT improved\n",
      "Validation loss 0.8672192645099673 NOT improved\n",
      "Validation loss 1.1711007543561351 NOT improved\n",
      "Early stopping\n",
      "Training round 31\n",
      "Validation loss 0.9997060806207994 NOT improved\n",
      "Validation loss 0.9997769728892769 NOT improved\n",
      "Validation loss 0.9998411633638704 NOT improved\n",
      "Validation loss 0.9998683399812881 NOT improved\n",
      "Validation loss 0.999892736816646 NOT improved\n",
      "Validation loss 0.9998952665701836 NOT improved\n",
      "Validation loss 0.9998996043690432 NOT improved\n",
      "Validation loss 0.999902195980195 NOT improved\n",
      "Validation loss 0.9998993830440612 NOT improved\n",
      "Validation loss 0.9998842991562875 NOT improved\n",
      "Validation loss 0.9998977003841012 NOT improved\n",
      "Validation loss 0.9998788737675818 NOT improved\n",
      "Validation loss 0.9998332395724057 NOT improved\n",
      "Validation loss 0.9998189923386311 NOT improved\n",
      "Validation loss 0.9998618684208642 NOT improved\n",
      "Validation loss 0.9997875560746333 NOT improved\n",
      "Validation loss 0.9998064282801707 NOT improved\n",
      "Validation loss 0.9996982621772482 NOT improved\n",
      "Validation loss 0.9996899291124297 NOT improved\n",
      "Validation loss 0.9993941950496704 NOT improved\n",
      "Validation loss 0.9992598091653189 NOT improved\n",
      "Validation loss 0.9993586558677809 NOT improved\n",
      "Validation loss 0.9995357930037577 NOT improved\n",
      "Validation loss 0.998895937859785 NOT improved\n",
      "Validation loss 0.9969911487168099 NOT improved\n",
      "Validation loss 0.9981717705481997 NOT improved\n",
      "Validation loss 0.9965900851976569 NOT improved\n",
      "Validation loss 0.9987333685337433 NOT improved\n",
      "Validation loss 0.9954916945529194 NOT improved\n",
      "Validation loss 0.9940030658000715 NOT improved\n",
      "Validation loss 0.9965001389266533 NOT improved\n",
      "Validation loss 0.9949147944656853 NOT improved\n",
      "Validation loss 0.8632877543637714 NOT improved\n",
      "Validation loss 0.9482046940429446 NOT improved\n",
      "Validation loss 0.9640681053046003 NOT improved\n",
      "Validation loss 0.8956102899017107 NOT improved\n",
      "Validation loss 0.9789245614054629 NOT improved\n",
      "Validation loss 0.8987647211706306 NOT improved\n",
      "Validation loss 0.9372650376946151 NOT improved\n",
      "Validation loss 0.9787784257901492 NOT improved\n",
      "Validation loss 0.9564394172994328 NOT improved\n",
      "Validation loss 0.9659118466870642 NOT improved\n",
      "Validation loss 0.8690197217320988 NOT improved\n",
      "Validation loss 0.8536003351522069 NOT improved\n",
      "Validation loss 2.9252273880519404 NOT improved\n",
      "Early stopping\n",
      "Training round 32\n",
      "Validation loss 0.9996140701850688 NOT improved\n",
      "Validation loss 0.9997695293977514 NOT improved\n",
      "Validation loss 0.9998348843075817 NOT improved\n",
      "Validation loss 0.9998722297420932 NOT improved\n",
      "Validation loss 0.9998966862675048 NOT improved\n",
      "Validation loss 0.9999024606048442 NOT improved\n",
      "Validation loss 0.9999164921896233 NOT improved\n",
      "Validation loss 0.9999142290059122 NOT improved\n",
      "Validation loss 0.9999133402465146 NOT improved\n",
      "Validation loss 0.9999139956226898 NOT improved\n",
      "Validation loss 0.9999168550181246 NOT improved\n",
      "Validation loss 0.9999059562287543 NOT improved\n",
      "Validation loss 0.9998956265806506 NOT improved\n",
      "Validation loss 0.9998852182397674 NOT improved\n",
      "Validation loss 0.9998458646568278 NOT improved\n",
      "Validation loss 0.9998524610703458 NOT improved\n",
      "Validation loss 0.9998386264848885 NOT improved\n",
      "Validation loss 0.9997405183947028 NOT improved\n",
      "Validation loss 0.9997203004602817 NOT improved\n",
      "Validation loss 0.9997298000781165 NOT improved\n",
      "Validation loss 0.9994022802062765 NOT improved\n",
      "Validation loss 0.9989862939987832 NOT improved\n",
      "Validation loss 0.9990371071888416 NOT improved\n",
      "Validation loss 0.9994801452870954 NOT improved\n",
      "Validation loss 0.9983708774138554 NOT improved\n",
      "Validation loss 0.997950820287319 NOT improved\n",
      "Validation loss 0.9919167770389573 NOT improved\n",
      "Validation loss 0.9981342074349099 NOT improved\n",
      "Validation loss 0.9762162396860501 NOT improved\n",
      "Validation loss 0.9952633497161496 NOT improved\n",
      "Validation loss 0.99795408038951 NOT improved\n",
      "Validation loss 0.9858837427638228 NOT improved\n",
      "Validation loss 0.9669379784207742 NOT improved\n",
      "Validation loss 0.9534426211547878 NOT improved\n",
      "Validation loss 0.9394759404727353 NOT improved\n",
      "Validation loss 0.947947577511445 NOT improved\n",
      "Validation loss 0.9515995349278867 NOT improved\n",
      "Validation loss 0.8971531240514798 NOT improved\n",
      "Validation loss 0.9527939141186607 NOT improved\n",
      "Validation loss 1.872383166285162 NOT improved\n",
      "Early stopping\n",
      "Training round 33\n",
      "Validation loss 0.999650120648915 NOT improved\n",
      "Validation loss 0.9997466685939495 NOT improved\n",
      "Validation loss 0.9998280033652036 NOT improved\n",
      "Validation loss 0.9998629527813769 NOT improved\n",
      "Validation loss 0.9998823662955892 NOT improved\n",
      "Validation loss 0.9998937394774892 NOT improved\n",
      "Validation loss 0.9998947607497164 NOT improved\n",
      "Validation loss 0.9998947235633734 NOT improved\n",
      "Validation loss 0.9998849140665025 NOT improved\n",
      "Validation loss 0.9998547448570552 NOT improved\n",
      "Validation loss 0.9998510563930827 NOT improved\n",
      "Validation loss 0.999825736543945 NOT improved\n",
      "Validation loss 0.9998352299030588 NOT improved\n",
      "Validation loss 0.9998004930486885 NOT improved\n",
      "Validation loss 0.9997857297220726 NOT improved\n",
      "Validation loss 0.9997153951092217 NOT improved\n",
      "Validation loss 0.9996725704391446 NOT improved\n",
      "Validation loss 0.999557605788717 NOT improved\n",
      "Validation loss 0.9996298769941535 NOT improved\n",
      "Validation loss 0.9987804948210981 NOT improved\n",
      "Validation loss 0.9990147187968639 NOT improved\n",
      "Validation loss 0.9982089892867688 NOT improved\n",
      "Validation loss 0.9985135891163864 NOT improved\n",
      "Validation loss 0.9985551960733143 NOT improved\n",
      "Validation loss 0.9954129357299613 NOT improved\n",
      "Validation loss 0.9942095904501116 NOT improved\n",
      "Validation loss 0.9930329289248333 NOT improved\n",
      "Validation loss 0.9916492584129231 NOT improved\n",
      "Validation loss 0.993492076323023 NOT improved\n",
      "Validation loss 0.9963218794006057 NOT improved\n",
      "Validation loss 0.9739157453899657 NOT improved\n",
      "Validation loss 0.9913244421137833 NOT improved\n",
      "Validation loss 0.8518577953223072 NOT improved\n",
      "Validation loss 0.8772332090035533 NOT improved\n",
      "Validation loss 0.9666809554877719 NOT improved\n",
      "Validation loss 0.9210368318810506 NOT improved\n",
      "Validation loss 0.953869077556364 NOT improved\n",
      "Validation loss 0.9723999744177502 NOT improved\n",
      "Validation loss 0.8373738519436095 NOT improved\n",
      "Validation loss 0.9177679010915611 NOT improved\n",
      "Validation loss 0.9331145855111235 NOT improved\n",
      "Validation loss 0.8881698682035695 NOT improved\n",
      "Validation loss 0.953902674331546 NOT improved\n",
      "Validation loss 0.8657821490092336 NOT improved\n",
      "Validation loss 0.9337586536684177 NOT improved\n",
      "Validation loss 0.8896817926382322 NOT improved\n",
      "Validation loss 0.8725557723276016 NOT improved\n",
      "Validation loss 0.9116588136754791 NOT improved\n",
      "Validation loss 0.978055566631904 NOT improved\n",
      "Validation loss 0.9423077256171025 NOT improved\n",
      "Validation loss 1.1506087523603994 NOT improved\n",
      "Early stopping\n",
      "Training round 34\n",
      "Validation loss 0.9996458697008084 NOT improved\n",
      "Validation loss 0.9997827256251625 NOT improved\n",
      "Validation loss 0.9998228921698981 NOT improved\n",
      "Validation loss 0.999845155748356 NOT improved\n",
      "Validation loss 0.9998574089652104 NOT improved\n",
      "Validation loss 0.9998498389458809 NOT improved\n",
      "Validation loss 0.999837675226851 NOT improved\n",
      "Validation loss 0.999838204061476 NOT improved\n",
      "Validation loss 0.9998279863440331 NOT improved\n",
      "Validation loss 0.9998313348184019 NOT improved\n",
      "Validation loss 0.999792961777019 NOT improved\n",
      "Validation loss 0.9997722606427862 NOT improved\n",
      "Validation loss 0.999725251745121 NOT improved\n",
      "Validation loss 0.999681160947118 NOT improved\n",
      "Validation loss 0.9996517298867783 NOT improved\n",
      "Validation loss 0.9996401689882585 NOT improved\n",
      "Validation loss 0.9994614310081459 NOT improved\n",
      "Validation loss 0.9991974397809874 NOT improved\n",
      "Validation loss 0.999216546580336 NOT improved\n",
      "Validation loss 0.9992019089286723 NOT improved\n",
      "Validation loss 0.9984946290168447 NOT improved\n",
      "Validation loss 0.995163085676049 NOT improved\n",
      "Validation loss 0.9967424969037824 NOT improved\n",
      "Validation loss 0.9943796956921599 NOT improved\n",
      "Validation loss 0.992580769237673 NOT improved\n",
      "Validation loss 0.9974966974806445 NOT improved\n",
      "Validation loss 0.9978770073000348 NOT improved\n",
      "Validation loss 0.9922747496970679 NOT improved\n",
      "Validation loss 0.9826675698796132 NOT improved\n",
      "Validation loss 0.9464472587576228 NOT improved\n",
      "Validation loss 0.9746965855653372 NOT improved\n",
      "Validation loss 0.9842474652661535 NOT improved\n",
      "Validation loss 0.9639031677093806 NOT improved\n",
      "Validation loss 0.9554215946427677 NOT improved\n",
      "Validation loss 0.9735381144686537 NOT improved\n",
      "Validation loss 0.9164348193775318 NOT improved\n",
      "Validation loss 0.9113064000019718 NOT improved\n",
      "Validation loss 0.9625091526096441 NOT improved\n",
      "Validation loss 0.933835616296015 NOT improved\n",
      "Validation loss 0.9311329743656621 NOT improved\n",
      "Validation loss 0.9565993515688491 NOT improved\n",
      "Validation loss 1.6792571389136806 NOT improved\n",
      "Early stopping\n",
      "Training round 35\n",
      "Validation loss 0.9996006667353149 NOT improved\n",
      "Validation loss 0.9997613571625047 NOT improved\n",
      "Validation loss 0.9998276571541095 NOT improved\n",
      "Validation loss 0.9998617040437346 NOT improved\n",
      "Validation loss 0.9998880976108309 NOT improved\n",
      "Validation loss 0.9999016533174971 NOT improved\n",
      "Validation loss 0.9999100349274636 NOT improved\n",
      "Validation loss 0.9999120768835487 NOT improved\n",
      "Validation loss 0.9999101241519094 NOT improved\n",
      "Validation loss 0.9999085873563067 NOT improved\n",
      "Validation loss 0.9999083873986925 NOT improved\n",
      "Validation loss 0.9999057109280974 NOT improved\n",
      "Validation loss 0.9998860891238 NOT improved\n",
      "Validation loss 0.9998734563441272 NOT improved\n",
      "Validation loss 0.9998706326280242 NOT improved\n",
      "Validation loss 0.9998070855629645 NOT improved\n",
      "Validation loss 0.999799907568464 NOT improved\n",
      "Validation loss 0.9997615749487702 NOT improved\n",
      "Validation loss 0.9996767196068004 NOT improved\n",
      "Validation loss 0.9992158918161702 NOT improved\n",
      "Validation loss 0.9994797701227326 NOT improved\n",
      "Validation loss 0.9995319459324569 NOT improved\n",
      "Validation loss 0.9991721387598973 NOT improved\n",
      "Validation loss 0.9985338414248651 NOT improved\n",
      "Validation loss 0.9986695337357038 NOT improved\n",
      "Validation loss 0.9974825162691678 NOT improved\n",
      "Validation loss 0.9972866838764745 NOT improved\n",
      "Validation loss 0.9943482862302195 NOT improved\n",
      "Validation loss 0.9958211228270964 NOT improved\n",
      "Validation loss 0.9944328518817267 NOT improved\n",
      "Validation loss 0.9732795558087468 NOT improved\n",
      "Validation loss 0.9912575693624613 NOT improved\n",
      "Validation loss 0.9527950117910675 NOT improved\n",
      "Validation loss 0.9677659774187025 NOT improved\n",
      "Validation loss 0.9757535982596658 NOT improved\n",
      "Validation loss 0.9055260777210374 NOT improved\n",
      "Validation loss 0.9478342997276336 NOT improved\n",
      "Validation loss 0.9603438239671059 NOT improved\n",
      "Validation loss 0.9294626800459155 NOT improved\n",
      "Validation loss 0.8804841863162927 NOT improved\n",
      "Validation loss 0.9821100954789063 NOT improved\n",
      "Validation loss 0.9753918942254203 NOT improved\n",
      "Validation loss 0.888481284164233 NOT improved\n",
      "Validation loss 0.8406340777754157 NOT improved\n",
      "Validation loss 3.971891740352198 NOT improved\n",
      "Early stopping\n",
      "Training round 36\n",
      "Validation loss 0.9997042668468962 NOT improved\n",
      "Validation loss 0.9997913581496894 NOT improved\n",
      "Validation loss 0.9998344693712008 NOT improved\n",
      "Validation loss 0.9998629808663351 NOT improved\n",
      "Validation loss 0.9998779667414677 NOT improved\n",
      "Validation loss 0.9998785574309942 NOT improved\n",
      "Validation loss 0.9998771710648593 NOT improved\n",
      "Validation loss 0.9998736108925376 NOT improved\n",
      "Validation loss 0.9998661140747646 NOT improved\n",
      "Validation loss 0.9998397866652882 NOT improved\n",
      "Validation loss 0.9998388171448561 NOT improved\n",
      "Validation loss 0.999830643995019 NOT improved\n",
      "Validation loss 0.9998332558957721 NOT improved\n",
      "Validation loss 0.9998033303773518 NOT improved\n",
      "Validation loss 0.9997185606844575 NOT improved\n",
      "Validation loss 0.9996501133030872 NOT improved\n",
      "Validation loss 0.9995860260853744 NOT improved\n",
      "Validation loss 0.999502593526765 NOT improved\n",
      "Validation loss 0.9993704175755904 NOT improved\n",
      "Validation loss 0.9993750900438056 NOT improved\n",
      "Validation loss 0.9990701099285287 NOT improved\n",
      "Validation loss 0.9986258359668978 NOT improved\n",
      "Validation loss 0.9989429389956984 NOT improved\n",
      "Validation loss 0.9979740054373462 NOT improved\n",
      "Validation loss 0.9968256616453853 NOT improved\n",
      "Validation loss 0.9925869383379918 NOT improved\n",
      "Validation loss 0.9853977536674633 NOT improved\n",
      "Validation loss 0.9973138081306988 NOT improved\n",
      "Validation loss 0.9934818943067139 NOT improved\n",
      "Validation loss 0.9850997225966831 NOT improved\n",
      "Validation loss 0.9773113620502073 NOT improved\n",
      "Validation loss 0.990468583415651 NOT improved\n",
      "Validation loss 0.9842793515167301 NOT improved\n",
      "Validation loss 0.9870100203642245 NOT improved\n",
      "Validation loss 0.9909532358221639 NOT improved\n",
      "Validation loss 0.892367765790094 NOT improved\n",
      "Validation loss 0.9620798782883582 NOT improved\n",
      "Validation loss 0.987048106587595 NOT improved\n",
      "Validation loss 0.9527216053717344 NOT improved\n",
      "Validation loss 0.8677119673728124 NOT improved\n",
      "Validation loss 0.9012318277046498 NOT improved\n",
      "Validation loss 0.9378450309817545 NOT improved\n",
      "Validation loss 0.9522300519343475 NOT improved\n",
      "Validation loss 0.9048099325898554 NOT improved\n",
      "Validation loss 0.8551379678313712 NOT improved\n",
      "Validation loss 0.8631568269081819 NOT improved\n",
      "Validation loss 0.8612373715490534 NOT improved\n",
      "Validation loss 0.8586334931280751 NOT improved\n",
      "Validation loss 0.8513057353574072 NOT improved\n",
      "Validation loss 0.9526785655993888 NOT improved\n",
      "Validation loss 0.8501344584288324 NOT improved\n",
      "Validation loss 0.877153690553456 NOT improved\n",
      "Validation loss 0.8442711734016772 NOT improved\n",
      "Validation loss 0.8803956966564451 NOT improved\n",
      "Validation loss 0.9664782212421795 NOT improved\n",
      "Validation loss 1.0521698451582802 NOT improved\n",
      "Early stopping\n",
      "Training round 37\n",
      "Validation loss 0.9995660809722289 NOT improved\n",
      "Validation loss 0.9997472683048533 NOT improved\n",
      "Validation loss 0.9998258232633599 NOT improved\n",
      "Validation loss 0.9998631547628131 NOT improved\n",
      "Validation loss 0.9998858153868024 NOT improved\n",
      "Validation loss 0.9999000480413759 NOT improved\n",
      "Validation loss 0.9999108527411327 NOT improved\n",
      "Validation loss 0.9999178340374978 NOT improved\n",
      "Validation loss 0.9999226697911692 NOT improved\n",
      "Validation loss 0.999909980241404 NOT improved\n",
      "Validation loss 0.9999098676698943 NOT improved\n",
      "Validation loss 0.999894509797177 NOT improved\n",
      "Validation loss 0.9998883800246088 NOT improved\n",
      "Validation loss 0.9998947708203239 NOT improved\n",
      "Validation loss 0.9998850672993178 NOT improved\n",
      "Validation loss 0.9998273956063805 NOT improved\n",
      "Validation loss 0.9997687818404551 NOT improved\n",
      "Validation loss 0.9998154202358454 NOT improved\n",
      "Validation loss 0.9997370762786659 NOT improved\n",
      "Validation loss 0.9995206101285278 NOT improved\n",
      "Validation loss 0.9996444694934814 NOT improved\n",
      "Validation loss 0.9995083153999506 NOT improved\n",
      "Validation loss 0.9994037148823615 NOT improved\n",
      "Validation loss 0.9985538660822957 NOT improved\n",
      "Validation loss 0.9993874973930252 NOT improved\n",
      "Validation loss 0.9984497967503086 NOT improved\n",
      "Validation loss 0.9978318395233325 NOT improved\n",
      "Validation loss 0.9963072708962822 NOT improved\n",
      "Validation loss 0.997010286346058 NOT improved\n",
      "Validation loss 0.9946694186796742 NOT improved\n",
      "Validation loss 0.9970832216011601 NOT improved\n",
      "Validation loss 0.9944397205720478 NOT improved\n",
      "Validation loss 0.9480768727431685 NOT improved\n",
      "Validation loss 0.9311769860329572 NOT improved\n",
      "Validation loss 0.9498048603873284 NOT improved\n",
      "Validation loss 0.923728820175346 NOT improved\n",
      "Validation loss 0.985198605077517 NOT improved\n",
      "Validation loss 0.9153872137205643 NOT improved\n",
      "Validation loss 0.9888001632064518 NOT improved\n",
      "Validation loss 0.9816206624415773 NOT improved\n",
      "Validation loss 0.8544827105276981 NOT improved\n",
      "Validation loss 0.8618138883955324 NOT improved\n",
      "Validation loss 0.9601386619487017 NOT improved\n",
      "Validation loss 0.9104160509264375 NOT improved\n",
      "Validation loss 1.46196529345089 NOT improved\n",
      "Early stopping\n",
      "Training round 38\n",
      "Validation loss 0.9997414150156234 NOT improved\n",
      "Validation loss 0.9998280845027163 NOT improved\n",
      "Validation loss 0.9998622148041761 NOT improved\n",
      "Validation loss 0.9998756076861715 NOT improved\n",
      "Validation loss 0.9998842342942242 NOT improved\n",
      "Validation loss 0.9998930524264772 NOT improved\n",
      "Validation loss 0.9998866800684105 NOT improved\n",
      "Validation loss 0.9998962315921199 NOT improved\n",
      "Validation loss 0.9998863682554335 NOT improved\n",
      "Validation loss 0.9998887908119893 NOT improved\n",
      "Validation loss 0.9998802912471296 NOT improved\n",
      "Validation loss 0.999841674539255 NOT improved\n",
      "Validation loss 0.9998769411060662 NOT improved\n",
      "Validation loss 0.9998398614499204 NOT improved\n",
      "Validation loss 0.9998217441728523 NOT improved\n",
      "Validation loss 0.9997032459556568 NOT improved\n",
      "Validation loss 0.9997026520940869 NOT improved\n",
      "Validation loss 0.999700487847459 NOT improved\n",
      "Validation loss 0.9997257090488416 NOT improved\n",
      "Validation loss 0.999705851824601 NOT improved\n",
      "Validation loss 0.9994677817426437 NOT improved\n",
      "Validation loss 0.9987918974670316 NOT improved\n",
      "Validation loss 0.9991211389842579 NOT improved\n",
      "Validation loss 0.9989675108816106 NOT improved\n",
      "Validation loss 0.9983855271434513 NOT improved\n",
      "Validation loss 0.9970036397819092 NOT improved\n",
      "Validation loss 0.9986218085447262 NOT improved\n",
      "Validation loss 0.9763227107353026 NOT improved\n",
      "Validation loss 0.9894032505601308 NOT improved\n",
      "Validation loss 0.9877645284718476 NOT improved\n",
      "Validation loss 0.9823676017629893 NOT improved\n",
      "Validation loss 0.9328124989514814 NOT improved\n",
      "Validation loss 0.9784424706437835 NOT improved\n",
      "Validation loss 0.9792529900905874 NOT improved\n",
      "Validation loss 0.9614810699623751 NOT improved\n",
      "Validation loss 0.9505716556573812 NOT improved\n",
      "Validation loss 0.9387006781765178 NOT improved\n",
      "Validation loss 0.987151766863465 NOT improved\n",
      "Validation loss 0.9483219551261367 NOT improved\n",
      "Validation loss 0.9428795654934455 NOT improved\n",
      "Validation loss 0.9196771871066487 NOT improved\n",
      "Validation loss 0.9082163535308901 NOT improved\n",
      "Validation loss 0.9707689545736566 NOT improved\n",
      "Validation loss 0.9840273289845402 NOT improved\n",
      "Validation loss 0.9169426001887696 NOT improved\n",
      "Validation loss 0.8332918444711852 NOT improved\n",
      "Validation loss 0.8480137675841456 NOT improved\n",
      "Validation loss 1.1315449791879193 NOT improved\n",
      "Early stopping\n",
      "Training round 39\n",
      "Validation loss 0.9996847688931496 NOT improved\n",
      "Validation loss 0.9997838256837872 NOT improved\n",
      "Validation loss 0.999824510907736 NOT improved\n",
      "Validation loss 0.9998477116296397 NOT improved\n",
      "Validation loss 0.9998689091358725 NOT improved\n",
      "Validation loss 0.9998814968264143 NOT improved\n",
      "Validation loss 0.9998873720932752 NOT improved\n",
      "Validation loss 0.9998809276644278 NOT improved\n",
      "Validation loss 0.9998938081848275 NOT improved\n",
      "Validation loss 0.9998993477875318 NOT improved\n",
      "Validation loss 0.9998816649915846 NOT improved\n",
      "Validation loss 0.9998938838035244 NOT improved\n",
      "Validation loss 0.9998637800675382 NOT improved\n",
      "Validation loss 0.9998303887283829 NOT improved\n",
      "Validation loss 0.999848951998079 NOT improved\n",
      "Validation loss 0.9998182654520642 NOT improved\n",
      "Validation loss 0.9997774621345736 NOT improved\n",
      "Validation loss 0.9998197958233277 NOT improved\n",
      "Validation loss 0.9997122028216415 NOT improved\n",
      "Validation loss 0.9996400345138108 NOT improved\n",
      "Validation loss 0.9996703254756066 NOT improved\n",
      "Validation loss 0.9992103164638175 NOT improved\n",
      "Validation loss 0.9989083896489866 NOT improved\n",
      "Validation loss 0.9979785327690872 NOT improved\n",
      "Validation loss 0.9985387542993055 NOT improved\n",
      "Validation loss 0.9980520593503818 NOT improved\n",
      "Validation loss 0.9957079617288748 NOT improved\n",
      "Validation loss 0.996841676627059 NOT improved\n",
      "Validation loss 0.9962449887667905 NOT improved\n",
      "Validation loss 0.977830694351979 NOT improved\n",
      "Validation loss 0.9922767845714867 NOT improved\n",
      "Validation loss 0.8963361597593783 NOT improved\n",
      "Validation loss 0.9688616191615116 NOT improved\n",
      "Validation loss 0.9560850894860246 NOT improved\n",
      "Validation loss 0.9649050449869729 NOT improved\n",
      "Validation loss 0.9572683891117155 NOT improved\n",
      "Validation loss 0.8849315145873121 NOT improved\n",
      "Validation loss 0.9788738943720084 NOT improved\n",
      "Validation loss 0.9925841307466058 NOT improved\n",
      "Validation loss 0.9567349178160947 NOT improved\n",
      "Validation loss 0.8787876732850944 NOT improved\n",
      "Validation loss 0.9045448609811201 NOT improved\n",
      "Validation loss 1.0303271799133304 NOT improved\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "seeds = [12342, 2536234, 98765, 473, 865, 7456, 69472, 3456357, 3425, 678,\n",
    "         2452624, 5787, 235362, 67896, 98454, 12445, 46767, 78906, 345, 8695, \n",
    "         2463725, 4734, 23234, 884, 2341, 362, 5, 234, 483, 785356, 23425, 3621, \n",
    "         58461, 80968765, 123, 425633, 5646, 67635, 76785, 34214]\n",
    "\n",
    "training_rounds = len(seeds)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "\n",
    "# =========== Model Section ========== #\n",
    "\n",
    "batch_dir = '/glade/scratch/ksha/DATA/NCAR_batch/'\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = '{}_lead{}'.format(model_tag, lead_name)\n",
    "\n",
    "model_name = '{}'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "tol = 0\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "L_pos = len(TRAIN_256_pos)\n",
    "L_neg = len(TRAIN_256_neg)\n",
    "\n",
    "record = 1.1\n",
    "print(\"Initial record: {}\".format(record))\n",
    "\n",
    "min_del = 0\n",
    "max_tol = 100 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "L_train = 16\n",
    "\n",
    "for r in range(training_rounds):\n",
    "    if r == 0:\n",
    "        tol = 0\n",
    "    else:\n",
    "        tol = -200\n",
    "\n",
    "    model = create_model()\n",
    "    #\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4))\n",
    "    \n",
    "    set_seeds(int(seeds[r]))\n",
    "    print('Training round {}'.format(r))\n",
    "\n",
    "    for i in range(epochs):            \n",
    "        start_time = time.time()\n",
    "\n",
    "        # loop of batch\n",
    "        for j in range(L_train):\n",
    "            N_pos = 32\n",
    "            N_neg = batch_size - N_pos\n",
    "\n",
    "            ind_neg = du.shuffle_ind(L_neg)\n",
    "            ind_pos = du.shuffle_ind(L_pos)\n",
    "\n",
    "            ind_neg_pick = ind_neg[:N_neg]\n",
    "            ind_pos_pick = ind_pos[:N_pos]\n",
    "\n",
    "            X_batch_neg = TRAIN_256_neg[ind_neg_pick, :]\n",
    "            X_batch_pos = TRAIN_256_pos[ind_pos_pick, :]\n",
    "            \n",
    "            X_batch_stn_neg = TRAIN_stn_neg[ind_neg_pick, :]\n",
    "            X_batch_stn_pos = TRAIN_stn_pos[ind_pos_pick, :]\n",
    "\n",
    "            X_batch = np.concatenate((X_batch_neg, X_batch_pos), axis=0)\n",
    "            X_batch_stn = np.concatenate((X_batch_stn_neg, X_batch_stn_pos), axis=0)\n",
    "\n",
    "            Y_batch = np.ones([batch_size,])\n",
    "            Y_batch[:N_neg] = 0.0\n",
    "\n",
    "            ind_ = du.shuffle_ind(batch_size)\n",
    "\n",
    "            X_batch = X_batch[ind_, :]\n",
    "            X_batch_stn = X_batch_stn[ind_, :]\n",
    "            Y_batch = Y_batch[ind_]\n",
    "\n",
    "            # train on batch\n",
    "            model.train_on_batch([X_batch, X_batch_stn], Y_batch);\n",
    "\n",
    "        # epoch end operations\n",
    "        Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "\n",
    "        Y_pred[Y_pred<0] = 0\n",
    "        Y_pred[Y_pred>1] = 1\n",
    "\n",
    "        record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n",
    "        # if i % 10 == 0:\n",
    "        #     model.save(model_path_backup)\n",
    "\n",
    "        if (record - record_temp > min_del):\n",
    "            print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "            record = record_temp\n",
    "            tol = 0\n",
    "            \n",
    "            #print('tol: {}'.format(tol))\n",
    "            # save\n",
    "            print('save to: {}'.format(model_path))\n",
    "            model.save(model_path)\n",
    "        else:\n",
    "            print('Validation loss {} NOT improved'.format(record_temp))\n",
    "            if record_temp > 1.01:\n",
    "                print('Early stopping')\n",
    "                break;\n",
    "            else:\n",
    "                tol += 1\n",
    "                if tol >= max_tol:\n",
    "                    print('Early stopping')\n",
    "                    break;\n",
    "                else:\n",
    "                    continue;\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba732cc-cef9-43ff-89ff-0fb00f59075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964176a0-95be-4e49-81c4-7a659751d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199f0a-0bd1-490b-b929-922a8a39a1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427b0011-7eee-4cca-a80a-ed37a18c5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=keras.optimizers.Adam(lr=0))\n",
    "\n",
    "W_old = k_utils.dummy_loader('/glade/work/ksha/NCAR/Keras_models/alt_lead{}/'.format(lead_name))\n",
    "model.set_weights(W_old)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb05d2d-092a-4702-a245-fea6f96ffe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/NCAR/RESULT_FULL_lead2_alt.npy\n"
     ]
    }
   ],
   "source": [
    "save_dict = {}\n",
    "save_dict['Y_pred'] = Y_pred\n",
    "save_dict['VALID_Y'] = VALID_Y\n",
    "np.save('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag), save_dict)\n",
    "print('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60af67c-8780-42cf-ab0a-d6434b1b5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8280119062518958"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b4252-b6b6-441e-abb0-c0bca38f3471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ec269e-6211-4a90-a8d9-fa78fc3f33ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b762c820d60>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94898f-0118-4b3e-91e7-c7b8f07b5187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a664b-35c5-4d13-bd1d-63fdfac63233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469f1cd-f820-44a1-9ba6-4f228782f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba0e7c-4640-4e65-b675-995d3a1a06d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e5327-70b2-4ba4-94bc-f1e37f04bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d4ab4-6e8d-49fb-adb5-29205a17e6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf3bf0-b6ad-4be6-b2f4-3bead7aaa672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b6f27-7551-4a81-8669-3482c0da28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca671f-cd07-4052-85c6-10c359bc8c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
