{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35ec06d-99e2-426d-8350-28623a7ed5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:21:09.348688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from keras_unet_collection import utils as k_utils\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "import re\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('lead1', help='lead')\n",
    "# parser.add_argument('lead2', help='lead')\n",
    "# parser.add_argument('lead3', help='lead')\n",
    "# parser.add_argument('lead4', help='lead')\n",
    "# parser.add_argument('lead_name', help='lead')\n",
    "# parser.add_argument('model_tag', help='lead')\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "lead1 = 2 #int(args['lead1'])\n",
    "lead2 = 3 #int(args['lead2'])\n",
    "\n",
    "lead_name = 2 #int(args['lead_name'])\n",
    "model_tag = 're' #args['model_tag']\n",
    "\n",
    "filepath_vec = \"/glade/work/ksha/NCAR/\"\n",
    "\n",
    "if (lead1 < 9) or (lead1 > 18):\n",
    "    path_name1 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name1 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "if (lead2 < 9) or (lead2 > 18):\n",
    "    path_name2 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name2 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "    \n",
    "# if (lead3 < 9) or (lead3 > 18):\n",
    "#     path_name3 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "# else:\n",
    "#     path_name3 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "    \n",
    "# if (lead4 < 9) or (lead4 > 18):\n",
    "#     path_name4 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "# else:\n",
    "#     path_name4 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred, ref):\n",
    "    BS = np.mean((VALID_target.ravel() - Y_pred.ravel())**2)\n",
    "    metric = BS\n",
    "    return metric / ref\n",
    "\n",
    "def feature_extract(filenames, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max):\n",
    "    \n",
    "    lon_out = []\n",
    "    lat_out = []\n",
    "    elev_out = []\n",
    "    mon_out = []\n",
    "    \n",
    "    base_v3_s = datetime(2018, 7, 15)\n",
    "    base_v3_e = datetime(2020, 12, 2)\n",
    "\n",
    "    base_v4_s = datetime(2020, 12, 3)\n",
    "    base_v4_e = datetime(2022, 7, 15)\n",
    "\n",
    "    base_ref = datetime(2010, 1, 1)\n",
    "    \n",
    "    date_list_v3 = [base_v3_s + timedelta(days=day) for day in range(365+365+142)]\n",
    "    date_list_v4 = [base_v4_s + timedelta(days=day) for day in range(365+180-151)]\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        if 'v4' in name:\n",
    "            date_list = date_list_v4\n",
    "        else:\n",
    "            date_list = date_list_v3\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "        day = date_list[day]\n",
    "        month = day.month\n",
    "        \n",
    "        month_norm = (month - 1)/(12-1)\n",
    "        \n",
    "        lon = lon_80km[indx, indy]\n",
    "        lat = lat_80km[indx, indy]\n",
    "\n",
    "        lon = (lon - lon_minmax[0])/(lon_minmax[1] - lon_minmax[0])\n",
    "        lat = (lat - lat_minmax[0])/(lat_minmax[1] - lat_minmax[0])\n",
    "\n",
    "        elev = elev_80km[indx, indy]\n",
    "        elev = elev / elev_max\n",
    "        \n",
    "        lon_out.append(lon)\n",
    "        lat_out.append(lat)\n",
    "        elev_out.append(elev)\n",
    "        mon_out.append(month_norm)\n",
    "        \n",
    "    return np.array(lon_out), np.array(lat_out), np.array(elev_out), np.array(mon_out)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    \n",
    "    IN_vec = keras.Input((256,))    \n",
    "    IN_elev = keras.Input((3,))\n",
    "    IN = keras.layers.Concatenate()([IN_vec, IN_elev])\n",
    "    \n",
    "    X = IN\n",
    "    #\n",
    "    X = keras.layers.Dense(1024, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(512, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(128, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    OUT = X\n",
    "    OUT = keras.layers.Dense(1, activation='sigmoid', bias_initializer=keras.initializers.Constant(-10))(OUT)\n",
    "\n",
    "    model = keras.models.Model(inputs=[IN_vec, IN_elev], outputs=OUT)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f933e6-fcb7-4e02-9bb6-c3d33b4ff170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]\n",
    "    elev_3km = h5io['elev_3km'][...]\n",
    "    land_mask_80km = h5io['land_mask_80km'][...]\n",
    "    \n",
    "grid_shape = land_mask_80km.shape\n",
    "\n",
    "elev_80km = du.interp2d_wraper(lon_3km, lat_3km, elev_3km, lon_80km, lat_80km, method='linear')\n",
    "\n",
    "elev_80km[np.isnan(elev_80km)] = 0\n",
    "elev_80km[elev_80km<0] = 0\n",
    "elev_max = np.max(elev_80km)\n",
    "\n",
    "lon_80km_mask = lon_80km[land_mask_80km]\n",
    "lat_80km_mask = lat_80km[land_mask_80km]\n",
    "\n",
    "lon_minmax = [np.min(lon_80km_mask), np.max(lon_80km_mask)]\n",
    "lat_minmax = [np.min(lat_80km_mask), np.max(lat_80km_mask)]\n",
    "\n",
    "filename_train_lead1 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_train_lead2 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name2, lead2)))\n",
    "# filename_train_lead3 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name3, lead3)))\n",
    "# filename_train_lead4 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name4, lead4)))\n",
    "\n",
    "IND_TRAIN_lead = np.load('/glade/work/ksha/NCAR/IND_TRAIN_lead_full.npy', allow_pickle=True)[()]\n",
    "TRAIN_ind1 = IND_TRAIN_lead['lead{}'.format(lead1)]\n",
    "TRAIN_ind2 = IND_TRAIN_lead['lead{}'.format(lead2)]\n",
    "# TRAIN_ind3 = IND_TRAIN_lead['lead{}'.format(lead3)]\n",
    "# TRAIN_ind4 = IND_TRAIN_lead['lead{}'.format(lead4)]\n",
    "\n",
    "data_lead1_p0 = np.load('{}TRAIN_v3_vec_lead{}_part0_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p1 = np.load('{}TRAIN_v3_vec_lead{}_part1_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p2 = np.load('{}TRAIN_v3_vec_lead{}_part2_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "data_lead2_p0 = np.load('{}TRAIN_v3_vec_lead{}_part0_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p1 = np.load('{}TRAIN_v3_vec_lead{}_part1_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p2 = np.load('{}TRAIN_v3_vec_lead{}_part2_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "# data_lead3_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# data_lead3_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# data_lead3_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "# data_lead4_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "# data_lead4_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "# data_lead4_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "TRAIN_lead1 = np.concatenate((data_lead1_p0['y_vector'], data_lead1_p1['y_vector'], data_lead1_p2['y_vector']), axis=0)\n",
    "TRAIN_lead2 = np.concatenate((data_lead2_p0['y_vector'], data_lead2_p1['y_vector'], data_lead2_p2['y_vector']), axis=0)\n",
    "# TRAIN_lead3 = np.concatenate((data_lead3_p0['y_vector'], data_lead3_p1['y_vector'], data_lead3_p2['y_vector']), axis=0)\n",
    "# TRAIN_lead4 = np.concatenate((data_lead4_p0['y_vector'], data_lead4_p1['y_vector'], data_lead4_p2['y_vector']), axis=0)\n",
    "\n",
    "TRAIN_lead1_y = np.concatenate((data_lead1_p0['y_true'], data_lead1_p1['y_true'], data_lead1_p2['y_true']), axis=0)\n",
    "TRAIN_lead2_y = np.concatenate((data_lead2_p0['y_true'], data_lead2_p1['y_true'], data_lead2_p2['y_true']), axis=0)\n",
    "# TRAIN_lead3_y = np.concatenate((data_lead3_p0['y_true'], data_lead3_p1['y_true'], data_lead3_p2['y_true']), axis=0)\n",
    "# TRAIN_lead4_y = np.concatenate((data_lead4_p0['y_true'], data_lead4_p1['y_true'], data_lead4_p2['y_true']), axis=0)\n",
    "\n",
    "L = len(TRAIN_ind1)\n",
    "\n",
    "filename_train1_pick = []\n",
    "filename_train2_pick = []\n",
    "# filename_train3_pick = []\n",
    "# filename_train4_pick = []\n",
    "\n",
    "TRAIN_X = np.empty((L, 256))\n",
    "TRAIN_Y = np.empty(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(TRAIN_ind1[i])\n",
    "    ind_lead2 = int(TRAIN_ind2[i])\n",
    "    # ind_lead3 = int(TRAIN_ind3[i])\n",
    "    # ind_lead4 = int(TRAIN_ind4[i])\n",
    "    \n",
    "    filename_train1_pick.append(filename_train_lead1[ind_lead1])\n",
    "    filename_train2_pick.append(filename_train_lead2[ind_lead2])\n",
    "    # filename_train3_pick.append(filename_train_lead3[ind_lead3])\n",
    "    # filename_train4_pick.append(filename_train_lead4[ind_lead4])\n",
    "    \n",
    "    TRAIN_X[i, 0:128]   = TRAIN_lead1[ind_lead1, :]\n",
    "    TRAIN_X[i, 128:256] = TRAIN_lead2[ind_lead2, :]\n",
    "    # TRAIN_X[i, 256:384] = TRAIN_lead3[ind_lead3, :]\n",
    "    # TRAIN_X[i, 384:512] = TRAIN_lead4[ind_lead4, :]\n",
    "    \n",
    "    TRAIN_Y[i] = TRAIN_lead1_y[ind_lead1]\n",
    "    \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_train1_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "\n",
    "TRAIN_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "TRAIN_merge = TRAIN_stn\n",
    "\n",
    "TRAIN_256_pos = TRAIN_X[TRAIN_Y==1, :]\n",
    "TRAIN_256_neg = TRAIN_X[TRAIN_Y==0, :]\n",
    "\n",
    "TRAIN_stn_pos = TRAIN_merge[TRAIN_Y==1]\n",
    "TRAIN_stn_neg = TRAIN_merge[TRAIN_Y==0]\n",
    "\n",
    "filename_valid_lead1 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_valid_lead2 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name2, lead2)))\n",
    "# filename_valid_lead3 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name3, lead3)))\n",
    "# filename_valid_lead4 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name4, lead4)))\n",
    "\n",
    "valid_lead1 = np.load('{}VALID_v3_vec_lead{}_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "valid_lead2 = np.load('{}VALID_v3_vec_lead{}_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "# valid_lead3 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "# valid_lead4 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead4, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "VALID_lead1 = valid_lead1['y_vector']\n",
    "VALID_lead2 = valid_lead2['y_vector']\n",
    "# VALID_lead3 = valid_lead3['y_vector']\n",
    "# VALID_lead4 = valid_lead4['y_vector']\n",
    "\n",
    "VALID_lead1_y = valid_lead1['y_true']\n",
    "VALID_lead2_y = valid_lead2['y_true']\n",
    "# VALID_lead3_y = valid_lead3['y_true']\n",
    "# VALID_lead4_y = valid_lead4['y_true']\n",
    "\n",
    "IND_VALID_lead = np.load('/glade/work/ksha/NCAR/IND_VALID_lead_full.npy', allow_pickle=True)[()]\n",
    "\n",
    "VALID_ind1 = IND_VALID_lead['lead{}'.format(lead1)]\n",
    "VALID_ind2 = IND_VALID_lead['lead{}'.format(lead2)]\n",
    "# VALID_ind3 = IND_VALID_lead['lead{}'.format(lead3)]\n",
    "# VALID_ind4 = IND_VALID_lead['lead{}'.format(lead4)]\n",
    "\n",
    "L = len(VALID_ind1)\n",
    "\n",
    "filename_valid1_pick = []\n",
    "filename_valid2_pick = []\n",
    "# filename_valid3_pick = []\n",
    "# filename_valid4_pick = []\n",
    "\n",
    "VALID_X = np.empty((L, 256))\n",
    "VALID_Y = np.zeros(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(VALID_ind1[i])\n",
    "    ind_lead2 = int(VALID_ind2[i])\n",
    "    # ind_lead3 = int(VALID_ind3[i])\n",
    "    # ind_lead4 = int(VALID_ind4[i])\n",
    "    \n",
    "    filename_valid1_pick.append(filename_valid_lead1[ind_lead1])\n",
    "    filename_valid2_pick.append(filename_valid_lead2[ind_lead2])\n",
    "    # filename_valid3_pick.append(filename_valid_lead3[ind_lead3])\n",
    "    # filename_valid4_pick.append(filename_valid_lead4[ind_lead4])\n",
    "    \n",
    "    VALID_X[i, 0:128]   = VALID_lead1[ind_lead1, :]\n",
    "    VALID_X[i, 128:256] = VALID_lead2[ind_lead2, :]\n",
    "    # VALID_X[i, 256:384] = VALID_lead3[ind_lead3, :]\n",
    "    # VALID_X[i, 384:512] = VALID_lead4[ind_lead4, :]\n",
    "    \n",
    "    if 'pos' in filename_valid_lead1[ind_lead1]:\n",
    "        if VALID_lead1_y[ind_lead1] == 1.0:\n",
    "            VALID_Y[i] = 1.0\n",
    "        else:\n",
    "            egwrshat\n",
    "        \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_valid1_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "        \n",
    "VALID_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "VALID_merge = VALID_stn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1cceb-d21e-402f-995b-16ad8f3b8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record: 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:25:10.254711: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-04 15:25:10.256124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-04 15:25:10.309218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-02-04 15:25:10.309266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-04 15:25:10.312699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-04 15:25:10.312765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-02-04 15:25:10.315916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-04 15:25:10.316903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-04 15:25:10.320339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-04 15:25:10.321677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-04 15:25:10.328459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-04 15:25:10.329093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-02-04 15:25:10.329577: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-04 15:25:10.329877: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-04 15:25:10.330241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-02-04 15:25:10.330264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-04 15:25:10.330283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-04 15:25:10.330293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-02-04 15:25:10.330302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-04 15:25:10.330311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-04 15:25:10.330321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-04 15:25:10.330330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-04 15:25:10.330339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-04 15:25:10.330824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-02-04 15:25:10.330869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-04 15:25:10.878862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-04 15:25:10.878900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-02-04 15:25:10.878913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-02-04 15:25:10.879945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:25:12.077453: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-02-04 15:25:12.082258: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2023-02-04 15:25:12.206432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.1 to 0.9997081800433579\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 15:25:18.026839: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 7.626169919967651 seconds ---\n",
      "Validation loss 0.9998035204886965 NOT improved\n",
      "Validation loss 0.9998534800467924 NOT improved\n",
      "Validation loss 0.999882676086494 NOT improved\n",
      "Validation loss 0.9998980581013036 NOT improved\n",
      "Validation loss 0.999904231563084 NOT improved\n",
      "Validation loss 0.9999071415669977 NOT improved\n",
      "Validation loss 0.9999024097249625 NOT improved\n",
      "Validation loss 0.999893487029953 NOT improved\n",
      "Validation loss 0.9998941580766277 NOT improved\n",
      "Validation loss 0.9998879243520291 NOT improved\n",
      "Validation loss 0.9998794482594608 NOT improved\n",
      "Validation loss 0.9998778246528526 NOT improved\n",
      "Validation loss 0.999831341553201 NOT improved\n",
      "Validation loss 0.9998123957297986 NOT improved\n",
      "Validation loss 0.9998172604696132 NOT improved\n",
      "Validation loss 0.9997371677415177 NOT improved\n",
      "Validation loss 0.9997378812667561 NOT improved\n",
      "Validation loss improved from 0.9997081800433579 to 0.9997048344570744\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 17.11531972885132 seconds ---\n",
      "Validation loss improved from 0.9997048344570744 to 0.999494834459791\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.79071569442749 seconds ---\n",
      "Validation loss 0.9995816941946412 NOT improved\n",
      "Validation loss improved from 0.999494834459791 to 0.999365107306022\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.272868394851685 seconds ---\n",
      "Validation loss improved from 0.999365107306022 to 0.9991196143020579\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.745182275772095 seconds ---\n",
      "Validation loss improved from 0.9991196143020579 to 0.9987572414000035\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.2511069774627686 seconds ---\n",
      "Validation loss improved from 0.9987572414000035 to 0.9951947874125542\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.605045795440674 seconds ---\n",
      "Validation loss 0.998553562313796 NOT improved\n",
      "Validation loss 0.9984633744662761 NOT improved\n",
      "Validation loss improved from 0.9951947874125542 to 0.9938682611806396\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.276809215545654 seconds ---\n",
      "Validation loss 0.9979930516945433 NOT improved\n",
      "Validation loss improved from 0.9938682611806396 to 0.987016969411852\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.661565780639648 seconds ---\n",
      "Validation loss improved from 0.987016969411852 to 0.9814636009458624\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.255524158477783 seconds ---\n",
      "Validation loss 0.9869520776303269 NOT improved\n",
      "Validation loss improved from 0.9814636009458624 to 0.9365896439972929\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.6247851848602295 seconds ---\n",
      "Validation loss 0.9895528537560992 NOT improved\n",
      "Validation loss 0.9849711485256288 NOT improved\n",
      "Validation loss 0.9786263327272705 NOT improved\n",
      "Validation loss improved from 0.9365896439972929 to 0.8567655548375712\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.5734946727752686 seconds ---\n",
      "Validation loss 0.9804483072957211 NOT improved\n",
      "Validation loss 0.9042522297316975 NOT improved\n",
      "Validation loss 0.9713990395626249 NOT improved\n",
      "Validation loss improved from 0.8567655548375712 to 0.8381027625445737\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.285298824310303 seconds ---\n",
      "Validation loss 0.9643842704007377 NOT improved\n",
      "Validation loss 0.8689769865344313 NOT improved\n",
      "Validation loss 0.9210607326411983 NOT improved\n",
      "Validation loss 1.4494259845450046 NOT improved\n",
      "Early stopping\n",
      "Training round 1\n",
      "Validation loss 0.9997917656203047 NOT improved\n",
      "Validation loss 0.9998138155781954 NOT improved\n",
      "Validation loss 0.999847259751526 NOT improved\n",
      "Validation loss 0.9998669163605011 NOT improved\n",
      "Validation loss 0.9998773751000263 NOT improved\n",
      "Validation loss 0.9998904266641206 NOT improved\n",
      "Validation loss 0.9998875496231245 NOT improved\n",
      "Validation loss 0.9998860752998597 NOT improved\n",
      "Validation loss 0.9998827232307939 NOT improved\n",
      "Validation loss 0.9998827036982678 NOT improved\n",
      "Validation loss 0.9998767624687781 NOT improved\n",
      "Validation loss 0.9998593631577919 NOT improved\n",
      "Validation loss 0.9998390979904633 NOT improved\n",
      "Validation loss 0.9998240991226939 NOT improved\n",
      "Validation loss 0.9998209974371106 NOT improved\n",
      "Validation loss 0.9997952309800097 NOT improved\n",
      "Validation loss 0.9997838278531326 NOT improved\n",
      "Validation loss 0.9995750305635299 NOT improved\n",
      "Validation loss 0.9996644624296592 NOT improved\n",
      "Validation loss 0.9996198408394981 NOT improved\n",
      "Validation loss 0.99951958271711 NOT improved\n",
      "Validation loss 0.9992909211265154 NOT improved\n",
      "Validation loss 0.9987318633271182 NOT improved\n",
      "Validation loss 0.9987181924578491 NOT improved\n",
      "Validation loss 0.9990948932521043 NOT improved\n",
      "Validation loss 0.9971891069877047 NOT improved\n",
      "Validation loss 0.9975143367067222 NOT improved\n",
      "Validation loss 0.9971493179276478 NOT improved\n",
      "Validation loss 0.9971725697787008 NOT improved\n",
      "Validation loss 0.9823717186372567 NOT improved\n",
      "Validation loss 0.9965540934912346 NOT improved\n",
      "Validation loss 0.9794968193348277 NOT improved\n",
      "Validation loss 0.9795367018151162 NOT improved\n",
      "Validation loss 0.9817905224493658 NOT improved\n",
      "Validation loss 0.9363310452903005 NOT improved\n",
      "Validation loss 0.9489801472085663 NOT improved\n",
      "Validation loss 1.0852135122827018 NOT improved\n",
      "Early stopping\n",
      "Training round 2\n",
      "Validation loss 0.9998132696450718 NOT improved\n",
      "Validation loss 0.9998384283867717 NOT improved\n",
      "Validation loss 0.9998528598375095 NOT improved\n",
      "Validation loss 0.9998616125163027 NOT improved\n",
      "Validation loss 0.9998722299293901 NOT improved\n",
      "Validation loss 0.9998658466965691 NOT improved\n",
      "Validation loss 0.9998608869925872 NOT improved\n",
      "Validation loss 0.9998401049843427 NOT improved\n",
      "Validation loss 0.9998423428550441 NOT improved\n",
      "Validation loss 0.9998318003026464 NOT improved\n",
      "Validation loss 0.9998263983218765 NOT improved\n",
      "Validation loss 0.9997846931551123 NOT improved\n",
      "Validation loss 0.9997717692420692 NOT improved\n",
      "Validation loss 0.9997713973292242 NOT improved\n",
      "Validation loss 0.9997383250908951 NOT improved\n",
      "Validation loss 0.9996841597108554 NOT improved\n",
      "Validation loss 0.9996263524616023 NOT improved\n",
      "Validation loss 0.999332347585372 NOT improved\n",
      "Validation loss 0.9994941810342639 NOT improved\n",
      "Validation loss 0.9992197275047996 NOT improved\n",
      "Validation loss 0.9992436601567402 NOT improved\n",
      "Validation loss 0.9988205237271369 NOT improved\n",
      "Validation loss 0.9988074557950639 NOT improved\n",
      "Validation loss 0.998588590608128 NOT improved\n",
      "Validation loss 0.9973216630924228 NOT improved\n",
      "Validation loss 0.9968236278209099 NOT improved\n",
      "Validation loss 0.9962961070464894 NOT improved\n",
      "Validation loss 0.9951222955329178 NOT improved\n",
      "Validation loss 0.9875018394458457 NOT improved\n",
      "Validation loss 0.9933427031434525 NOT improved\n",
      "Validation loss 0.9948255414411268 NOT improved\n",
      "Validation loss 0.9798606572653551 NOT improved\n",
      "Validation loss 0.9905871214204577 NOT improved\n",
      "Validation loss 0.9575182676235933 NOT improved\n",
      "Validation loss 0.9847426064465032 NOT improved\n",
      "Validation loss 0.978587298334372 NOT improved\n",
      "Validation loss 0.980349814763212 NOT improved\n",
      "Validation loss 0.9804759753924331 NOT improved\n",
      "Validation loss 0.911705167507434 NOT improved\n",
      "Validation loss 0.8587286363131494 NOT improved\n",
      "Validation loss 0.8856802932559175 NOT improved\n",
      "Validation loss improved from 0.8381027625445737 to 0.8178174463359887\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/re_lead2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/re_lead2/assets\n",
      "--- 6.663131475448608 seconds ---\n",
      "Validation loss 0.8690181579089681 NOT improved\n",
      "Validation loss 0.8799175398275658 NOT improved\n",
      "Validation loss 0.9890281036898474 NOT improved\n",
      "Validation loss 0.9061710517848982 NOT improved\n",
      "Validation loss 0.9460307183771339 NOT improved\n",
      "Validation loss 0.8268780490898144 NOT improved\n",
      "Validation loss 0.9430030772954598 NOT improved\n",
      "Validation loss 0.9101377789602466 NOT improved\n",
      "Validation loss 0.9147640450798604 NOT improved\n",
      "Validation loss 0.943292093395842 NOT improved\n",
      "Validation loss 3.0996050378719224 NOT improved\n",
      "Early stopping\n",
      "Training round 3\n",
      "Validation loss 0.9997005454435686 NOT improved\n",
      "Validation loss 0.9998074629037678 NOT improved\n",
      "Validation loss 0.999862938947845 NOT improved\n",
      "Validation loss 0.9998886285117794 NOT improved\n",
      "Validation loss 0.9999039389668904 NOT improved\n",
      "Validation loss 0.9999123419316571 NOT improved\n",
      "Validation loss 0.9999083131661366 NOT improved\n",
      "Validation loss 0.9999071470603875 NOT improved\n",
      "Validation loss 0.9999115057163483 NOT improved\n",
      "Validation loss 0.9999044655274016 NOT improved\n",
      "Validation loss 0.9999037286449902 NOT improved\n",
      "Validation loss 0.999890973590894 NOT improved\n",
      "Validation loss 0.999872929510173 NOT improved\n",
      "Validation loss 0.9998589317377072 NOT improved\n",
      "Validation loss 0.9998255570747192 NOT improved\n",
      "Validation loss 0.9997781309470571 NOT improved\n",
      "Validation loss 0.9998234924658796 NOT improved\n",
      "Validation loss 0.9997018625526806 NOT improved\n",
      "Validation loss 0.9996049574440289 NOT improved\n",
      "Validation loss 0.9996405886498101 NOT improved\n",
      "Validation loss 0.9996944830061127 NOT improved\n",
      "Validation loss 0.999122759626049 NOT improved\n",
      "Validation loss 0.9990299372825122 NOT improved\n",
      "Validation loss 0.9991665144116965 NOT improved\n",
      "Validation loss 0.9985358914584845 NOT improved\n",
      "Validation loss 0.9993692748588485 NOT improved\n",
      "Validation loss 0.9987199233928349 NOT improved\n",
      "Validation loss 0.9970738701957079 NOT improved\n",
      "Validation loss 0.9984155124552611 NOT improved\n",
      "Validation loss 0.9906609448857381 NOT improved\n",
      "Validation loss 0.9612041870256849 NOT improved\n",
      "Validation loss 0.9891003220582701 NOT improved\n",
      "Validation loss 0.9829666238694518 NOT improved\n",
      "Validation loss 0.9888731237811551 NOT improved\n",
      "Validation loss 0.8621736408175594 NOT improved\n",
      "Validation loss 0.8573013457316323 NOT improved\n",
      "Validation loss 0.980720474730949 NOT improved\n",
      "Validation loss 0.9701839849536401 NOT improved\n",
      "Validation loss 0.9157106504031934 NOT improved\n",
      "Validation loss 0.9086371707889109 NOT improved\n",
      "Validation loss 0.8688579112250737 NOT improved\n",
      "Validation loss 0.9694477765215566 NOT improved\n",
      "Validation loss 2.120282074636012 NOT improved\n",
      "Early stopping\n",
      "Training round 4\n",
      "Validation loss 0.9997773986575623 NOT improved\n",
      "Validation loss 0.999830654761953 NOT improved\n",
      "Validation loss 0.9998599707481429 NOT improved\n",
      "Validation loss 0.9998765647339589 NOT improved\n",
      "Validation loss 0.9998868362298241 NOT improved\n",
      "Validation loss 0.9998878713341628 NOT improved\n",
      "Validation loss 0.9998927169986056 NOT improved\n",
      "Validation loss 0.9998875126824208 NOT improved\n",
      "Validation loss 0.9998982976546088 NOT improved\n",
      "Validation loss 0.9998684112776449 NOT improved\n",
      "Validation loss 0.9998687590986917 NOT improved\n",
      "Validation loss 0.99985405599626 NOT improved\n",
      "Validation loss 0.9998590904399457 NOT improved\n",
      "Validation loss 0.9998185763445051 NOT improved\n",
      "Validation loss 0.9997706596096604 NOT improved\n",
      "Validation loss 0.9997565959903298 NOT improved\n",
      "Validation loss 0.9997341472766536 NOT improved\n",
      "Validation loss 0.9996236644862212 NOT improved\n",
      "Validation loss 0.9995868302871364 NOT improved\n",
      "Validation loss 0.9993651284177459 NOT improved\n",
      "Validation loss 0.9992662855087182 NOT improved\n",
      "Validation loss 0.9993874360520957 NOT improved\n",
      "Validation loss 0.998737705573463 NOT improved\n",
      "Validation loss 0.9981623993992478 NOT improved\n",
      "Validation loss 0.9975479213631814 NOT improved\n",
      "Validation loss 0.9968814674051653 NOT improved\n",
      "Validation loss 0.9968378842595369 NOT improved\n",
      "Validation loss 0.9967526850224947 NOT improved\n",
      "Validation loss 0.9981548285696453 NOT improved\n",
      "Validation loss 0.9765845946461008 NOT improved\n",
      "Validation loss 0.9749958177122922 NOT improved\n",
      "Validation loss 0.9722063900074188 NOT improved\n",
      "Validation loss 0.9846371494745609 NOT improved\n",
      "Validation loss 0.9847692989672545 NOT improved\n",
      "Validation loss 0.9498867444818612 NOT improved\n",
      "Validation loss 0.9166247541041593 NOT improved\n",
      "Validation loss 0.9484728346612941 NOT improved\n",
      "Validation loss 0.9684606005824231 NOT improved\n",
      "Validation loss 0.9224329540783162 NOT improved\n",
      "Validation loss 0.9689259529826852 NOT improved\n",
      "Validation loss 0.9148951682175989 NOT improved\n",
      "Validation loss 0.8921809046378174 NOT improved\n",
      "Validation loss 0.973003917969318 NOT improved\n",
      "Validation loss 0.9292102152976776 NOT improved\n",
      "Validation loss 0.9453382092078613 NOT improved\n",
      "Validation loss 0.9607526800845593 NOT improved\n",
      "Validation loss 0.8418804037645701 NOT improved\n",
      "Validation loss 0.8852505151955897 NOT improved\n",
      "Validation loss 1.362512622738922 NOT improved\n",
      "Early stopping\n",
      "Training round 5\n",
      "Validation loss 0.9996896821080851 NOT improved\n",
      "Validation loss 0.9997959234350464 NOT improved\n",
      "Validation loss 0.9998582531215227 NOT improved\n",
      "Validation loss 0.9998851031368763 NOT improved\n",
      "Validation loss 0.9999007376634632 NOT improved\n",
      "Validation loss 0.9999052048528282 NOT improved\n",
      "Validation loss 0.9999110993697615 NOT improved\n",
      "Validation loss 0.999911948037228 NOT improved\n",
      "Validation loss 0.9999035779060295 NOT improved\n",
      "Validation loss 0.9999058419115797 NOT improved\n",
      "Validation loss 0.9998880797796016 NOT improved\n",
      "Validation loss 0.9998774403925301 NOT improved\n",
      "Validation loss 0.9998634578781831 NOT improved\n",
      "Validation loss 0.9998276789938548 NOT improved\n",
      "Validation loss 0.9998212323322351 NOT improved\n",
      "Validation loss 0.999745795306123 NOT improved\n",
      "Validation loss 0.9997399860412531 NOT improved\n",
      "Validation loss 0.9997496060580832 NOT improved\n",
      "Validation loss 0.9996921297287583 NOT improved\n",
      "Validation loss 0.9996678307166937 NOT improved\n",
      "Validation loss 0.9994770958492243 NOT improved\n",
      "Validation loss 0.9991653781252581 NOT improved\n",
      "Validation loss 0.9992969424863499 NOT improved\n",
      "Validation loss 0.9983109428306232 NOT improved\n",
      "Validation loss 0.9973901791872821 NOT improved\n",
      "Validation loss 0.9974084951922155 NOT improved\n",
      "Validation loss 0.9978429158099591 NOT improved\n",
      "Validation loss 0.9946446174812307 NOT improved\n",
      "Validation loss 0.9889572136872726 NOT improved\n",
      "Validation loss 0.989286948230378 NOT improved\n",
      "Validation loss 0.9977478455948017 NOT improved\n",
      "Validation loss 0.9749464706770384 NOT improved\n",
      "Validation loss 0.9853108617215527 NOT improved\n",
      "Validation loss 0.9877504489064302 NOT improved\n",
      "Validation loss 0.9720333477040012 NOT improved\n",
      "Validation loss 0.9901923270523656 NOT improved\n",
      "Validation loss 0.9100712174749803 NOT improved\n",
      "Validation loss 0.8840663438162464 NOT improved\n",
      "Validation loss 0.9886119245931823 NOT improved\n",
      "Validation loss 0.9178357897089049 NOT improved\n",
      "Validation loss 0.8800103398753927 NOT improved\n",
      "Validation loss 2.6769863419765265 NOT improved\n",
      "Early stopping\n",
      "Training round 6\n",
      "Validation loss 0.999681150731543 NOT improved\n",
      "Validation loss 0.9997537160596154 NOT improved\n",
      "Validation loss 0.9998195847309732 NOT improved\n",
      "Validation loss 0.9998573742781839 NOT improved\n",
      "Validation loss 0.9998693760882491 NOT improved\n",
      "Validation loss 0.9998759387333873 NOT improved\n",
      "Validation loss 0.9998828732448308 NOT improved\n",
      "Validation loss 0.9998859510387865 NOT improved\n",
      "Validation loss 0.9998899731657181 NOT improved\n",
      "Validation loss 0.999878468608109 NOT improved\n",
      "Validation loss 0.999856413810148 NOT improved\n",
      "Validation loss 0.9998549373030062 NOT improved\n",
      "Validation loss 0.9998566451898485 NOT improved\n",
      "Validation loss 0.9998306840235498 NOT improved\n",
      "Validation loss 0.9997868126918843 NOT improved\n",
      "Validation loss 0.9997549090883506 NOT improved\n",
      "Validation loss 0.9997362939783346 NOT improved\n",
      "Validation loss 0.9996736752696942 NOT improved\n",
      "Validation loss 0.9995766443708017 NOT improved\n",
      "Validation loss 0.9994860449265823 NOT improved\n",
      "Validation loss 0.9992391148318231 NOT improved\n",
      "Validation loss 0.9989776471806128 NOT improved\n",
      "Validation loss 0.9990719848746112 NOT improved\n",
      "Validation loss 0.99904857535903 NOT improved\n",
      "Validation loss 0.9985805530601819 NOT improved\n",
      "Validation loss 0.9983216128613909 NOT improved\n",
      "Validation loss 0.9974543050492084 NOT improved\n",
      "Validation loss 0.9978299525646013 NOT improved\n",
      "Validation loss 0.9955563200967117 NOT improved\n",
      "Validation loss 0.9968783025361918 NOT improved\n",
      "Validation loss 0.9919676807550019 NOT improved\n",
      "Validation loss 0.948938207897948 NOT improved\n",
      "Validation loss 0.9114763114498435 NOT improved\n",
      "Validation loss 0.9901257480384899 NOT improved\n",
      "Validation loss 0.9919343077030653 NOT improved\n",
      "Validation loss 0.950537886011937 NOT improved\n",
      "Validation loss 0.8303990310749672 NOT improved\n",
      "Validation loss 0.8575678783247311 NOT improved\n",
      "Validation loss 0.9368313534951933 NOT improved\n",
      "Validation loss 0.9488933493542143 NOT improved\n",
      "Validation loss 0.8797637516055384 NOT improved\n",
      "Validation loss 0.9271501103555214 NOT improved\n",
      "Validation loss 0.8355106975712893 NOT improved\n",
      "Validation loss 0.8827513635995917 NOT improved\n",
      "Validation loss 0.9362046198158942 NOT improved\n",
      "Validation loss 0.8623739994944215 NOT improved\n",
      "Validation loss 1.8133889704207458 NOT improved\n",
      "Early stopping\n",
      "Training round 7\n",
      "Validation loss 0.9997843744770831 NOT improved\n",
      "Validation loss 0.9998181720287901 NOT improved\n",
      "Validation loss 0.9998491504598653 NOT improved\n",
      "Validation loss 0.9998712063385312 NOT improved\n",
      "Validation loss 0.9998762458332094 NOT improved\n",
      "Validation loss 0.9998791349072607 NOT improved\n",
      "Validation loss 0.9998711158880452 NOT improved\n",
      "Validation loss 0.9998673368245132 NOT improved\n",
      "Validation loss 0.9998552739277243 NOT improved\n",
      "Validation loss 0.9998380158123833 NOT improved\n",
      "Validation loss 0.9998266077094973 NOT improved\n",
      "Validation loss 0.9998079443072854 NOT improved\n",
      "Validation loss 0.9997851533951189 NOT improved\n",
      "Validation loss 0.9997841958942058 NOT improved\n",
      "Validation loss 0.999759095604295 NOT improved\n",
      "Validation loss 0.9996362176926674 NOT improved\n",
      "Validation loss 0.9996119748759377 NOT improved\n",
      "Validation loss 0.9995564069531545 NOT improved\n",
      "Validation loss 0.9994342314800558 NOT improved\n",
      "Validation loss 0.9993206969070716 NOT improved\n",
      "Validation loss 0.998779970193831 NOT improved\n",
      "Validation loss 0.9986064599414927 NOT improved\n",
      "Validation loss 0.9977427331434018 NOT improved\n",
      "Validation loss 0.9990591975233009 NOT improved\n",
      "Validation loss 0.997629791684131 NOT improved\n",
      "Validation loss 0.9978277489756727 NOT improved\n",
      "Validation loss 0.9988944710377397 NOT improved\n",
      "Validation loss 0.9786098401476043 NOT improved\n",
      "Validation loss 0.9965767846771603 NOT improved\n",
      "Validation loss 0.9953594618382469 NOT improved\n",
      "Validation loss 0.9779976995344691 NOT improved\n",
      "Validation loss 0.9443148648734615 NOT improved\n",
      "Validation loss 0.9287006090156037 NOT improved\n",
      "Validation loss 0.952589961270987 NOT improved\n",
      "Validation loss 0.9261086450672237 NOT improved\n",
      "Validation loss 0.9049121886058112 NOT improved\n",
      "Validation loss 0.9094436047938166 NOT improved\n",
      "Validation loss 0.9556804673618595 NOT improved\n",
      "Validation loss 0.8972066491902116 NOT improved\n",
      "Validation loss 0.8475586481180303 NOT improved\n",
      "Validation loss 0.8852489672195268 NOT improved\n",
      "Validation loss 0.9194902954700116 NOT improved\n",
      "Validation loss 1.3170541088513095 NOT improved\n",
      "Early stopping\n",
      "Training round 8\n",
      "Validation loss 0.9997090468034368 NOT improved\n",
      "Validation loss 0.9997922825216657 NOT improved\n",
      "Validation loss 0.9998450987456655 NOT improved\n",
      "Validation loss 0.999871573847108 NOT improved\n",
      "Validation loss 0.9998849220512938 NOT improved\n",
      "Validation loss 0.9998910545648212 NOT improved\n",
      "Validation loss 0.999896295057073 NOT improved\n",
      "Validation loss 0.9998904193070154 NOT improved\n",
      "Validation loss 0.9998895492328218 NOT improved\n",
      "Validation loss 0.9998880611184341 NOT improved\n",
      "Validation loss 0.9998863962156667 NOT improved\n",
      "Validation loss 0.9998696577368997 NOT improved\n",
      "Validation loss 0.9998680733801317 NOT improved\n",
      "Validation loss 0.9998076678568651 NOT improved\n",
      "Validation loss 0.9997515426029409 NOT improved\n",
      "Validation loss 0.9997815293001536 NOT improved\n",
      "Validation loss 0.9997777854580359 NOT improved\n",
      "Validation loss 0.9995944268771965 NOT improved\n",
      "Validation loss 0.9995054951815645 NOT improved\n",
      "Validation loss 0.9996472301941014 NOT improved\n",
      "Validation loss 0.9995305778404114 NOT improved\n",
      "Validation loss 0.9986012322088207 NOT improved\n",
      "Validation loss 0.9987582457071328 NOT improved\n",
      "Validation loss 0.9983640867874183 NOT improved\n",
      "Validation loss 0.9985630327151228 NOT improved\n",
      "Validation loss 0.9981970369135 NOT improved\n",
      "Validation loss 0.9966154407991754 NOT improved\n",
      "Validation loss 0.9878834268053545 NOT improved\n",
      "Validation loss 0.9959077389454567 NOT improved\n",
      "Validation loss 0.9970264190492496 NOT improved\n",
      "Validation loss 0.9700144810121146 NOT improved\n",
      "Validation loss 0.9911105628616457 NOT improved\n",
      "Validation loss 0.9459536119457469 NOT improved\n",
      "Validation loss 0.9867028000348484 NOT improved\n",
      "Validation loss 0.9384058460231919 NOT improved\n",
      "Validation loss 0.9028917566623461 NOT improved\n",
      "Validation loss 0.8457456498639162 NOT improved\n",
      "Validation loss 0.8617485572595294 NOT improved\n",
      "Validation loss 0.9631802406102883 NOT improved\n",
      "Validation loss 0.9092681881802248 NOT improved\n",
      "Validation loss 0.8637923923755156 NOT improved\n",
      "Validation loss 0.8414051152287918 NOT improved\n",
      "Validation loss 1.3466164028082008 NOT improved\n",
      "Early stopping\n",
      "Training round 9\n",
      "Validation loss 0.9997398580890352 NOT improved\n",
      "Validation loss 0.9998051967378631 NOT improved\n",
      "Validation loss 0.999851771046389 NOT improved\n",
      "Validation loss 0.9998798192057967 NOT improved\n",
      "Validation loss 0.9998918663508505 NOT improved\n",
      "Validation loss 0.9998976809676012 NOT improved\n",
      "Validation loss 0.9998926312957644 NOT improved\n",
      "Validation loss 0.9998965079717268 NOT improved\n",
      "Validation loss 0.9998899432767282 NOT improved\n",
      "Validation loss 0.9998810641863842 NOT improved\n",
      "Validation loss 0.9998826774547175 NOT improved\n",
      "Validation loss 0.9998662706013145 NOT improved\n",
      "Validation loss 0.9998658154178345 NOT improved\n",
      "Validation loss 0.9998367255117416 NOT improved\n",
      "Validation loss 0.999824030257555 NOT improved\n",
      "Validation loss 0.9997667435431496 NOT improved\n",
      "Validation loss 0.9997710881967703 NOT improved\n",
      "Validation loss 0.9997651866106483 NOT improved\n",
      "Validation loss 0.999652727768207 NOT improved\n",
      "Validation loss 0.9995933757612409 NOT improved\n",
      "Validation loss 0.9994822996521153 NOT improved\n",
      "Validation loss 0.9991474787859687 NOT improved\n",
      "Validation loss 0.9994515685744348 NOT improved\n",
      "Validation loss 0.9992059722142376 NOT improved\n",
      "Validation loss 0.9990023330012169 NOT improved\n",
      "Validation loss 0.9978295583440683 NOT improved\n",
      "Validation loss 0.9964065918506054 NOT improved\n",
      "Validation loss 0.9894245213926877 NOT improved\n",
      "Validation loss 0.9967816834181349 NOT improved\n",
      "Validation loss 0.9841745406514619 NOT improved\n",
      "Validation loss 0.9348558278835241 NOT improved\n",
      "Validation loss 0.9910158074947304 NOT improved\n",
      "Validation loss 0.9768207778883087 NOT improved\n",
      "Validation loss 0.9273994521319608 NOT improved\n",
      "Validation loss 0.9112456964248474 NOT improved\n",
      "Validation loss 0.9132612785821184 NOT improved\n",
      "Validation loss 0.9663270450131253 NOT improved\n",
      "Validation loss 0.9386526184554475 NOT improved\n",
      "Validation loss 0.8893589313987691 NOT improved\n",
      "Validation loss 0.9696049698826336 NOT improved\n",
      "Validation loss 1.2823324001968655 NOT improved\n",
      "Early stopping\n",
      "Training round 10\n",
      "Validation loss 0.9996784534241371 NOT improved\n",
      "Validation loss 0.9998031988396876 NOT improved\n",
      "Validation loss 0.9998683708680987 NOT improved\n",
      "Validation loss 0.999895041983964 NOT improved\n",
      "Validation loss 0.999904429003344 NOT improved\n",
      "Validation loss 0.9999069865726179 NOT improved\n",
      "Validation loss 0.9999057039982407 NOT improved\n",
      "Validation loss 0.9999048724364056 NOT improved\n",
      "Validation loss 0.9999000368272632 NOT improved\n",
      "Validation loss 0.9999001458655521 NOT improved\n",
      "Validation loss 0.9998870628671072 NOT improved\n",
      "Validation loss 0.9998920313455615 NOT improved\n",
      "Validation loss 0.9998714566927284 NOT improved\n",
      "Validation loss 0.9998366038259328 NOT improved\n",
      "Validation loss 0.9998060348902372 NOT improved\n",
      "Validation loss 0.9997411997760721 NOT improved\n",
      "Validation loss 0.9996826383271383 NOT improved\n",
      "Validation loss 0.9997091542170151 NOT improved\n",
      "Validation loss 0.9994842967059578 NOT improved\n",
      "Validation loss 0.9995273345639579 NOT improved\n",
      "Validation loss 0.99953129126483 NOT improved\n",
      "Validation loss 0.9994758565066958 NOT improved\n",
      "Validation loss 0.9981591011181563 NOT improved\n",
      "Validation loss 0.9987341847636031 NOT improved\n",
      "Validation loss 0.9977215619149634 NOT improved\n",
      "Validation loss 0.9974034398431763 NOT improved\n",
      "Validation loss 0.9953955322027023 NOT improved\n",
      "Validation loss 0.9957695163138034 NOT improved\n",
      "Validation loss 0.9934655171339382 NOT improved\n",
      "Validation loss 0.9777117803619015 NOT improved\n",
      "Validation loss 0.9445452666906642 NOT improved\n",
      "Validation loss 0.9886845577895815 NOT improved\n",
      "Validation loss 0.9913555149326951 NOT improved\n",
      "Validation loss 0.992772643972412 NOT improved\n",
      "Validation loss 0.9131338387712011 NOT improved\n",
      "Validation loss 0.9433679763656607 NOT improved\n",
      "Validation loss 0.9841137166133485 NOT improved\n",
      "Validation loss 0.9243810347792917 NOT improved\n",
      "Validation loss 0.905623587862126 NOT improved\n",
      "Validation loss 0.8472730672031262 NOT improved\n",
      "Validation loss 0.9006265966730378 NOT improved\n",
      "Validation loss 0.8708909362098985 NOT improved\n",
      "Validation loss 0.9063566680864155 NOT improved\n",
      "Validation loss 0.9693528656781112 NOT improved\n",
      "Validation loss 0.878480859997206 NOT improved\n",
      "Validation loss 0.8668076153920561 NOT improved\n",
      "Validation loss 1.1245769443458675 NOT improved\n",
      "Early stopping\n",
      "Training round 11\n",
      "Validation loss 0.999693630488005 NOT improved\n",
      "Validation loss 0.9997931523169403 NOT improved\n",
      "Validation loss 0.9998462975928384 NOT improved\n",
      "Validation loss 0.9998715594786665 NOT improved\n",
      "Validation loss 0.9998901739396786 NOT improved\n",
      "Validation loss 0.999890231063543 NOT improved\n",
      "Validation loss 0.9998935674943683 NOT improved\n",
      "Validation loss 0.999892805438323 NOT improved\n",
      "Validation loss 0.9998929433589457 NOT improved\n",
      "Validation loss 0.9998960471118917 NOT improved\n",
      "Validation loss 0.9998694907878259 NOT improved\n",
      "Validation loss 0.999865414826094 NOT improved\n",
      "Validation loss 0.9998571848976378 NOT improved\n",
      "Validation loss 0.9998359157750052 NOT improved\n",
      "Validation loss 0.9998255970620044 NOT improved\n",
      "Validation loss 0.9997782902573997 NOT improved\n",
      "Validation loss 0.9997407632525434 NOT improved\n",
      "Validation loss 0.9997195489506097 NOT improved\n",
      "Validation loss 0.9996495327028501 NOT improved\n",
      "Validation loss 0.9994099855828095 NOT improved\n",
      "Validation loss 0.9992621560714467 NOT improved\n",
      "Validation loss 0.9991115778937074 NOT improved\n",
      "Validation loss 0.9986348096042987 NOT improved\n",
      "Validation loss 0.9978157085323929 NOT improved\n",
      "Validation loss 0.9968192977884903 NOT improved\n",
      "Validation loss 0.9968327769053429 NOT improved\n",
      "Validation loss 0.9952705243627203 NOT improved\n",
      "Validation loss 0.9983083818394844 NOT improved\n",
      "Validation loss 0.9931640742285246 NOT improved\n",
      "Validation loss 0.9917398917379471 NOT improved\n",
      "Validation loss 0.9941181127299151 NOT improved\n",
      "Validation loss 0.9935314868870833 NOT improved\n",
      "Validation loss 0.964919362090546 NOT improved\n",
      "Validation loss 0.9873188510710849 NOT improved\n",
      "Validation loss 0.9586391795755916 NOT improved\n",
      "Validation loss 0.9869573531679299 NOT improved\n",
      "Validation loss 0.8812039902555848 NOT improved\n",
      "Validation loss 0.9457016013046123 NOT improved\n",
      "Validation loss 0.9814752344266796 NOT improved\n",
      "Validation loss 0.914425146895231 NOT improved\n",
      "Validation loss 0.9576731593298008 NOT improved\n",
      "Validation loss 0.8758421861773686 NOT improved\n",
      "Validation loss 1.7856056800357691 NOT improved\n",
      "Early stopping\n",
      "Training round 12\n",
      "Validation loss 0.9997573953556154 NOT improved\n",
      "Validation loss 0.9998314781567368 NOT improved\n",
      "Validation loss 0.9998779626924205 NOT improved\n",
      "Validation loss 0.9998974092848477 NOT improved\n",
      "Validation loss 0.9999014924080858 NOT improved\n",
      "Validation loss 0.9999023106315521 NOT improved\n",
      "Validation loss 0.9999066955936003 NOT improved\n",
      "Validation loss 0.9999001499863577 NOT improved\n",
      "Validation loss 0.9998948174724113 NOT improved\n",
      "Validation loss 0.9998749725387327 NOT improved\n",
      "Validation loss 0.9998785433652675 NOT improved\n",
      "Validation loss 0.9998565509597123 NOT improved\n",
      "Validation loss 0.9998436920290408 NOT improved\n",
      "Validation loss 0.9997941851174803 NOT improved\n",
      "Validation loss 0.9997568455110929 NOT improved\n",
      "Validation loss 0.9997330243600678 NOT improved\n",
      "Validation loss 0.9996680070563513 NOT improved\n",
      "Validation loss 0.9996703899278542 NOT improved\n",
      "Validation loss 0.9996361791966759 NOT improved\n",
      "Validation loss 0.9996471501463317 NOT improved\n",
      "Validation loss 0.9991972183605295 NOT improved\n",
      "Validation loss 0.9991440618879072 NOT improved\n",
      "Validation loss 0.998974110507976 NOT improved\n",
      "Validation loss 0.9989006530322606 NOT improved\n",
      "Validation loss 0.999063101870952 NOT improved\n",
      "Validation loss 0.9975215110113601 NOT improved\n",
      "Validation loss 0.9953959371748442 NOT improved\n",
      "Validation loss 0.9969452404604232 NOT improved\n",
      "Validation loss 0.9946164487769962 NOT improved\n",
      "Validation loss 0.9945782783777423 NOT improved\n",
      "Validation loss 0.9947535200657093 NOT improved\n",
      "Validation loss 0.9947690195416112 NOT improved\n",
      "Validation loss 0.9939675048960528 NOT improved\n",
      "Validation loss 0.9632625691570273 NOT improved\n",
      "Validation loss 0.8404844178777209 NOT improved\n",
      "Validation loss 0.9279397741564512 NOT improved\n",
      "Validation loss 0.9698255446337698 NOT improved\n",
      "Validation loss 0.8871703367873278 NOT improved\n",
      "Validation loss 0.9710346180773102 NOT improved\n",
      "Validation loss 0.936652862352522 NOT improved\n",
      "Validation loss 0.9577894048665255 NOT improved\n",
      "Validation loss 0.9650203841401805 NOT improved\n",
      "Validation loss 0.9404234158473199 NOT improved\n",
      "Validation loss 1.3728293201589616 NOT improved\n",
      "Early stopping\n",
      "Training round 13\n",
      "Validation loss 0.9997694498549657 NOT improved\n",
      "Validation loss 0.9998202529449041 NOT improved\n",
      "Validation loss 0.9998512689068318 NOT improved\n",
      "Validation loss 0.9998695987008006 NOT improved\n",
      "Validation loss 0.9998785119426196 NOT improved\n",
      "Validation loss 0.999888884823665 NOT improved\n",
      "Validation loss 0.9998835470534556 NOT improved\n",
      "Validation loss 0.9998754171139657 NOT improved\n",
      "Validation loss 0.9998755555585562 NOT improved\n",
      "Validation loss 0.9998739212817663 NOT improved\n",
      "Validation loss 0.999850239533404 NOT improved\n",
      "Validation loss 0.9998468528199753 NOT improved\n",
      "Validation loss 0.9997986587532877 NOT improved\n",
      "Validation loss 0.9998075028488251 NOT improved\n",
      "Validation loss 0.9998337026503435 NOT improved\n",
      "Validation loss 0.9997509784336672 NOT improved\n",
      "Validation loss 0.9996859960555947 NOT improved\n",
      "Validation loss 0.9996801749832835 NOT improved\n",
      "Validation loss 0.9997059942228802 NOT improved\n",
      "Validation loss 0.9995277389096255 NOT improved\n",
      "Validation loss 0.9991617920443359 NOT improved\n",
      "Validation loss 0.9989373041053761 NOT improved\n",
      "Validation loss 0.9991762040333538 NOT improved\n",
      "Validation loss 0.999247741405852 NOT improved\n",
      "Validation loss 0.9983365653633499 NOT improved\n",
      "Validation loss 0.9948186737223355 NOT improved\n",
      "Validation loss 0.9979561301481777 NOT improved\n",
      "Validation loss 0.9939062018989041 NOT improved\n",
      "Validation loss 0.9935063132729719 NOT improved\n",
      "Validation loss 0.9959021029090733 NOT improved\n",
      "Validation loss 0.9946715539502085 NOT improved\n",
      "Validation loss 0.9907699255181608 NOT improved\n",
      "Validation loss 0.9897144924253676 NOT improved\n",
      "Validation loss 0.9693613307583144 NOT improved\n",
      "Validation loss 0.9785101091166133 NOT improved\n",
      "Validation loss 0.954425182412002 NOT improved\n",
      "Validation loss 0.9237701220087926 NOT improved\n",
      "Validation loss 0.9837730360400415 NOT improved\n",
      "Validation loss 0.8660671011626663 NOT improved\n",
      "Validation loss 0.9368200443205814 NOT improved\n",
      "Validation loss 0.9583874000822322 NOT improved\n",
      "Validation loss 0.8852360883796905 NOT improved\n",
      "Validation loss 0.9911987197336524 NOT improved\n",
      "Validation loss 0.9724051517858369 NOT improved\n",
      "Validation loss 1.7258703919802305 NOT improved\n",
      "Early stopping\n",
      "Training round 14\n",
      "Validation loss 0.9997272824856112 NOT improved\n",
      "Validation loss 0.9997947085513287 NOT improved\n",
      "Validation loss 0.9998413294555696 NOT improved\n",
      "Validation loss 0.9998634093209205 NOT improved\n",
      "Validation loss 0.9998857875074457 NOT improved\n",
      "Validation loss 0.9998921546046858 NOT improved\n",
      "Validation loss 0.999900797940781 NOT improved\n",
      "Validation loss 0.9999036530674669 NOT improved\n",
      "Validation loss 0.9998939469643257 NOT improved\n",
      "Validation loss 0.9998968208873631 NOT improved\n",
      "Validation loss 0.9998805037866062 NOT improved\n",
      "Validation loss 0.9998729434764567 NOT improved\n",
      "Validation loss 0.9998709112956902 NOT improved\n",
      "Validation loss 0.9998451006866803 NOT improved\n",
      "Validation loss 0.9998101249609923 NOT improved\n",
      "Validation loss 0.9997985795500578 NOT improved\n",
      "Validation loss 0.9997713367048905 NOT improved\n",
      "Validation loss 0.9996903792491199 NOT improved\n",
      "Validation loss 0.9996617657114484 NOT improved\n",
      "Validation loss 0.9993958765259362 NOT improved\n",
      "Validation loss 0.9995399489544269 NOT improved\n",
      "Validation loss 0.9994379804614678 NOT improved\n",
      "Validation loss 0.9991483240066011 NOT improved\n",
      "Validation loss 0.9993063504024239 NOT improved\n",
      "Validation loss 0.9990501652189889 NOT improved\n",
      "Validation loss 0.9973168130891996 NOT improved\n",
      "Validation loss 0.997360569324468 NOT improved\n",
      "Validation loss 0.9976437512664124 NOT improved\n",
      "Validation loss 0.9975510178909045 NOT improved\n",
      "Validation loss 0.9864636708371807 NOT improved\n",
      "Validation loss 0.9921553136578621 NOT improved\n",
      "Validation loss 0.9289291130794898 NOT improved\n",
      "Validation loss 0.9889708616817743 NOT improved\n",
      "Validation loss 0.98920906107465 NOT improved\n",
      "Validation loss 0.9606585025039728 NOT improved\n",
      "Validation loss 0.9024031092557788 NOT improved\n",
      "Validation loss 0.9150627843863257 NOT improved\n",
      "Validation loss 0.8954390999773615 NOT improved\n",
      "Validation loss 0.8860300107391731 NOT improved\n",
      "Validation loss 0.9639620582871753 NOT improved\n",
      "Validation loss 1.2711161536158444 NOT improved\n",
      "Early stopping\n",
      "Training round 15\n",
      "Validation loss 0.9996213853381933 NOT improved\n",
      "Validation loss 0.9997612999872405 NOT improved\n",
      "Validation loss 0.9998375571903934 NOT improved\n",
      "Validation loss 0.9998755407514167 NOT improved\n",
      "Validation loss 0.9998937399761422 NOT improved\n",
      "Validation loss 0.9999026865658192 NOT improved\n",
      "Validation loss 0.9999043677576687 NOT improved\n",
      "Validation loss 0.9999094976854777 NOT improved\n",
      "Validation loss 0.9999108089042621 NOT improved\n",
      "Validation loss 0.9999055225541557 NOT improved\n",
      "Validation loss 0.9998852111998471 NOT improved\n",
      "Validation loss 0.9998789253769944 NOT improved\n",
      "Validation loss 0.9998768636041931 NOT improved\n",
      "Validation loss 0.9998475396860561 NOT improved\n",
      "Validation loss 0.9998416535895228 NOT improved\n",
      "Validation loss 0.9998142400314393 NOT improved\n",
      "Validation loss 0.9997854333377081 NOT improved\n",
      "Validation loss 0.9997475913282865 NOT improved\n",
      "Validation loss 0.9994691746657781 NOT improved\n",
      "Validation loss 0.9996179856930693 NOT improved\n",
      "Validation loss 0.9994591901268371 NOT improved\n",
      "Validation loss 0.9993647839229729 NOT improved\n",
      "Validation loss 0.9987536821058717 NOT improved\n",
      "Validation loss 0.9982841151607548 NOT improved\n",
      "Validation loss 0.9976778976367596 NOT improved\n",
      "Validation loss 0.9985248419223433 NOT improved\n",
      "Validation loss 0.9963378490676359 NOT improved\n",
      "Validation loss 0.9950578095634689 NOT improved\n",
      "Validation loss 0.9961021066355124 NOT improved\n",
      "Validation loss 0.9965497925188553 NOT improved\n",
      "Validation loss 0.9688206553036148 NOT improved\n",
      "Validation loss 0.9929121689342503 NOT improved\n",
      "Validation loss 0.9825970972266825 NOT improved\n",
      "Validation loss 0.9748586851734177 NOT improved\n",
      "Validation loss 0.8525605428959736 NOT improved\n",
      "Validation loss 0.9656652855972188 NOT improved\n",
      "Validation loss 0.8555043945906832 NOT improved\n",
      "Validation loss 0.9213055933677423 NOT improved\n",
      "Validation loss 0.8779313144262161 NOT improved\n",
      "Validation loss 0.9660823735761929 NOT improved\n",
      "Validation loss 0.9394696360942784 NOT improved\n",
      "Validation loss 0.8484205619205144 NOT improved\n",
      "Validation loss 0.9539383840755811 NOT improved\n",
      "Validation loss 0.9036385678660245 NOT improved\n",
      "Validation loss 0.9016599924019743 NOT improved\n",
      "Validation loss 0.914411326756848 NOT improved\n",
      "Validation loss 1.1209841276981964 NOT improved\n",
      "Early stopping\n",
      "Training round 16\n",
      "Validation loss 0.9997586925382005 NOT improved\n",
      "Validation loss 0.9998204627677272 NOT improved\n",
      "Validation loss 0.9998567095124181 NOT improved\n",
      "Validation loss 0.9998764932214133 NOT improved\n",
      "Validation loss 0.9998840225902844 NOT improved\n",
      "Validation loss 0.9998858772925936 NOT improved\n",
      "Validation loss 0.9998861039541607 NOT improved\n",
      "Validation loss 0.9998790433156141 NOT improved\n",
      "Validation loss 0.9998869104791019 NOT improved\n",
      "Validation loss 0.9998801070347993 NOT improved\n",
      "Validation loss 0.9998409532502409 NOT improved\n",
      "Validation loss 0.9998460074188746 NOT improved\n",
      "Validation loss 0.9997907618645929 NOT improved\n",
      "Validation loss 0.9998059134066546 NOT improved\n",
      "Validation loss 0.9998007892549542 NOT improved\n",
      "Validation loss 0.9997163793288891 NOT improved\n",
      "Validation loss 0.9996529348695002 NOT improved\n",
      "Validation loss 0.9997316000833938 NOT improved\n",
      "Validation loss 0.9994131818711754 NOT improved\n",
      "Validation loss 0.9993224628542896 NOT improved\n",
      "Validation loss 0.9989477552803211 NOT improved\n",
      "Validation loss 0.9994411062490236 NOT improved\n",
      "Validation loss 0.9985859615700843 NOT improved\n",
      "Validation loss 0.9994502533509492 NOT improved\n",
      "Validation loss 0.9976097413843131 NOT improved\n",
      "Validation loss 0.9988175873711042 NOT improved\n",
      "Validation loss 0.9948214726704366 NOT improved\n",
      "Validation loss 0.9936050610995293 NOT improved\n",
      "Validation loss 0.9882143625756907 NOT improved\n",
      "Validation loss 0.982601789245536 NOT improved\n",
      "Validation loss 0.9902675696379803 NOT improved\n",
      "Validation loss 0.9849635611077703 NOT improved\n",
      "Validation loss 0.9939468338710008 NOT improved\n",
      "Validation loss 0.957653252904405 NOT improved\n",
      "Validation loss 0.9846997788407673 NOT improved\n",
      "Validation loss 0.9899184612884147 NOT improved\n",
      "Validation loss 0.9122130112482392 NOT improved\n",
      "Validation loss 0.8562674792136948 NOT improved\n",
      "Validation loss 0.9568450113947676 NOT improved\n",
      "Validation loss 0.868984962224866 NOT improved\n",
      "Validation loss 1.26479075763032 NOT improved\n",
      "Early stopping\n",
      "Training round 17\n",
      "Validation loss 0.9997088138769713 NOT improved\n",
      "Validation loss 0.9998122582528193 NOT improved\n",
      "Validation loss 0.9998555436674516 NOT improved\n",
      "Validation loss 0.9998802345532956 NOT improved\n",
      "Validation loss 0.9998911398577066 NOT improved\n",
      "Validation loss 0.9998965864109819 NOT improved\n",
      "Validation loss 0.9998993649776764 NOT improved\n",
      "Validation loss 0.9998961367397935 NOT improved\n",
      "Validation loss 0.999883372734963 NOT improved\n",
      "Validation loss 0.9998956744993441 NOT improved\n",
      "Validation loss 0.9998726780515291 NOT improved\n",
      "Validation loss 0.9998655688566798 NOT improved\n",
      "Validation loss 0.9998427168711289 NOT improved\n",
      "Validation loss 0.9998234062866674 NOT improved\n",
      "Validation loss 0.9997559376718085 NOT improved\n",
      "Validation loss 0.9997669196341358 NOT improved\n",
      "Validation loss 0.9996992565180204 NOT improved\n",
      "Validation loss 0.9996772098277316 NOT improved\n",
      "Validation loss 0.9995787824355178 NOT improved\n",
      "Validation loss 0.9991774139560173 NOT improved\n",
      "Validation loss 0.9994502423064469 NOT improved\n",
      "Validation loss 0.9991544061690539 NOT improved\n",
      "Validation loss 0.9987248034604046 NOT improved\n",
      "Validation loss 0.9952324001271781 NOT improved\n",
      "Validation loss 0.998501541919907 NOT improved\n",
      "Validation loss 0.9983169037012436 NOT improved\n",
      "Validation loss 0.9964563955021322 NOT improved\n",
      "Validation loss 0.9924194594371036 NOT improved\n",
      "Validation loss 0.9977026096978089 NOT improved\n",
      "Validation loss 0.9858197440118935 NOT improved\n"
     ]
    }
   ],
   "source": [
    "seeds = [12342, 2536234, 98765, 473, 865, 7456, 69472, 3456357, 3425, 678,\n",
    "         2452624, 5787, 235362, 67896, 98454, 12445, 46767, 78906, 345, 8695, \n",
    "         2463725, 4734, 23234, 884, 2341, 362, 5, 234, 483, 785356, 23425, 3621, \n",
    "         58461, 80968765, 123, 425633, 5646, 67635, 76785, 34214]\n",
    "\n",
    "training_rounds = len(seeds)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "\n",
    "# =========== Model Section ========== #\n",
    "\n",
    "batch_dir = '/glade/scratch/ksha/DATA/NCAR_batch/'\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = '{}_lead{}'.format(model_tag, lead_name)\n",
    "\n",
    "model_name = '{}'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "tol = 0\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "L_pos = len(TRAIN_256_pos)\n",
    "L_neg = len(TRAIN_256_neg)\n",
    "\n",
    "record = 1.1\n",
    "print(\"Initial record: {}\".format(record))\n",
    "\n",
    "min_del = 0\n",
    "max_tol = 100 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "L_train = 16\n",
    "\n",
    "for r in range(training_rounds):\n",
    "    if r == 0:\n",
    "        tol = 0\n",
    "    else:\n",
    "        tol = -200\n",
    "\n",
    "    model = create_model()\n",
    "    #\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4))\n",
    "    \n",
    "    set_seeds(int(seeds[r]))\n",
    "    print('Training round {}'.format(r))\n",
    "\n",
    "    for i in range(epochs):            \n",
    "        start_time = time.time()\n",
    "\n",
    "        # loop of batch\n",
    "        for j in range(L_train):\n",
    "            N_pos = 32\n",
    "            N_neg = batch_size - N_pos\n",
    "\n",
    "            ind_neg = du.shuffle_ind(L_neg)\n",
    "            ind_pos = du.shuffle_ind(L_pos)\n",
    "\n",
    "            ind_neg_pick = ind_neg[:N_neg]\n",
    "            ind_pos_pick = ind_pos[:N_pos]\n",
    "\n",
    "            X_batch_neg = TRAIN_256_neg[ind_neg_pick, :]\n",
    "            X_batch_pos = TRAIN_256_pos[ind_pos_pick, :]\n",
    "            \n",
    "            X_batch_stn_neg = TRAIN_stn_neg[ind_neg_pick, :]\n",
    "            X_batch_stn_pos = TRAIN_stn_pos[ind_pos_pick, :]\n",
    "\n",
    "            X_batch = np.concatenate((X_batch_neg, X_batch_pos), axis=0)\n",
    "            X_batch_stn = np.concatenate((X_batch_stn_neg, X_batch_stn_pos), axis=0)\n",
    "\n",
    "            Y_batch = np.ones([batch_size,])\n",
    "            Y_batch[:N_neg] = 0.0\n",
    "\n",
    "            ind_ = du.shuffle_ind(batch_size)\n",
    "\n",
    "            X_batch = X_batch[ind_, :]\n",
    "            X_batch_stn = X_batch_stn[ind_, :]\n",
    "            Y_batch = Y_batch[ind_]\n",
    "\n",
    "            # train on batch\n",
    "            model.train_on_batch([X_batch, X_batch_stn], Y_batch);\n",
    "\n",
    "        # epoch end operations\n",
    "        Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "\n",
    "        Y_pred[Y_pred<0] = 0\n",
    "        Y_pred[Y_pred>1] = 1\n",
    "\n",
    "        record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n",
    "        # if i % 10 == 0:\n",
    "        #     model.save(model_path_backup)\n",
    "\n",
    "        if (record - record_temp > min_del):\n",
    "            print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "            record = record_temp\n",
    "            tol = 0\n",
    "            \n",
    "            #print('tol: {}'.format(tol))\n",
    "            # save\n",
    "            print('save to: {}'.format(model_path))\n",
    "            model.save(model_path)\n",
    "        else:\n",
    "            print('Validation loss {} NOT improved'.format(record_temp))\n",
    "            if record_temp > 1.01:\n",
    "                print('Early stopping')\n",
    "                break;\n",
    "            else:\n",
    "                tol += 1\n",
    "                if tol >= max_tol:\n",
    "                    print('Early stopping')\n",
    "                    break;\n",
    "                else:\n",
    "                    continue;\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba732cc-cef9-43ff-89ff-0fb00f59075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964176a0-95be-4e49-81c4-7a659751d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199f0a-0bd1-490b-b929-922a8a39a1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427b0011-7eee-4cca-a80a-ed37a18c5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=keras.optimizers.Adam(lr=0))\n",
    "\n",
    "W_old = k_utils.dummy_loader('/glade/work/ksha/NCAR/Keras_models/alt_lead{}/'.format(lead_name))\n",
    "model.set_weights(W_old)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb05d2d-092a-4702-a245-fea6f96ffe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/NCAR/RESULT_FULL_lead2_alt.npy\n"
     ]
    }
   ],
   "source": [
    "save_dict = {}\n",
    "save_dict['Y_pred'] = Y_pred\n",
    "save_dict['VALID_Y'] = VALID_Y\n",
    "np.save('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag), save_dict)\n",
    "print('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60af67c-8780-42cf-ab0a-d6434b1b5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8280119062518958"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b4252-b6b6-441e-abb0-c0bca38f3471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ec269e-6211-4a90-a8d9-fa78fc3f33ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b762c820d60>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94898f-0118-4b3e-91e7-c7b8f07b5187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a664b-35c5-4d13-bd1d-63fdfac63233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469f1cd-f820-44a1-9ba6-4f228782f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba0e7c-4640-4e65-b675-995d3a1a06d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e5327-70b2-4ba4-94bc-f1e37f04bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d4ab4-6e8d-49fb-adb5-29205a17e6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf3bf0-b6ad-4be6-b2f4-3bead7aaa672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b6f27-7551-4a81-8669-3482c0da28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca671f-cd07-4052-85c6-10c359bc8c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
