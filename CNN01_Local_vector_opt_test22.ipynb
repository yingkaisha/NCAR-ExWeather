{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35ec06d-99e2-426d-8350-28623a7ed5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 10:58:11.941998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from keras_unet_collection import utils as k_utils\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "import re\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('lead1', help='lead')\n",
    "# parser.add_argument('lead2', help='lead')\n",
    "# parser.add_argument('lead3', help='lead')\n",
    "# parser.add_argument('lead4', help='lead')\n",
    "# parser.add_argument('lead_name', help='lead')\n",
    "# parser.add_argument('model_tag', help='lead')\n",
    "# args = vars(parser.parse_args())\n",
    "\n",
    "lead1 = 20 #int(args['lead1'])\n",
    "lead2 = 21 #int(args['lead2'])\n",
    "lead3 = 22 #int(args['lead3'])\n",
    "\n",
    "lead_name = 22 #int(args['lead_name'])\n",
    "model_tag = 'alt' #args['model_tag']\n",
    "\n",
    "filepath_vec = \"/glade/work/ksha/NCAR/\"\n",
    "\n",
    "if (lead1 < 9) or (lead1 > 18):\n",
    "    path_name1 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name1 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "if (lead2 < 9) or (lead2 > 18):\n",
    "    path_name2 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name2 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "    \n",
    "if (lead3 < 9) or (lead3 > 18):\n",
    "    path_name3 = '/glade/scratch/ksha/DATA/NCAR_batch_v3/'\n",
    "else:\n",
    "    path_name3 = '/glade/campaign/cisl/aiml/ksha/NCAR_batch_v3/'\n",
    "\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred, ref):\n",
    "    BS = np.mean((VALID_target.ravel() - Y_pred.ravel())**2)\n",
    "    metric = BS\n",
    "    return metric / ref\n",
    "\n",
    "def feature_extract(filenames, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max):\n",
    "    \n",
    "    lon_out = []\n",
    "    lat_out = []\n",
    "    elev_out = []\n",
    "    mon_out = []\n",
    "    \n",
    "    base_v3_s = datetime(2018, 7, 15)\n",
    "    base_v3_e = datetime(2020, 12, 2)\n",
    "\n",
    "    base_v4_s = datetime(2020, 12, 3)\n",
    "    base_v4_e = datetime(2022, 7, 15)\n",
    "\n",
    "    base_ref = datetime(2010, 1, 1)\n",
    "    \n",
    "    date_list_v3 = [base_v3_s + timedelta(days=day) for day in range(365+365+142)]\n",
    "    date_list_v4 = [base_v4_s + timedelta(days=day) for day in range(365+180-151)]\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        if 'v4' in name:\n",
    "            date_list = date_list_v4\n",
    "        else:\n",
    "            date_list = date_list_v3\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "        day = date_list[day]\n",
    "        month = day.month\n",
    "        \n",
    "        month_norm = (month - 1)/(12-1)\n",
    "        \n",
    "        lon = lon_80km[indx, indy]\n",
    "        lat = lat_80km[indx, indy]\n",
    "\n",
    "        lon = (lon - lon_minmax[0])/(lon_minmax[1] - lon_minmax[0])\n",
    "        lat = (lat - lat_minmax[0])/(lat_minmax[1] - lat_minmax[0])\n",
    "\n",
    "        elev = elev_80km[indx, indy]\n",
    "        elev = elev / elev_max\n",
    "        \n",
    "        lon_out.append(lon)\n",
    "        lat_out.append(lat)\n",
    "        elev_out.append(elev)\n",
    "        mon_out.append(month_norm)\n",
    "        \n",
    "    return np.array(lon_out), np.array(lat_out), np.array(elev_out), np.array(mon_out)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    \n",
    "    IN_vec = keras.Input((384,))    \n",
    "    IN_elev = keras.Input((3,))\n",
    "    IN = keras.layers.Concatenate()([IN_vec, IN_elev])\n",
    "    \n",
    "    X = IN\n",
    "    #\n",
    "    X = keras.layers.Dense(1024, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(512, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    X = keras.layers.Dropout(0.4)(X)\n",
    "    \n",
    "    X = keras.layers.Dense(128, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    OUT = X\n",
    "    OUT = keras.layers.Dense(1, activation='sigmoid', bias_initializer=keras.initializers.Constant(-10))(OUT)\n",
    "\n",
    "    model = keras.models.Model(inputs=[IN_vec, IN_elev], outputs=OUT)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f933e6-fcb7-4e02-9bb6-c3d33b4ff170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]\n",
    "    elev_3km = h5io['elev_3km'][...]\n",
    "    land_mask_80km = h5io['land_mask_80km'][...]\n",
    "    \n",
    "grid_shape = land_mask_80km.shape\n",
    "\n",
    "elev_80km = du.interp2d_wraper(lon_3km, lat_3km, elev_3km, lon_80km, lat_80km, method='linear')\n",
    "\n",
    "elev_80km[np.isnan(elev_80km)] = 0\n",
    "elev_80km[elev_80km<0] = 0\n",
    "elev_max = np.max(elev_80km)\n",
    "\n",
    "lon_80km_mask = lon_80km[land_mask_80km]\n",
    "lat_80km_mask = lat_80km[land_mask_80km]\n",
    "\n",
    "lon_minmax = [np.min(lon_80km_mask), np.max(lon_80km_mask)]\n",
    "lat_minmax = [np.min(lat_80km_mask), np.max(lat_80km_mask)]\n",
    "\n",
    "filename_train_lead1 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_train_lead2 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name2, lead2)))\n",
    "filename_train_lead3 = sorted(glob(\"{}TRAIN*lead{}.npy\".format(path_name3, lead3)))\n",
    "\n",
    "IND_TRAIN_lead = np.load('/glade/work/ksha/NCAR/IND_TRAIN_lead_full.npy', allow_pickle=True)[()]\n",
    "TRAIN_ind1 = IND_TRAIN_lead['lead{}'.format(lead1)]\n",
    "TRAIN_ind2 = IND_TRAIN_lead['lead{}'.format(lead2)]\n",
    "TRAIN_ind3 = IND_TRAIN_lead['lead{}'.format(lead3)]\n",
    "\n",
    "data_lead1_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "data_lead1_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "data_lead2_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "data_lead2_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "data_lead3_p0 = np.load('{}TRAIN_pp15_pred_lead{}_part0_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "data_lead3_p1 = np.load('{}TRAIN_pp15_pred_lead{}_part1_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "data_lead3_p2 = np.load('{}TRAIN_pp15_pred_lead{}_part2_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "TRAIN_lead1 = np.concatenate((data_lead1_p0['y_vector'], data_lead1_p1['y_vector'], data_lead1_p2['y_vector']), axis=0)\n",
    "TRAIN_lead2 = np.concatenate((data_lead2_p0['y_vector'], data_lead2_p1['y_vector'], data_lead2_p2['y_vector']), axis=0)\n",
    "TRAIN_lead3 = np.concatenate((data_lead3_p0['y_vector'], data_lead3_p1['y_vector'], data_lead3_p2['y_vector']), axis=0)\n",
    "\n",
    "TRAIN_lead1_y = np.concatenate((data_lead1_p0['y_true'], data_lead1_p1['y_true'], data_lead1_p2['y_true']), axis=0)\n",
    "TRAIN_lead2_y = np.concatenate((data_lead2_p0['y_true'], data_lead2_p1['y_true'], data_lead2_p2['y_true']), axis=0)\n",
    "TRAIN_lead3_y = np.concatenate((data_lead3_p0['y_true'], data_lead3_p1['y_true'], data_lead3_p2['y_true']), axis=0)\n",
    "\n",
    "L = len(TRAIN_ind1)\n",
    "\n",
    "filename_train1_pick = []\n",
    "filename_train2_pick = []\n",
    "filename_train3_pick = []\n",
    "\n",
    "TRAIN_X = np.empty((L, 384))\n",
    "TRAIN_Y = np.empty(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(TRAIN_ind1[i])\n",
    "    ind_lead2 = int(TRAIN_ind2[i])\n",
    "    ind_lead3 = int(TRAIN_ind3[i])\n",
    "    \n",
    "    filename_train1_pick.append(filename_train_lead1[ind_lead1])\n",
    "    filename_train2_pick.append(filename_train_lead2[ind_lead2])\n",
    "    filename_train3_pick.append(filename_train_lead3[ind_lead3])\n",
    "    \n",
    "    TRAIN_X[i, 0:128]   = TRAIN_lead1[ind_lead1, :]\n",
    "    TRAIN_X[i, 128:256] = TRAIN_lead2[ind_lead2, :]\n",
    "    TRAIN_X[i, 256:384] = TRAIN_lead3[ind_lead3, :]\n",
    " \n",
    "    TRAIN_Y[i] = TRAIN_lead3_y[ind_lead3]\n",
    "    \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_train3_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "\n",
    "TRAIN_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "TRAIN_merge = TRAIN_stn\n",
    "\n",
    "TRAIN_256_pos = TRAIN_X[TRAIN_Y==1, :]\n",
    "TRAIN_256_neg = TRAIN_X[TRAIN_Y==0, :]\n",
    "\n",
    "TRAIN_stn_pos = TRAIN_merge[TRAIN_Y==1]\n",
    "TRAIN_stn_neg = TRAIN_merge[TRAIN_Y==0]\n",
    "\n",
    "filename_valid_lead1 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name1, lead1)))\n",
    "filename_valid_lead2 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name2, lead2)))\n",
    "filename_valid_lead3 = sorted(glob(\"{}VALID*lead{}.npy\".format(path_name3, lead3)))\n",
    "\n",
    "valid_lead1 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead1, model_tag), allow_pickle=True)[()]\n",
    "valid_lead2 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead2, model_tag), allow_pickle=True)[()]\n",
    "valid_lead3 = np.load('{}TEST_pp15_pred_lead{}_{}.npy'.format(filepath_vec, lead3, model_tag), allow_pickle=True)[()]\n",
    "\n",
    "VALID_lead1 = valid_lead1['y_vector']\n",
    "VALID_lead2 = valid_lead2['y_vector']\n",
    "VALID_lead3 = valid_lead3['y_vector']\n",
    "\n",
    "VALID_lead1_y = valid_lead1['y_true']\n",
    "VALID_lead2_y = valid_lead2['y_true']\n",
    "VALID_lead3_y = valid_lead3['y_true']\n",
    "\n",
    "IND_VALID_lead = np.load('/glade/work/ksha/NCAR/IND_VALID_lead_full.npy', allow_pickle=True)[()]\n",
    "\n",
    "VALID_ind1 = IND_VALID_lead['lead{}'.format(lead1)]\n",
    "VALID_ind2 = IND_VALID_lead['lead{}'.format(lead2)]\n",
    "VALID_ind3 = IND_VALID_lead['lead{}'.format(lead3)]\n",
    "\n",
    "L = len(VALID_ind1)\n",
    "\n",
    "filename_valid1_pick = []\n",
    "filename_valid2_pick = []\n",
    "filename_valid3_pick = []\n",
    "\n",
    "VALID_X = np.empty((L, 384))\n",
    "VALID_Y = np.zeros(L)\n",
    "\n",
    "for i in range(L):\n",
    "    \n",
    "    ind_lead1 = int(VALID_ind1[i])\n",
    "    ind_lead2 = int(VALID_ind2[i])\n",
    "    ind_lead3 = int(VALID_ind3[i])\n",
    "    \n",
    "    filename_valid1_pick.append(filename_valid_lead1[ind_lead1])\n",
    "    filename_valid2_pick.append(filename_valid_lead2[ind_lead2])\n",
    "    filename_valid3_pick.append(filename_valid_lead3[ind_lead3])\n",
    "    \n",
    "    VALID_X[i, 0:128]   = VALID_lead1[ind_lead1, :]\n",
    "    VALID_X[i, 128:256] = VALID_lead2[ind_lead2, :]\n",
    "    VALID_X[i, 256:384] = VALID_lead3[ind_lead3, :]\n",
    "    \n",
    "    if 'pos' in filename_valid_lead3[ind_lead3]:\n",
    "        if VALID_lead3_y[ind_lead3] == 1.0:\n",
    "            VALID_Y[i] = 1.0\n",
    "        else:\n",
    "            egwrshat\n",
    "        \n",
    "lon_norm, lat_norm, elev_norm, mon_norm = feature_extract(\n",
    "    filename_valid3_pick, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max)\n",
    "        \n",
    "VALID_stn = np.concatenate((lon_norm[:, None], lat_norm[:, None], elev_norm[:, None]), axis=1)\n",
    "VALID_merge = VALID_stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f1cceb-d21e-402f-995b-16ad8f3b8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record: 1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:00:32.943239: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-24 11:00:32.944754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-24 11:00:32.974058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-01-24 11:00:32.974109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-24 11:00:33.119647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-24 11:00:33.119717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-24 11:00:33.204702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-24 11:00:33.300405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-24 11:00:33.405030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-24 11:00:33.490700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-24 11:00:33.619501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-24 11:00:33.620248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-24 11:00:33.620864: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-24 11:00:33.621089: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-24 11:00:33.621472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-01-24 11:00:33.621513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-24 11:00:33.621536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-24 11:00:33.621547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-24 11:00:33.621556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-24 11:00:33.621565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-24 11:00:33.621574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-24 11:00:33.621585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-24 11:00:33.621594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-24 11:00:33.622081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-24 11:00:33.622124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-24 11:00:36.876223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-24 11:00:36.876260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-01-24 11:00:36.876278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-01-24 11:00:36.877388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:00:38.099384: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-24 11:00:38.104130: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2023-01-24 11:00:38.328556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.1 to 0.9996105170380091\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:00:45.601963: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 9.054218053817749 seconds ---\n",
      "Validation loss 0.9997586499468082 NOT improved\n",
      "Validation loss 0.9998442456204525 NOT improved\n",
      "Validation loss 0.9998697786471781 NOT improved\n",
      "Validation loss 0.9998774486286457 NOT improved\n",
      "Validation loss 0.9998706650130771 NOT improved\n",
      "Validation loss 0.9998790627643054 NOT improved\n",
      "Validation loss 0.9998742377084162 NOT improved\n",
      "Validation loss 0.9998705296850671 NOT improved\n",
      "Validation loss 0.9998695977861249 NOT improved\n",
      "Validation loss 0.9998454206655963 NOT improved\n",
      "Validation loss 0.9997929236527654 NOT improved\n",
      "Validation loss 0.9997666689885664 NOT improved\n",
      "Validation loss 0.9997868504983967 NOT improved\n",
      "Validation loss 0.9998155449596291 NOT improved\n",
      "Validation loss improved from 0.9996105170380091 to 0.9995821603926688\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 7.834436655044556 seconds ---\n",
      "Validation loss 0.9996325416955189 NOT improved\n",
      "Validation loss improved from 0.9995821603926688 to 0.999470106689137\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.752588272094727 seconds ---\n",
      "Validation loss improved from 0.999470106689137 to 0.999151066446593\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 7.058851003646851 seconds ---\n",
      "Validation loss 0.9993240627158495 NOT improved\n",
      "Validation loss improved from 0.999151066446593 to 0.998610207737218\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.926809549331665 seconds ---\n",
      "Validation loss 0.9993753062232328 NOT improved\n",
      "Validation loss improved from 0.998610207737218 to 0.9975103089517272\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.574856519699097 seconds ---\n",
      "Validation loss 0.9977407817410048 NOT improved\n",
      "Validation loss 0.9990904884959553 NOT improved\n",
      "Validation loss improved from 0.9975103089517272 to 0.9974382484009415\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.550998210906982 seconds ---\n",
      "Validation loss improved from 0.9974382484009415 to 0.9852837139706904\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.9617438316345215 seconds ---\n",
      "Validation loss improved from 0.9852837139706904 to 0.9696894594143858\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.957097291946411 seconds ---\n",
      "Validation loss 0.9854680804396379 NOT improved\n",
      "Validation loss 0.9905566815432821 NOT improved\n",
      "Validation loss 0.9971715062394054 NOT improved\n",
      "Validation loss 0.9950918495566174 NOT improved\n",
      "Validation loss 5.032961075945363 NOT improved\n",
      "Early stopping\n",
      "Training round 1\n",
      "Validation loss 0.9998072390549203 NOT improved\n",
      "Validation loss 0.9998353473309018 NOT improved\n",
      "Validation loss 0.9998506307989807 NOT improved\n",
      "Validation loss 0.9998626932956451 NOT improved\n",
      "Validation loss 0.9998568894462339 NOT improved\n",
      "Validation loss 0.9998538034868295 NOT improved\n",
      "Validation loss 0.9998572192501908 NOT improved\n",
      "Validation loss 0.999830078161111 NOT improved\n",
      "Validation loss 0.9998418067673087 NOT improved\n",
      "Validation loss 0.9998434971475363 NOT improved\n",
      "Validation loss 0.9998275670931049 NOT improved\n",
      "Validation loss 0.999815685161798 NOT improved\n",
      "Validation loss 0.9997201279430319 NOT improved\n",
      "Validation loss 0.9997352023024138 NOT improved\n",
      "Validation loss 0.999681625321292 NOT improved\n",
      "Validation loss 0.999770903713242 NOT improved\n",
      "Validation loss 0.9996077081243746 NOT improved\n",
      "Validation loss 0.9994725355016337 NOT improved\n",
      "Validation loss 0.9992691816214112 NOT improved\n",
      "Validation loss 0.99928936161372 NOT improved\n",
      "Validation loss 0.9988541521382016 NOT improved\n",
      "Validation loss 0.9986797739806974 NOT improved\n",
      "Validation loss 0.9981770907452934 NOT improved\n",
      "Validation loss 0.9994013469194262 NOT improved\n",
      "Validation loss 0.9975369735882763 NOT improved\n",
      "Validation loss 0.9977487874084213 NOT improved\n",
      "Validation loss 0.9852666816097875 NOT improved\n",
      "Validation loss 0.9897985499100705 NOT improved\n",
      "Validation loss 0.9976846716965325 NOT improved\n",
      "Validation loss 0.9752867048600979 NOT improved\n",
      "Validation loss improved from 0.9696894594143858 to 0.9682714320179079\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.977254629135132 seconds ---\n",
      "Validation loss improved from 0.9682714320179079 to 0.9153736939179232\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.5152153968811035 seconds ---\n",
      "Validation loss 0.9928212042866801 NOT improved\n",
      "Validation loss 0.9913106294034547 NOT improved\n",
      "Validation loss 0.9167418659061654 NOT improved\n",
      "Validation loss 0.944932616282733 NOT improved\n",
      "Validation loss 0.9320246004387357 NOT improved\n",
      "Validation loss 0.9498737915485621 NOT improved\n",
      "Validation loss 0.993924976317859 NOT improved\n",
      "Validation loss 0.9821828218618042 NOT improved\n",
      "Validation loss 1.0118789079833708 NOT improved\n",
      "Early stopping\n",
      "Training round 2\n",
      "Validation loss 0.9997855885105528 NOT improved\n",
      "Validation loss 0.9998277087034326 NOT improved\n",
      "Validation loss 0.9998316378688543 NOT improved\n",
      "Validation loss 0.999825482493779 NOT improved\n",
      "Validation loss 0.9998370372483262 NOT improved\n",
      "Validation loss 0.9998277616729428 NOT improved\n",
      "Validation loss 0.9998147066281861 NOT improved\n",
      "Validation loss 0.9998098099658606 NOT improved\n",
      "Validation loss 0.9997959825036408 NOT improved\n",
      "Validation loss 0.9997930409010843 NOT improved\n",
      "Validation loss 0.9997341954220739 NOT improved\n",
      "Validation loss 0.9997361077985378 NOT improved\n",
      "Validation loss 0.9997252885665465 NOT improved\n",
      "Validation loss 0.9996691065020039 NOT improved\n",
      "Validation loss 0.9995827963809099 NOT improved\n",
      "Validation loss 0.99944108899261 NOT improved\n",
      "Validation loss 0.9994629383310559 NOT improved\n",
      "Validation loss 0.999499192590551 NOT improved\n",
      "Validation loss 0.9989750493156281 NOT improved\n",
      "Validation loss 0.9990965133030687 NOT improved\n",
      "Validation loss 0.999360537727021 NOT improved\n",
      "Validation loss 0.9987740652361116 NOT improved\n",
      "Validation loss 0.9990540706380903 NOT improved\n",
      "Validation loss 0.9980413530569044 NOT improved\n",
      "Validation loss 0.998085206535722 NOT improved\n",
      "Validation loss 0.9988020093521792 NOT improved\n",
      "Validation loss 0.9889340864528893 NOT improved\n",
      "Validation loss 0.9876087523661671 NOT improved\n",
      "Validation loss 0.9922830478869253 NOT improved\n",
      "Validation loss 0.9571759390497427 NOT improved\n",
      "Validation loss 0.9821824030495387 NOT improved\n",
      "Validation loss 0.9714759313495891 NOT improved\n",
      "Validation loss 0.9530989723060004 NOT improved\n",
      "Validation loss 0.9795097852787873 NOT improved\n",
      "Validation loss 0.9835951498407257 NOT improved\n",
      "Validation loss 0.9814711980909767 NOT improved\n",
      "Validation loss 0.944421814335493 NOT improved\n",
      "Validation loss 0.9901075142514211 NOT improved\n",
      "Validation loss 0.9238124295479636 NOT improved\n",
      "Validation loss 0.9671396502788406 NOT improved\n",
      "Validation loss improved from 0.9153736939179232 to 0.9088605351629913\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.832417011260986 seconds ---\n",
      "Validation loss 0.9673596400963247 NOT improved\n",
      "Validation loss 0.9160291562689652 NOT improved\n",
      "Validation loss 0.9938060270126918 NOT improved\n",
      "Validation loss 0.9186235229881794 NOT improved\n",
      "Validation loss 1.3701176792824605 NOT improved\n",
      "Early stopping\n",
      "Training round 3\n",
      "Validation loss 0.9996777052698139 NOT improved\n",
      "Validation loss 0.9998052619181658 NOT improved\n",
      "Validation loss 0.9998613988440783 NOT improved\n",
      "Validation loss 0.999887683281338 NOT improved\n",
      "Validation loss 0.9998838779043212 NOT improved\n",
      "Validation loss 0.9998968978127873 NOT improved\n",
      "Validation loss 0.9999001517272952 NOT improved\n",
      "Validation loss 0.9998889787843723 NOT improved\n",
      "Validation loss 0.999879762839053 NOT improved\n",
      "Validation loss 0.9998757083704107 NOT improved\n",
      "Validation loss 0.9998377574696341 NOT improved\n",
      "Validation loss 0.9998690097336337 NOT improved\n",
      "Validation loss 0.9998171749726306 NOT improved\n",
      "Validation loss 0.9997859239748214 NOT improved\n",
      "Validation loss 0.9997113779424306 NOT improved\n",
      "Validation loss 0.9997292490888878 NOT improved\n",
      "Validation loss 0.9996758080474513 NOT improved\n",
      "Validation loss 0.9993627585066988 NOT improved\n",
      "Validation loss 0.9995408096076774 NOT improved\n",
      "Validation loss 0.9991590810519783 NOT improved\n",
      "Validation loss 0.9995705583789808 NOT improved\n",
      "Validation loss 0.99733870252707 NOT improved\n",
      "Validation loss 0.9988993069165588 NOT improved\n",
      "Validation loss 0.9962779056378761 NOT improved\n",
      "Validation loss 0.992839164494936 NOT improved\n",
      "Validation loss 0.9947823793138774 NOT improved\n",
      "Validation loss 0.9969876335524361 NOT improved\n",
      "Validation loss 0.9982625227404232 NOT improved\n",
      "Validation loss 0.9966552575357593 NOT improved\n",
      "Validation loss 0.9841350644919992 NOT improved\n",
      "Validation loss 0.9955132980736795 NOT improved\n",
      "Validation loss 0.980113810568298 NOT improved\n",
      "Validation loss 0.9971460501044855 NOT improved\n",
      "Validation loss 0.92023447075684 NOT improved\n",
      "Validation loss 0.9857148794962367 NOT improved\n",
      "Validation loss 0.9748373326993904 NOT improved\n",
      "Validation loss 0.9407150211667192 NOT improved\n",
      "Validation loss 0.9452008741465061 NOT improved\n",
      "Validation loss 1.0311837827087116 NOT improved\n",
      "Early stopping\n",
      "Training round 4\n",
      "Validation loss 0.9997702636874937 NOT improved\n",
      "Validation loss 0.9998328797627003 NOT improved\n",
      "Validation loss 0.9998704462469722 NOT improved\n",
      "Validation loss 0.9998737061708098 NOT improved\n",
      "Validation loss 0.9998745131445126 NOT improved\n",
      "Validation loss 0.9998804668275703 NOT improved\n",
      "Validation loss 0.9998624079993672 NOT improved\n",
      "Validation loss 0.999855114588717 NOT improved\n",
      "Validation loss 0.99984678653153 NOT improved\n",
      "Validation loss 0.9998289682450899 NOT improved\n",
      "Validation loss 0.9998297908064543 NOT improved\n",
      "Validation loss 0.9997696704736171 NOT improved\n",
      "Validation loss 0.9997933824361418 NOT improved\n",
      "Validation loss 0.9996891567247251 NOT improved\n",
      "Validation loss 0.9997095435310241 NOT improved\n",
      "Validation loss 0.9996068574146411 NOT improved\n",
      "Validation loss 0.9995570689448439 NOT improved\n",
      "Validation loss 0.9994601776728441 NOT improved\n",
      "Validation loss 0.9990585652385552 NOT improved\n",
      "Validation loss 0.9994645189313199 NOT improved\n",
      "Validation loss 0.9990507437701986 NOT improved\n",
      "Validation loss 0.9935705907665207 NOT improved\n",
      "Validation loss 0.9990404986559285 NOT improved\n",
      "Validation loss 0.9983226885784652 NOT improved\n",
      "Validation loss 0.9954761866144044 NOT improved\n",
      "Validation loss 0.9986968393708575 NOT improved\n",
      "Validation loss 0.9976512164587807 NOT improved\n",
      "Validation loss 0.994524170185063 NOT improved\n",
      "Validation loss 0.9974924608456113 NOT improved\n",
      "Validation loss 0.9947228498934042 NOT improved\n",
      "Validation loss 0.9598273698167035 NOT improved\n",
      "Validation loss 0.9419695136348908 NOT improved\n",
      "Validation loss 0.9723991542116737 NOT improved\n",
      "Validation loss 0.9938342302730561 NOT improved\n",
      "Validation loss 0.9793332514674857 NOT improved\n",
      "Validation loss 0.9484846004580303 NOT improved\n",
      "Validation loss improved from 0.9088605351629913 to 0.9081140833577075\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 7.081773519515991 seconds ---\n",
      "Validation loss 0.9434550793344441 NOT improved\n",
      "Validation loss 0.9840717282322067 NOT improved\n",
      "Validation loss 0.9732877948796932 NOT improved\n",
      "Validation loss 0.9844456796566291 NOT improved\n",
      "Validation loss 0.9696693302282082 NOT improved\n",
      "Validation loss 0.9434489932935337 NOT improved\n",
      "Validation loss 0.9454387203870592 NOT improved\n",
      "Validation loss 0.9255244812807257 NOT improved\n",
      "Validation loss 1.1612061421025135 NOT improved\n",
      "Early stopping\n",
      "Training round 5\n",
      "Validation loss 0.9996931000444289 NOT improved\n",
      "Validation loss 0.9997780692480819 NOT improved\n",
      "Validation loss 0.9998413885446764 NOT improved\n",
      "Validation loss 0.9998756531482506 NOT improved\n",
      "Validation loss 0.9998955095757678 NOT improved\n",
      "Validation loss 0.9998962378128471 NOT improved\n",
      "Validation loss 0.999888579527648 NOT improved\n",
      "Validation loss 0.9998737459494237 NOT improved\n",
      "Validation loss 0.9998790944417825 NOT improved\n",
      "Validation loss 0.9998534372056401 NOT improved\n",
      "Validation loss 0.9998636051762407 NOT improved\n",
      "Validation loss 0.9998494008510229 NOT improved\n",
      "Validation loss 0.9998217974059627 NOT improved\n",
      "Validation loss 0.9996928058268721 NOT improved\n",
      "Validation loss 0.9997856704494019 NOT improved\n",
      "Validation loss 0.9997047322101787 NOT improved\n",
      "Validation loss 0.9994532386404059 NOT improved\n",
      "Validation loss 0.9997693111470777 NOT improved\n",
      "Validation loss 0.9989866851073527 NOT improved\n",
      "Validation loss 0.9985789310542028 NOT improved\n",
      "Validation loss 0.9994004945841529 NOT improved\n",
      "Validation loss 0.9974333534060947 NOT improved\n",
      "Validation loss 0.9971484170722192 NOT improved\n",
      "Validation loss 0.9973859904527598 NOT improved\n",
      "Validation loss 0.9969468255758469 NOT improved\n",
      "Validation loss 0.9965254367964621 NOT improved\n",
      "Validation loss 0.9990309048306887 NOT improved\n",
      "Validation loss 0.9967766489878206 NOT improved\n",
      "Validation loss 0.9847210235353545 NOT improved\n",
      "Validation loss 0.9946521221280155 NOT improved\n",
      "Validation loss 0.9981352790093055 NOT improved\n",
      "Validation loss 0.9302256517903594 NOT improved\n",
      "Validation loss 0.9807501400162708 NOT improved\n",
      "Validation loss 0.9950606486370454 NOT improved\n",
      "Validation loss 0.9808621700952583 NOT improved\n",
      "Validation loss 0.915616125661285 NOT improved\n",
      "Validation loss 0.9141709084952195 NOT improved\n",
      "Validation loss 1.0252211164555032 NOT improved\n",
      "Early stopping\n",
      "Training round 6\n",
      "Validation loss 0.9995784397760734 NOT improved\n",
      "Validation loss 0.9997586681323875 NOT improved\n",
      "Validation loss 0.9998423635345396 NOT improved\n",
      "Validation loss 0.9998626383230654 NOT improved\n",
      "Validation loss 0.9998821328768982 NOT improved\n",
      "Validation loss 0.9998894240374933 NOT improved\n",
      "Validation loss 0.9998909188175484 NOT improved\n",
      "Validation loss 0.9998966080233341 NOT improved\n",
      "Validation loss 0.9998757659710024 NOT improved\n",
      "Validation loss 0.9998726923896268 NOT improved\n",
      "Validation loss 0.9998258600742568 NOT improved\n",
      "Validation loss 0.9998162537584173 NOT improved\n",
      "Validation loss 0.9998619413116207 NOT improved\n",
      "Validation loss 0.9998187754992884 NOT improved\n",
      "Validation loss 0.9995780863134777 NOT improved\n",
      "Validation loss 0.9995641288837679 NOT improved\n",
      "Validation loss 0.9997656719526936 NOT improved\n",
      "Validation loss 0.9994661494329791 NOT improved\n",
      "Validation loss 0.9997600326112609 NOT improved\n",
      "Validation loss 0.9992012362336391 NOT improved\n",
      "Validation loss 0.9981391185021475 NOT improved\n",
      "Validation loss 0.9991940921283036 NOT improved\n",
      "Validation loss 0.9963208548879476 NOT improved\n",
      "Validation loss 0.9982255202846556 NOT improved\n",
      "Validation loss 0.9983119757663573 NOT improved\n",
      "Validation loss 0.9956581874417685 NOT improved\n",
      "Validation loss 0.9970750808184397 NOT improved\n",
      "Validation loss 0.9970197171610043 NOT improved\n",
      "Validation loss 0.9669276514250938 NOT improved\n",
      "Validation loss 0.9921112440091655 NOT improved\n",
      "Validation loss 0.9205683042947829 NOT improved\n",
      "Validation loss 0.9932474601532523 NOT improved\n",
      "Validation loss 0.9935818063247315 NOT improved\n",
      "Validation loss 0.9671191608730595 NOT improved\n",
      "Validation loss 0.9201467636165591 NOT improved\n",
      "Validation loss 0.9744994152841026 NOT improved\n",
      "Validation loss 0.9195203276375197 NOT improved\n",
      "Validation loss 1.4127818619611898 NOT improved\n",
      "Early stopping\n",
      "Training round 7\n",
      "Validation loss 0.9997621528348549 NOT improved\n",
      "Validation loss 0.9998032985376345 NOT improved\n",
      "Validation loss 0.999845297871182 NOT improved\n",
      "Validation loss 0.9998561810066404 NOT improved\n",
      "Validation loss 0.9998615880769275 NOT improved\n",
      "Validation loss 0.9998620182224692 NOT improved\n",
      "Validation loss 0.9998514218361652 NOT improved\n",
      "Validation loss 0.9998395846702159 NOT improved\n",
      "Validation loss 0.999812117390264 NOT improved\n",
      "Validation loss 0.9997856700675108 NOT improved\n",
      "Validation loss 0.9997403600597063 NOT improved\n",
      "Validation loss 0.9997699174776714 NOT improved\n",
      "Validation loss 0.999766646407044 NOT improved\n",
      "Validation loss 0.99958893305854 NOT improved\n",
      "Validation loss 0.9997909622520262 NOT improved\n",
      "Validation loss 0.9994578904356721 NOT improved\n",
      "Validation loss 0.9987985461815703 NOT improved\n",
      "Validation loss 0.9993076987490606 NOT improved\n",
      "Validation loss 0.9990911118021892 NOT improved\n",
      "Validation loss 0.9996092986023479 NOT improved\n",
      "Validation loss 0.9991916385869888 NOT improved\n",
      "Validation loss 0.9991349192297145 NOT improved\n",
      "Validation loss 0.9980349548281229 NOT improved\n",
      "Validation loss 0.9949541525341589 NOT improved\n",
      "Validation loss 0.9982928928591259 NOT improved\n",
      "Validation loss 0.997813037659707 NOT improved\n",
      "Validation loss 0.995724300868316 NOT improved\n",
      "Validation loss 0.980127564338014 NOT improved\n",
      "Validation loss 0.9931265834206865 NOT improved\n",
      "Validation loss 0.9582915700698326 NOT improved\n",
      "Validation loss 0.993950363154721 NOT improved\n",
      "Validation loss 0.9804316262751959 NOT improved\n",
      "Validation loss 0.9882430019496695 NOT improved\n",
      "Validation loss 0.924174509546421 NOT improved\n",
      "Validation loss 0.9643310270626899 NOT improved\n",
      "Validation loss 0.9703333216540888 NOT improved\n",
      "Validation loss improved from 0.9081140833577075 to 0.9079230480428345\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 7.099477529525757 seconds ---\n",
      "Validation loss 0.9816504997941876 NOT improved\n",
      "Validation loss 1.028580649371587 NOT improved\n",
      "Early stopping\n",
      "Training round 8\n",
      "Validation loss 0.9994710931861643 NOT improved\n",
      "Validation loss 0.9997664602375754 NOT improved\n",
      "Validation loss 0.9998371286963716 NOT improved\n",
      "Validation loss 0.9998695726590151 NOT improved\n",
      "Validation loss 0.9998711201712347 NOT improved\n",
      "Validation loss 0.9998769385587426 NOT improved\n",
      "Validation loss 0.9998605240383789 NOT improved\n",
      "Validation loss 0.9998386244088897 NOT improved\n",
      "Validation loss 0.9998516579002137 NOT improved\n",
      "Validation loss 0.999848455490999 NOT improved\n",
      "Validation loss 0.999801665469363 NOT improved\n",
      "Validation loss 0.9997662579585196 NOT improved\n",
      "Validation loss 0.9997254595864965 NOT improved\n",
      "Validation loss 0.9997181578751029 NOT improved\n",
      "Validation loss 0.9996730778733696 NOT improved\n",
      "Validation loss 0.9995850876533745 NOT improved\n",
      "Validation loss 0.9994539456826218 NOT improved\n",
      "Validation loss 0.999548976142902 NOT improved\n",
      "Validation loss 0.9994828766483612 NOT improved\n",
      "Validation loss 0.9991211629310142 NOT improved\n",
      "Validation loss 0.9987146978648108 NOT improved\n",
      "Validation loss 0.9990682139542829 NOT improved\n",
      "Validation loss 0.999241534957789 NOT improved\n",
      "Validation loss 0.9921186324012106 NOT improved\n",
      "Validation loss 0.9821141303758836 NOT improved\n",
      "Validation loss 0.9967067038833635 NOT improved\n",
      "Validation loss 0.9963899039046323 NOT improved\n",
      "Validation loss 0.9966298040499842 NOT improved\n",
      "Validation loss 0.9848167078258795 NOT improved\n",
      "Validation loss 0.9940140574656424 NOT improved\n",
      "Validation loss 0.9864215854091071 NOT improved\n",
      "Validation loss 0.9671935799592475 NOT improved\n",
      "Validation loss 0.9927952010570288 NOT improved\n",
      "Validation loss 1.0446883421255198 NOT improved\n",
      "Early stopping\n",
      "Training round 9\n",
      "Validation loss 0.9997062724299806 NOT improved\n",
      "Validation loss 0.999783776314368 NOT improved\n",
      "Validation loss 0.9998370535640445 NOT improved\n",
      "Validation loss 0.9998595907933295 NOT improved\n",
      "Validation loss 0.9998831335953203 NOT improved\n",
      "Validation loss 0.9998780267444577 NOT improved\n",
      "Validation loss 0.9998712343911199 NOT improved\n",
      "Validation loss 0.9998801791822812 NOT improved\n",
      "Validation loss 0.9998479798477299 NOT improved\n",
      "Validation loss 0.999852984257601 NOT improved\n",
      "Validation loss 0.9998427263126991 NOT improved\n",
      "Validation loss 0.9998276608973995 NOT improved\n",
      "Validation loss 0.9997968306709857 NOT improved\n",
      "Validation loss 0.9997014086810384 NOT improved\n",
      "Validation loss 0.9997628248038168 NOT improved\n",
      "Validation loss 0.9996666248287955 NOT improved\n",
      "Validation loss 0.9996412492172533 NOT improved\n",
      "Validation loss 0.9996164435961441 NOT improved\n",
      "Validation loss 0.9992550301207083 NOT improved\n",
      "Validation loss 0.9994049377398212 NOT improved\n",
      "Validation loss 0.9989761691900662 NOT improved\n",
      "Validation loss 0.9996539603792645 NOT improved\n",
      "Validation loss 0.9978598657645507 NOT improved\n",
      "Validation loss 0.9989344858212093 NOT improved\n",
      "Validation loss 0.9991817331384971 NOT improved\n",
      "Validation loss 0.9990200382035771 NOT improved\n",
      "Validation loss 0.9938909465889166 NOT improved\n",
      "Validation loss 0.9952876425848918 NOT improved\n",
      "Validation loss 0.9929043820327782 NOT improved\n",
      "Validation loss 0.9743921673221985 NOT improved\n",
      "Validation loss 0.9587251793946785 NOT improved\n",
      "Validation loss 0.9801649042175367 NOT improved\n",
      "Validation loss 0.9894291511620151 NOT improved\n",
      "Validation loss 0.9447664407401186 NOT improved\n",
      "Validation loss 0.9891374031188739 NOT improved\n",
      "Validation loss 0.9689936228355158 NOT improved\n",
      "Validation loss 0.933220009297583 NOT improved\n",
      "Validation loss 0.9489498065946176 NOT improved\n",
      "Validation loss 0.996238627560345 NOT improved\n",
      "Validation loss 0.9825944475641802 NOT improved\n",
      "Validation loss 0.9908097530798252 NOT improved\n",
      "Validation loss 0.9242268757102592 NOT improved\n",
      "Validation loss 1.381973620336819 NOT improved\n",
      "Early stopping\n",
      "Training round 10\n",
      "Validation loss 0.9995745046274768 NOT improved\n",
      "Validation loss 0.9998032091139927 NOT improved\n",
      "Validation loss 0.9998641359236327 NOT improved\n",
      "Validation loss 0.9998850372963336 NOT improved\n",
      "Validation loss 0.9998850829478279 NOT improved\n",
      "Validation loss 0.9998844312412588 NOT improved\n",
      "Validation loss 0.9998802101214721 NOT improved\n",
      "Validation loss 0.9998936030549539 NOT improved\n",
      "Validation loss 0.9998592528555145 NOT improved\n",
      "Validation loss 0.9998503945012795 NOT improved\n",
      "Validation loss 0.9998435833426129 NOT improved\n",
      "Validation loss 0.9998024938540969 NOT improved\n",
      "Validation loss 0.9998297588150592 NOT improved\n",
      "Validation loss 0.9997705046391697 NOT improved\n",
      "Validation loss 0.9997541418831232 NOT improved\n",
      "Validation loss 0.999708615772141 NOT improved\n",
      "Validation loss 0.9993627852195128 NOT improved\n",
      "Validation loss 0.9995019588432775 NOT improved\n",
      "Validation loss 0.99914482922182 NOT improved\n",
      "Validation loss 0.9994639022907229 NOT improved\n",
      "Validation loss 0.9991011939946428 NOT improved\n",
      "Validation loss 0.9990301231386542 NOT improved\n",
      "Validation loss 0.9987571360341986 NOT improved\n",
      "Validation loss 0.9946052025492319 NOT improved\n",
      "Validation loss 0.9992197549741761 NOT improved\n",
      "Validation loss 0.9937154245373455 NOT improved\n",
      "Validation loss 0.9971228466405058 NOT improved\n",
      "Validation loss 0.9968261872327655 NOT improved\n",
      "Validation loss 0.993041294228071 NOT improved\n",
      "Validation loss 0.9887454847505884 NOT improved\n",
      "Validation loss 0.9935857831827102 NOT improved\n",
      "Validation loss 0.9672675443410851 NOT improved\n",
      "Validation loss 0.9857334558316715 NOT improved\n",
      "Validation loss 0.9977917052448971 NOT improved\n",
      "Validation loss 0.9119229624012217 NOT improved\n",
      "Validation loss 0.9375229885771124 NOT improved\n",
      "Validation loss 0.970341337303063 NOT improved\n",
      "Validation loss 0.9957938872645318 NOT improved\n",
      "Validation loss 0.950542272254966 NOT improved\n",
      "Validation loss 0.9782118410872083 NOT improved\n",
      "Validation loss 1.562712948183064 NOT improved\n",
      "Early stopping\n",
      "Training round 11\n",
      "Validation loss 0.9996919911998683 NOT improved\n",
      "Validation loss 0.9997864339196011 NOT improved\n",
      "Validation loss 0.9998206561571863 NOT improved\n",
      "Validation loss 0.9998474484940545 NOT improved\n",
      "Validation loss 0.9998724161237545 NOT improved\n",
      "Validation loss 0.9998744858151914 NOT improved\n",
      "Validation loss 0.9998736938546569 NOT improved\n",
      "Validation loss 0.9998471166964271 NOT improved\n",
      "Validation loss 0.999854809697271 NOT improved\n",
      "Validation loss 0.9998527488582268 NOT improved\n",
      "Validation loss 0.9998453921629388 NOT improved\n",
      "Validation loss 0.9997373843650857 NOT improved\n",
      "Validation loss 0.9997220938359893 NOT improved\n",
      "Validation loss 0.9997830181786465 NOT improved\n",
      "Validation loss 0.999810335220322 NOT improved\n",
      "Validation loss 0.9994999370744494 NOT improved\n",
      "Validation loss 0.9994758669872368 NOT improved\n",
      "Validation loss 0.9994820492566578 NOT improved\n",
      "Validation loss 0.999375183701839 NOT improved\n",
      "Validation loss 0.9990855796030562 NOT improved\n",
      "Validation loss 0.9993601483136341 NOT improved\n",
      "Validation loss 0.9987988153255857 NOT improved\n",
      "Validation loss 0.9959249226907937 NOT improved\n",
      "Validation loss 0.9988434284045967 NOT improved\n",
      "Validation loss 0.9940610278316357 NOT improved\n",
      "Validation loss 0.9967943244137487 NOT improved\n",
      "Validation loss 0.9857665887831425 NOT improved\n",
      "Validation loss 0.9962267787205622 NOT improved\n",
      "Validation loss 0.989775341342888 NOT improved\n",
      "Validation loss 0.9958809482117782 NOT improved\n",
      "Validation loss 0.9922989819195394 NOT improved\n",
      "Validation loss 0.9519313518554114 NOT improved\n",
      "Validation loss 0.9462380758676491 NOT improved\n",
      "Validation loss improved from 0.9079230480428345 to 0.9053355015935326\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.639919996261597 seconds ---\n",
      "Validation loss 0.9977195984176651 NOT improved\n",
      "Validation loss 0.9144287229697868 NOT improved\n",
      "Validation loss 0.9331422189947423 NOT improved\n",
      "Validation loss 0.988118082048879 NOT improved\n",
      "Validation loss 0.9080056003066097 NOT improved\n",
      "Validation loss 5.001451916064339 NOT improved\n",
      "Early stopping\n",
      "Training round 12\n",
      "Validation loss 0.9997121649031667 NOT improved\n",
      "Validation loss 0.9998021068894714 NOT improved\n",
      "Validation loss 0.9998572344464279 NOT improved\n",
      "Validation loss 0.9998801429247008 NOT improved\n",
      "Validation loss 0.9998943666210938 NOT improved\n",
      "Validation loss 0.9998828671697444 NOT improved\n",
      "Validation loss 0.9998784688561698 NOT improved\n",
      "Validation loss 0.9998752688184009 NOT improved\n",
      "Validation loss 0.9998774798084871 NOT improved\n",
      "Validation loss 0.9998539109866104 NOT improved\n",
      "Validation loss 0.9998377178959142 NOT improved\n",
      "Validation loss 0.9998040844684762 NOT improved\n",
      "Validation loss 0.9997831919319834 NOT improved\n",
      "Validation loss 0.9997602252297674 NOT improved\n",
      "Validation loss 0.9997366511886084 NOT improved\n",
      "Validation loss 0.9997598934178862 NOT improved\n",
      "Validation loss 0.999702488640454 NOT improved\n",
      "Validation loss 0.9995119022207857 NOT improved\n",
      "Validation loss 0.9995512858406262 NOT improved\n",
      "Validation loss 0.9993390556669801 NOT improved\n",
      "Validation loss 0.9992944047764213 NOT improved\n",
      "Validation loss 0.9990579317629737 NOT improved\n",
      "Validation loss 0.9992241902676542 NOT improved\n",
      "Validation loss 0.9990381138684706 NOT improved\n",
      "Validation loss 0.9978368658759446 NOT improved\n",
      "Validation loss 0.9966699555353198 NOT improved\n",
      "Validation loss 0.9975996992703992 NOT improved\n",
      "Validation loss 0.9968533762848333 NOT improved\n",
      "Validation loss 0.9921649727530869 NOT improved\n",
      "Validation loss 0.9878242447939231 NOT improved\n",
      "Validation loss 0.9954260596087867 NOT improved\n",
      "Validation loss 0.9919318608513165 NOT improved\n",
      "Validation loss 0.9940710070910455 NOT improved\n",
      "Validation loss 0.990731291030411 NOT improved\n",
      "Validation loss 0.9916132007764178 NOT improved\n",
      "Validation loss 0.9889217562656935 NOT improved\n",
      "Validation loss 0.9055209821577206 NOT improved\n",
      "Validation loss 0.987155456928735 NOT improved\n",
      "Validation loss 0.9949289067580768 NOT improved\n",
      "Validation loss 0.9454382750506184 NOT improved\n",
      "Validation loss 0.9704725666654829 NOT improved\n",
      "Validation loss 0.9915513930369951 NOT improved\n",
      "Validation loss 1.0046070914581586 NOT improved\n",
      "Validation loss 0.9180771951181314 NOT improved\n",
      "Validation loss 0.9310993641333694 NOT improved\n",
      "Validation loss 0.9747145961877384 NOT improved\n",
      "Validation loss 0.974120299376828 NOT improved\n",
      "Validation loss 1.851885559837618 NOT improved\n",
      "Early stopping\n",
      "Training round 13\n",
      "Validation loss 0.9997571012983764 NOT improved\n",
      "Validation loss 0.9997837330735159 NOT improved\n",
      "Validation loss 0.99983492863914 NOT improved\n",
      "Validation loss 0.9998515672146463 NOT improved\n",
      "Validation loss 0.9998628533041333 NOT improved\n",
      "Validation loss 0.9998695763628107 NOT improved\n",
      "Validation loss 0.9998658412979818 NOT improved\n",
      "Validation loss 0.9998755779006488 NOT improved\n",
      "Validation loss 0.9998687952581943 NOT improved\n",
      "Validation loss 0.9998377595741914 NOT improved\n",
      "Validation loss 0.999836923798449 NOT improved\n",
      "Validation loss 0.9998359091481246 NOT improved\n",
      "Validation loss 0.999801430657385 NOT improved\n",
      "Validation loss 0.9998017003456899 NOT improved\n",
      "Validation loss 0.9997175181161537 NOT improved\n",
      "Validation loss 0.9997570523775593 NOT improved\n",
      "Validation loss 0.9993230774943449 NOT improved\n",
      "Validation loss 0.9994448003918787 NOT improved\n",
      "Validation loss 0.9992561968068239 NOT improved\n",
      "Validation loss 0.9990021260175583 NOT improved\n",
      "Validation loss 0.9992535882214701 NOT improved\n",
      "Validation loss 0.9990994045107533 NOT improved\n",
      "Validation loss 0.9976920247324893 NOT improved\n",
      "Validation loss 0.9990035364570642 NOT improved\n",
      "Validation loss 0.9886799280597146 NOT improved\n",
      "Validation loss 0.978599095092558 NOT improved\n",
      "Validation loss 0.9913274647531531 NOT improved\n",
      "Validation loss 0.9974383415814762 NOT improved\n",
      "Validation loss 0.9952640183551412 NOT improved\n",
      "Validation loss 0.9909314270824433 NOT improved\n",
      "Validation loss 0.9948952972745133 NOT improved\n",
      "Validation loss 1.2679061674059098 NOT improved\n",
      "Early stopping\n",
      "Training round 14\n",
      "Validation loss 0.9997262806434876 NOT improved\n",
      "Validation loss 0.999811831090256 NOT improved\n",
      "Validation loss 0.9998416169564484 NOT improved\n",
      "Validation loss 0.9998559632566053 NOT improved\n",
      "Validation loss 0.9998626586400973 NOT improved\n",
      "Validation loss 0.9998879867232695 NOT improved\n",
      "Validation loss 0.9998873908030457 NOT improved\n",
      "Validation loss 0.9998766119796256 NOT improved\n",
      "Validation loss 0.9998755210637773 NOT improved\n",
      "Validation loss 0.9998554746067435 NOT improved\n",
      "Validation loss 0.9998233165445926 NOT improved\n",
      "Validation loss 0.9998533195487057 NOT improved\n",
      "Validation loss 0.999852087809014 NOT improved\n",
      "Validation loss 0.9997411465982436 NOT improved\n",
      "Validation loss 0.9997867995670152 NOT improved\n",
      "Validation loss 0.9994912623902491 NOT improved\n",
      "Validation loss 0.9997563334247958 NOT improved\n",
      "Validation loss 0.9995540012735507 NOT improved\n",
      "Validation loss 0.9993710831035268 NOT improved\n",
      "Validation loss 0.9989804381004769 NOT improved\n",
      "Validation loss 0.999541813196578 NOT improved\n",
      "Validation loss 0.9980592963569717 NOT improved\n",
      "Validation loss 0.995550439830745 NOT improved\n",
      "Validation loss 0.9961924945031251 NOT improved\n",
      "Validation loss 0.99690282330049 NOT improved\n",
      "Validation loss 0.9978883981194837 NOT improved\n",
      "Validation loss 0.9948562386859551 NOT improved\n",
      "Validation loss 0.9864732436994791 NOT improved\n",
      "Validation loss 0.9920763689409818 NOT improved\n",
      "Validation loss 0.9266847667965891 NOT improved\n",
      "Validation loss 0.9776096563075287 NOT improved\n",
      "Validation loss 0.9746795411569161 NOT improved\n",
      "Validation loss 0.9161794985674638 NOT improved\n",
      "Validation loss 0.9396777799287928 NOT improved\n",
      "Validation loss 0.9788834482651021 NOT improved\n",
      "Validation loss 0.9767084992379266 NOT improved\n",
      "Validation loss 0.9753645242503389 NOT improved\n",
      "Validation loss 0.9463527577503971 NOT improved\n",
      "Validation loss 0.9231274489812744 NOT improved\n",
      "Validation loss 0.9686956890998507 NOT improved\n",
      "Validation loss 0.9246282744078451 NOT improved\n",
      "Validation loss 0.9306468774872114 NOT improved\n",
      "Validation loss 0.9443073099820427 NOT improved\n",
      "Validation loss 0.9910145060761503 NOT improved\n",
      "Validation loss 0.969735210108879 NOT improved\n",
      "Validation loss 7.468285476042365 NOT improved\n",
      "Early stopping\n",
      "Training round 15\n",
      "Validation loss 0.9995116004696936 NOT improved\n",
      "Validation loss 0.9997764521463238 NOT improved\n",
      "Validation loss 0.9998507070782837 NOT improved\n",
      "Validation loss 0.9998660247809438 NOT improved\n",
      "Validation loss 0.9998762560174445 NOT improved\n",
      "Validation loss 0.9998732607473337 NOT improved\n",
      "Validation loss 0.9998704648493684 NOT improved\n",
      "Validation loss 0.9998469344041373 NOT improved\n",
      "Validation loss 0.9998233755056749 NOT improved\n",
      "Validation loss 0.9997811646670001 NOT improved\n",
      "Validation loss 0.9998165232799181 NOT improved\n",
      "Validation loss 0.9997777203610003 NOT improved\n",
      "Validation loss 0.9997351085728033 NOT improved\n",
      "Validation loss 0.9996479630408129 NOT improved\n",
      "Validation loss 0.9996587789877748 NOT improved\n",
      "Validation loss 0.9994592458082415 NOT improved\n",
      "Validation loss 0.9993803639814479 NOT improved\n",
      "Validation loss 0.9994745655870565 NOT improved\n",
      "Validation loss 0.9991734633394792 NOT improved\n",
      "Validation loss 0.998207520124486 NOT improved\n",
      "Validation loss 0.9973440879805832 NOT improved\n",
      "Validation loss 0.9994578392470354 NOT improved\n",
      "Validation loss 0.9988416506373407 NOT improved\n",
      "Validation loss 0.9987307224212 NOT improved\n",
      "Validation loss 0.9980337112244271 NOT improved\n",
      "Validation loss 0.9742940983502953 NOT improved\n",
      "Validation loss 0.993136091726977 NOT improved\n",
      "Validation loss 0.9957946385142097 NOT improved\n",
      "Validation loss 0.9911357603625576 NOT improved\n",
      "Validation loss 0.967882578870084 NOT improved\n",
      "Validation loss 0.9722847491437419 NOT improved\n",
      "Validation loss 0.9885048107373947 NOT improved\n",
      "Validation loss 0.9889771348906355 NOT improved\n",
      "Validation loss improved from 0.9053355015935326 to 0.9052048760836047\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/alt_lead22\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/alt_lead22/assets\n",
      "--- 6.9355409145355225 seconds ---\n",
      "Validation loss 0.9971046237241642 NOT improved\n",
      "Validation loss 0.9817529264224819 NOT improved\n",
      "Validation loss 0.9539129599800434 NOT improved\n",
      "Validation loss 0.9146325526537548 NOT improved\n",
      "Validation loss 1.4362275521175123 NOT improved\n",
      "Early stopping\n",
      "Training round 16\n",
      "Validation loss 0.9996495493800367 NOT improved\n",
      "Validation loss 0.9997857442700321 NOT improved\n",
      "Validation loss 0.9998326744950338 NOT improved\n",
      "Validation loss 0.9998471992231747 NOT improved\n",
      "Validation loss 0.9998603995468526 NOT improved\n",
      "Validation loss 0.9998761276350022 NOT improved\n",
      "Validation loss 0.9998578782044895 NOT improved\n",
      "Validation loss 0.9998461283402954 NOT improved\n",
      "Validation loss 0.999864917312642 NOT improved\n",
      "Validation loss 0.9998399689516518 NOT improved\n",
      "Validation loss 0.9998064882481871 NOT improved\n",
      "Validation loss 0.9998115839513001 NOT improved\n",
      "Validation loss 0.9997811257084731 NOT improved\n",
      "Validation loss 0.9998169993663347 NOT improved\n",
      "Validation loss 0.9997520371588942 NOT improved\n",
      "Validation loss 0.9995697709172825 NOT improved\n",
      "Validation loss 0.9992933859487882 NOT improved\n",
      "Validation loss 0.9996067747667944 NOT improved\n",
      "Validation loss 0.999277502864173 NOT improved\n",
      "Validation loss 0.9993739771823041 NOT improved\n",
      "Validation loss 0.9978842669529496 NOT improved\n",
      "Validation loss 0.9988065124048515 NOT improved\n",
      "Validation loss 0.9993876299507072 NOT improved\n",
      "Validation loss 0.9926534340603881 NOT improved\n",
      "Validation loss 0.9922221907581815 NOT improved\n",
      "Validation loss 0.9981131519829008 NOT improved\n",
      "Validation loss 0.9904995564536169 NOT improved\n",
      "Validation loss 0.9966811542089431 NOT improved\n",
      "Validation loss 0.9285812474325003 NOT improved\n",
      "Validation loss 0.9962411625906656 NOT improved\n",
      "Validation loss 0.9849861943349907 NOT improved\n",
      "Validation loss 0.9753768612508896 NOT improved\n",
      "Validation loss 0.9128680353554028 NOT improved\n",
      "Validation loss 0.9755444359615 NOT improved\n",
      "Validation loss 0.9268449366648731 NOT improved\n",
      "Validation loss 3.1074076798817445 NOT improved\n",
      "Early stopping\n",
      "Training round 17\n",
      "Validation loss 0.9997221264226692 NOT improved\n",
      "Validation loss 0.9998181030462668 NOT improved\n",
      "Validation loss 0.9998644921497095 NOT improved\n",
      "Validation loss 0.999880454688585 NOT improved\n",
      "Validation loss 0.9998810078970722 NOT improved\n",
      "Validation loss 0.9998632795335753 NOT improved\n",
      "Validation loss 0.9998688392614615 NOT improved\n",
      "Validation loss 0.9998607767439567 NOT improved\n",
      "Validation loss 0.999860746423381 NOT improved\n",
      "Validation loss 0.9998510349847156 NOT improved\n",
      "Validation loss 0.9998199269126351 NOT improved\n",
      "Validation loss 0.9998111653055768 NOT improved\n",
      "Validation loss 0.9998045985574974 NOT improved\n",
      "Validation loss 0.9996735399687626 NOT improved\n",
      "Validation loss 0.9997651002961915 NOT improved\n",
      "Validation loss 0.999480837112481 NOT improved\n",
      "Validation loss 0.9995990485355666 NOT improved\n",
      "Validation loss 0.9995248531499864 NOT improved\n",
      "Validation loss 0.9995813024190788 NOT improved\n",
      "Validation loss 0.9979384382517367 NOT improved\n",
      "Validation loss 0.9981219401642228 NOT improved\n",
      "Validation loss 0.9984651898718381 NOT improved\n",
      "Validation loss 0.9989797797445163 NOT improved\n",
      "Validation loss 0.9963716711079973 NOT improved\n",
      "Validation loss 0.998334678909735 NOT improved\n",
      "Validation loss 0.9976662378029241 NOT improved\n",
      "Validation loss 0.9972583035959542 NOT improved\n",
      "Validation loss 0.9979969395167534 NOT improved\n",
      "Validation loss 0.9646644069798228 NOT improved\n",
      "Validation loss 0.9958741216682208 NOT improved\n",
      "Validation loss 0.9991009187083328 NOT improved\n",
      "Validation loss 0.9959847935984293 NOT improved\n",
      "Validation loss 0.9832595824408656 NOT improved\n",
      "Validation loss 0.986071218824006 NOT improved\n",
      "Validation loss 0.9837463978387379 NOT improved\n",
      "Validation loss 0.9960855462370197 NOT improved\n",
      "Validation loss 0.9635060190878584 NOT improved\n",
      "Validation loss 0.9417253408612599 NOT improved\n",
      "Validation loss 0.956414218505225 NOT improved\n",
      "Validation loss 0.9287400335455142 NOT improved\n",
      "Validation loss 1.4725805838117414 NOT improved\n",
      "Early stopping\n",
      "Training round 18\n",
      "Validation loss 0.9995479973709048 NOT improved\n",
      "Validation loss 0.9998145500795141 NOT improved\n",
      "Validation loss 0.9998775904078917 NOT improved\n",
      "Validation loss 0.9998933936968745 NOT improved\n",
      "Validation loss 0.9998848146746118 NOT improved\n",
      "Validation loss 0.9998783238122299 NOT improved\n",
      "Validation loss 0.9998799120488133 NOT improved\n",
      "Validation loss 0.9998824291164204 NOT improved\n",
      "Validation loss 0.9998571604109451 NOT improved\n",
      "Validation loss 0.9998608904831197 NOT improved\n",
      "Validation loss 0.9998823734963943 NOT improved\n",
      "Validation loss 0.9998587979323439 NOT improved\n",
      "Validation loss 0.9998551027598959 NOT improved\n",
      "Validation loss 0.9998185518155064 NOT improved\n",
      "Validation loss 0.9997086602507403 NOT improved\n",
      "Validation loss 0.9998215644913925 NOT improved\n",
      "Validation loss 0.9996445489975806 NOT improved\n",
      "Validation loss 0.9995651038919432 NOT improved\n",
      "Validation loss 0.9995017657520371 NOT improved\n",
      "Validation loss 0.9992566040119933 NOT improved\n",
      "Validation loss 0.9989651442013916 NOT improved\n",
      "Validation loss 0.9991192268514388 NOT improved\n",
      "Validation loss 0.999005692407962 NOT improved\n",
      "Validation loss 0.9961885651154793 NOT improved\n",
      "Validation loss 0.9957512297143383 NOT improved\n",
      "Validation loss 0.9968943175293599 NOT improved\n",
      "Validation loss 0.9976122910008173 NOT improved\n",
      "Validation loss 0.9932657841190914 NOT improved\n",
      "Validation loss 0.9463627072675248 NOT improved\n",
      "Validation loss 0.9873353176767655 NOT improved\n",
      "Validation loss 0.9940346282793202 NOT improved\n",
      "Validation loss 0.9409726350791171 NOT improved\n",
      "Validation loss 0.9663912596657244 NOT improved\n",
      "Validation loss 0.955097098212592 NOT improved\n",
      "Validation loss 0.991085201134446 NOT improved\n",
      "Validation loss 0.9974967089772026 NOT improved\n",
      "Validation loss 0.9424528523588251 NOT improved\n",
      "Validation loss 0.9965420103689102 NOT improved\n",
      "Validation loss 0.980405474941353 NOT improved\n",
      "Validation loss 0.9070783152613509 NOT improved\n",
      "Validation loss 0.9163843651646341 NOT improved\n",
      "Validation loss 0.9292793407894059 NOT improved\n",
      "Validation loss 0.9678522272268094 NOT improved\n",
      "Validation loss 0.9591267400724798 NOT improved\n",
      "Validation loss 0.9572589513462597 NOT improved\n",
      "Validation loss 1.3772863334244003 NOT improved\n",
      "Early stopping\n",
      "Training round 19\n",
      "Validation loss 0.9996489404441293 NOT improved\n",
      "Validation loss 0.9998092341481466 NOT improved\n",
      "Validation loss 0.9998748682900941 NOT improved\n",
      "Validation loss 0.9998892903756347 NOT improved\n",
      "Validation loss 0.9998945343390259 NOT improved\n",
      "Validation loss 0.9999037076618361 NOT improved\n",
      "Validation loss 0.999900204758272 NOT improved\n",
      "Validation loss 0.9998931725913927 NOT improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [12342, 2536234, 98765, 473, 865, 7456, 69472, 3456357, 3425, 678,\n",
    "         2452624, 5787, 235362, 67896, 98454, 12445, 46767, 78906, 345, 8695, \n",
    "         2463725, 4734, 23234, 884, 2341, 362, 5, 234, 483, 785356, 23425, 3621, \n",
    "         58461, 80968765, 123, 425633, 5646, 67635, 76785, 34214]\n",
    "\n",
    "training_rounds = len(seeds)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "\n",
    "# =========== Model Section ========== #\n",
    "\n",
    "batch_dir = '/glade/scratch/ksha/DATA/NCAR_batch/'\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = '{}_lead{}'.format(model_tag, lead_name)\n",
    "\n",
    "model_name = '{}'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "tol = 0\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "L_pos = len(TRAIN_256_pos)\n",
    "L_neg = len(TRAIN_256_neg)\n",
    "\n",
    "record = 1.1\n",
    "print(\"Initial record: {}\".format(record))\n",
    "\n",
    "min_del = 0\n",
    "max_tol = 100 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "L_train = 16\n",
    "\n",
    "for r in range(training_rounds):\n",
    "    if r == 0:\n",
    "        tol = 0\n",
    "    else:\n",
    "        tol = -200\n",
    "\n",
    "    model = create_model()\n",
    "    #\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=keras.optimizers.Adam(lr=1e-4))\n",
    "    \n",
    "    set_seeds(int(seeds[r]))\n",
    "    print('Training round {}'.format(r))\n",
    "\n",
    "    for i in range(epochs):            \n",
    "        start_time = time.time()\n",
    "\n",
    "        # loop of batch\n",
    "        for j in range(L_train):\n",
    "            N_pos = 32\n",
    "            N_neg = batch_size - N_pos\n",
    "\n",
    "            ind_neg = du.shuffle_ind(L_neg)\n",
    "            ind_pos = du.shuffle_ind(L_pos)\n",
    "\n",
    "            ind_neg_pick = ind_neg[:N_neg]\n",
    "            ind_pos_pick = ind_pos[:N_pos]\n",
    "\n",
    "            X_batch_neg = TRAIN_256_neg[ind_neg_pick, :]\n",
    "            X_batch_pos = TRAIN_256_pos[ind_pos_pick, :]\n",
    "            \n",
    "            X_batch_stn_neg = TRAIN_stn_neg[ind_neg_pick, :]\n",
    "            X_batch_stn_pos = TRAIN_stn_pos[ind_pos_pick, :]\n",
    "\n",
    "            X_batch = np.concatenate((X_batch_neg, X_batch_pos), axis=0)\n",
    "            X_batch_stn = np.concatenate((X_batch_stn_neg, X_batch_stn_pos), axis=0)\n",
    "\n",
    "            Y_batch = np.ones([batch_size,])\n",
    "            Y_batch[:N_neg] = 0.0\n",
    "\n",
    "            ind_ = du.shuffle_ind(batch_size)\n",
    "\n",
    "            X_batch = X_batch[ind_, :]\n",
    "            X_batch_stn = X_batch_stn[ind_, :]\n",
    "            Y_batch = Y_batch[ind_]\n",
    "\n",
    "            # train on batch\n",
    "            model.train_on_batch([X_batch, X_batch_stn], Y_batch);\n",
    "\n",
    "        # epoch end operations\n",
    "        Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "\n",
    "        Y_pred[Y_pred<0] = 0\n",
    "        Y_pred[Y_pred>1] = 1\n",
    "\n",
    "        record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n",
    "        # if i % 10 == 0:\n",
    "        #     model.save(model_path_backup)\n",
    "\n",
    "        if (record - record_temp > min_del):\n",
    "            print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "            record = record_temp\n",
    "            tol = 0\n",
    "            \n",
    "            #print('tol: {}'.format(tol))\n",
    "            # save\n",
    "            print('save to: {}'.format(model_path))\n",
    "            model.save(model_path)\n",
    "        else:\n",
    "            print('Validation loss {} NOT improved'.format(record_temp))\n",
    "            if record_temp > 1.01:\n",
    "                print('Early stopping')\n",
    "                break;\n",
    "            else:\n",
    "                tol += 1\n",
    "                if tol >= max_tol:\n",
    "                    print('Early stopping')\n",
    "                    break;\n",
    "                else:\n",
    "                    continue;\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba732cc-cef9-43ff-89ff-0fb00f59075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964176a0-95be-4e49-81c4-7a659751d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27199f0a-0bd1-490b-b929-922a8a39a1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427b0011-7eee-4cca-a80a-ed37a18c5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=keras.optimizers.Adam(lr=0))\n",
    "\n",
    "W_old = k_utils.dummy_loader('/glade/work/ksha/NCAR/Keras_models/alt_lead{}/'.format(lead_name))\n",
    "model.set_weights(W_old)\n",
    "\n",
    "ref = np.sum(VALID_Y) / len(VALID_Y)\n",
    "Y_pred = model.predict([VALID_X, VALID_merge])\n",
    "record_temp = verif_metric(VALID_Y, Y_pred, ref)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb05d2d-092a-4702-a245-fea6f96ffe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/NCAR/RESULT_FULL_lead22_alt.npy\n"
     ]
    }
   ],
   "source": [
    "save_dict = {}\n",
    "save_dict['Y_pred'] = Y_pred\n",
    "save_dict['VALID_Y'] = VALID_Y\n",
    "np.save('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag), save_dict)\n",
    "print('{}RESULT_FULL_lead{}_{}.npy'.format(filepath_vec, lead_name, model_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60af67c-8780-42cf-ab0a-d6434b1b5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052048760836047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b4252-b6b6-441e-abb0-c0bca38f3471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ec269e-6211-4a90-a8d9-fa78fc3f33ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0a64be13d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94898f-0118-4b3e-91e7-c7b8f07b5187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a664b-35c5-4d13-bd1d-63fdfac63233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469f1cd-f820-44a1-9ba6-4f228782f813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba0e7c-4640-4e65-b675-995d3a1a06d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e5327-70b2-4ba4-94bc-f1e37f04bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d4ab4-6e8d-49fb-adb5-29205a17e6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf3bf0-b6ad-4be6-b2f4-3bead7aaa672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b6f27-7551-4a81-8669-3482c0da28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca671f-cd07-4052-85c6-10c359bc8c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
