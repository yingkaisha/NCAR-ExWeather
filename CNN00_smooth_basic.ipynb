{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7085e38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14320\\4214788644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnamelist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import re\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== #\n",
    "weights_round = 0\n",
    "save_round = 1\n",
    "seeds = 777\n",
    "model_prefix_load = 'RE2_peak2_base{}'.format(weights_round) #False\n",
    "model_prefix_save = 'RE2_smooth_base{}'.format(save_round)\n",
    "N_vars = L_vars = 15\n",
    "# ==================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------- #\n",
    "# Collect pos and neg batch filenames\n",
    "\n",
    "vers = ['v3', 'v4x', 'v4'] # HRRR v4, v4x, v4\n",
    "leads = [2, 3, 4, 5, 6, 20, 21, 22, 23]\n",
    "\n",
    "filenames_pos = {}\n",
    "filenames_neg = {}\n",
    "\n",
    "# Identify and separate pos / neg batch files\n",
    "for ver in vers:\n",
    "    for lead in leads:\n",
    "        if ver == 'v3':\n",
    "            path_ = path_batch_v3\n",
    "        elif ver == 'v4':\n",
    "            path_ = path_batch_v4\n",
    "        else:\n",
    "            path_ = path_batch_v4x\n",
    "            \n",
    "        filenames_pos['{}_lead{}'.format(ver, lead)] = sorted(glob(\"{}*pos*lead{}.npy\".format(path_, lead)))\n",
    "        filenames_neg['{}_lead{}'.format(ver, lead)] = sorted(glob(\"{}*neg_neg_neg*lead{}.npy\".format(path_, lead)))\n",
    "        \n",
    "        print('{}, lead{}, pos: {}, neg: {}'.format(ver, lead, len(filenames_pos['{}_lead{}'.format(ver, lead)]), \n",
    "                                             len(filenames_neg['{}_lead{}'.format(ver, lead)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9aed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------- #\n",
    "# Separate train and valid from pos / neg batches\n",
    "filenames_pos_train = {}\n",
    "filenames_neg_train = {}\n",
    "\n",
    "filenames_pos_valid = {}\n",
    "filenames_neg_valid = {}\n",
    "\n",
    "for ver in vers:\n",
    "    for lead in leads:\n",
    "        temp_namelist_pos = filenames_pos['{}_lead{}'.format(ver, lead)]\n",
    "        temp_namelist_neg = filenames_neg['{}_lead{}'.format(ver, lead)]\n",
    "        \n",
    "        pos_train, pos_valid = mu.name_extract(temp_namelist_pos)\n",
    "        neg_train, neg_valid = mu.name_extract(temp_namelist_neg)\n",
    "        \n",
    "        print('pos train: {} pos valid: {} neg train: {} neg valid {}'.format(len(pos_train), len(pos_valid), len(neg_train),len(neg_valid)))\n",
    "        \n",
    "        filenames_pos_train['{}_lead{}'.format(ver, lead)] = pos_train\n",
    "        filenames_neg_train['{}_lead{}'.format(ver, lead)] = neg_train\n",
    "        \n",
    "        filenames_pos_valid['{}_lead{}'.format(ver, lead)] = pos_valid\n",
    "        filenames_neg_valid['{}_lead{}'.format(ver, lead)] = neg_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------ #\n",
    "# Merge train/valid and pos/neg batch files from multiple lead times\n",
    "pos_train_all = []\n",
    "neg_train_all = []\n",
    "pos_valid_all = []\n",
    "neg_valid_all = []\n",
    "\n",
    "for ver in vers:\n",
    "    for lead in leads:\n",
    "        pos_train_all += filenames_pos_train['{}_lead{}'.format(ver, lead)]\n",
    "        neg_train_all += filenames_neg_train['{}_lead{}'.format(ver, lead)]\n",
    "        pos_valid_all += filenames_pos_valid['{}_lead{}'.format(ver, lead)]\n",
    "        neg_valid_all += filenames_neg_valid['{}_lead{}'.format(ver, lead)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930092a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6154a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbour_leads(lead):\n",
    "    out = [lead-2, lead-1, lead, lead+1]\n",
    "    flag_shift = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        if out[i] < 0:\n",
    "            out[i] = 24+out[i]\n",
    "            flag_shift[i] = -1\n",
    "        if out[i] > 23:\n",
    "            out[i] = out[i]-24\n",
    "            flag_shift[i] = +1\n",
    "            \n",
    "    return out, flag_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff23d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_smooth_v3 = ()\n",
    "label_smooth_v4x = ()\n",
    "label_smooth_v4 = ()\n",
    "\n",
    "for lead in leads:\n",
    "\n",
    "    lead_window, flag_shift = neighbour_leads(lead)\n",
    "    \n",
    "    print('Collect HRRR v3 labels ...')\n",
    "    \n",
    "    record_all = ()\n",
    "\n",
    "    for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "        flag_ = flag_shift[i]\n",
    "\n",
    "        with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_all.hdf'.format(lead_temp), 'r') as h5io:\n",
    "            record_temp = h5io['record_v3'][...]\n",
    "\n",
    "        if flag_shift[i] == 0:\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == -1:\n",
    "            record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "            record_temp[0, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == +1:\n",
    "            record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "            record_temp[-1, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "\n",
    "    shape_record = record_temp.shape      \n",
    "    record_v3 = np.empty(shape_record)\n",
    "    record_v3[...] = 0.0 #np.nan\n",
    "\n",
    "    for i in range(4):\n",
    "        record_temp = record_all[i]\n",
    "        for day in range(shape_record[0]):\n",
    "            for ix in range(shape_record[1]):\n",
    "                for iy in range(shape_record[2]):\n",
    "                    for event in range(shape_record[3]):\n",
    "                        if record_temp[day, ix, iy, event] > 0:\n",
    "                            record_v3[day, ix, iy, event] = 1.0\n",
    "                        elif record_v3[day, ix, iy, event] == 1.0:\n",
    "                            record_v3[day, ix, iy, event] = 1.0\n",
    "                        else:\n",
    "                            record_v3[day, ix, iy, event] = 0.0\n",
    "    \n",
    "    label_smooth_v3 += (record_v3[None, ...],)\n",
    "    \n",
    "    print('... Done. Collect HRRR v4x labels ...')\n",
    "    \n",
    "    record_all = ()\n",
    "\n",
    "    for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "        flag_ = flag_shift[i]\n",
    "\n",
    "        with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_v4x.hdf'.format(lead_temp), 'r') as h5io:\n",
    "            record_temp = h5io['record_v4x'][...]\n",
    "\n",
    "        if flag_shift[i] == 0:\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == -1:\n",
    "            record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "            record_temp[0, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == +1:\n",
    "            record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "            record_temp[-1, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "\n",
    "    shape_record = record_temp.shape      \n",
    "    record_v4x = np.empty(shape_record)\n",
    "    record_v4x[...] = np.nan\n",
    "\n",
    "    for i in range(4):\n",
    "        record_temp = record_all[i]\n",
    "        for day in range(shape_record[0]):\n",
    "            for ix in range(shape_record[1]):\n",
    "                for iy in range(shape_record[2]):\n",
    "                    for event in range(shape_record[3]):\n",
    "                        if record_temp[day, ix, iy, event] > 0:\n",
    "                            record_v4x[day, ix, iy, event] = 1.0\n",
    "                        elif record_v4x[day, ix, iy, event] == 1.0:\n",
    "                            record_v4x[day, ix, iy, event] = 1.0\n",
    "                        else:\n",
    "                            record_v4x[day, ix, iy, event] = 0.0\n",
    "    \n",
    "    label_smooth_v4x += (record_v4x[None, ...],)\n",
    "    \n",
    "    print('... Done. Collect HRRR v4 labels ...')\n",
    "    \n",
    "    record_all = ()\n",
    "    \n",
    "    for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "        flag_ = flag_shift[i]\n",
    "\n",
    "        with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_all.hdf'.format(lead_temp), 'r') as h5io:\n",
    "            record_temp = h5io['record_v4'][...]\n",
    "\n",
    "        if flag_shift[i] == 0:\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == -1:\n",
    "            record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "            record_temp[0, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "\n",
    "        if flag_shift[i] == +1:\n",
    "            record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "            record_temp[-1, ...] = np.nan\n",
    "            record_all = record_all + (record_temp,)\n",
    "            \n",
    "            \n",
    "    shape_record = record_temp.shape      \n",
    "    record_v4 = np.empty(shape_record)\n",
    "    record_v4[...] = 0.0 #np.nan\n",
    "\n",
    "    for i in range(4):\n",
    "        record_temp = record_all[i]\n",
    "        for day in range(shape_record[0]):\n",
    "            for ix in range(shape_record[1]):\n",
    "                for iy in range(shape_record[2]):\n",
    "                    for event in range(shape_record[3]):\n",
    "                        if record_temp[day, ix, iy, event] > 0:\n",
    "                            record_v4[day, ix, iy, event] = 1.0\n",
    "                        elif record_v4[day, ix, iy, event] == 1.0:\n",
    "                            record_v4[day, ix, iy, event] = 1.0\n",
    "                        else:\n",
    "                            record_v4[day, ix, iy, event] = 0.0\n",
    "                            \n",
    "    label_smooth_v4 += (record_v4[None, ...],)\n",
    "    \n",
    "    print('... Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52156402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label smoothing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_concat_v3 = np.concatenate(label_smooth_v3, axis=0)\n",
    "label_concat_v4x = np.concatenate(label_smooth_v4x, axis=0)\n",
    "label_concat_v4 = np.concatenate(label_smooth_v4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc10b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_final = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_loc(filenames):\n",
    "    \n",
    "    indx_out = []\n",
    "    indy_out = []\n",
    "    day_out = []\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "      \n",
    "        indx_out.append(indx)\n",
    "        indy_out.append(indy)\n",
    "        day_out.append(day)\n",
    "        \n",
    "    return np.array(indx_out), np.array(indy_out), np.array(day_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e344aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_pos_train, indy_pos_train, day_pos_train = filename_to_loc(pos_train_all)\n",
    "indx_neg_train, indy_neg_train, day_neg_train = filename_to_loc(neg_train_all)\n",
    "\n",
    "indx_pos_valid, indy_pos_valid, day_pos_valid = filename_to_loc(pos_valid_all)\n",
    "indx_neg_valid, indy_neg_valid, day_neg_valid = filename_to_loc(neg_valid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos_train = label_final[day_pos_train, indx_pos_train, indy_pos_train]\n",
    "y_neg_train = label_final[day_neg_train, indx_neg_train, indy_neg_train]\n",
    "\n",
    "y_pos_valid = label_final[day_pos_valid, indx_pos_valid, indy_pos_valid]\n",
    "y_neg_valid = label_final[day_neg_valid, indx_neg_valid, indy_neg_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fad923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------- #\n",
    "# Load valid files for model training\n",
    "\n",
    "filename_valid = neg_valid_all[::130] + pos_valid_all[::13]\n",
    "L_valid = len(filename_valid)\n",
    "print('number of validation batches: {}'.format(L_valid))\n",
    "\n",
    "VALID_input_64 = np.empty((L_valid, 64, 64, L_vars))\n",
    "VALID_target = np.ones(L_valid)\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    data = np.load(name)\n",
    "    for k, c in enumerate(ind_pick_from_batch):\n",
    "        \n",
    "        VALID_input_64[i, ..., k] = data[..., c]\n",
    "\n",
    "        if 'pos' in name:\n",
    "            VALID_target[i] = 1.0\n",
    "        else:\n",
    "            VALID_target[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------- #\n",
    "# model and weights\n",
    "model_head = create_model_head(input_shape=(128,), N_node=64)\n",
    "model_base = create_model(input_shape=(64, 64, 15), depths=[3, 3, 27, 3], projection_dims=[32, 64, 96, 128])\n",
    "\n",
    "IN = layers.Input(shape=(64, 64, 15))\n",
    "\n",
    "VEC = model_base(IN)\n",
    "OUT = model_head(VEC)\n",
    "\n",
    "model_final = Model(inputs=IN, outputs=OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6a1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79db583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= #\n",
    "# Weights\n",
    "\n",
    "if weights_round == 0:\n",
    "    W_old = mu.dummy_loader('/glade/work/ksha/NCAR/Keras_models/RE2_peak_base5/')\n",
    "else:\n",
    "    if model_prefix_load:\n",
    "        W_old = mu.dummy_loader('/glade/work/ksha/NCAR/Keras_models/{}/'.format(model_prefix_load))\n",
    "    \n",
    "model_final.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(lr=1e-4))\n",
    "model_final.set_weights(W_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46875f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc105378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------- #\n",
    "# model training loop\n",
    "Y_pred = model_final.predict([VALID_input_64])\n",
    "record_temp = mu.verif_metric(VALID_target, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17de5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change based on smoothed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "min_del = 0.0\n",
    "max_tol = 100 # early stopping with patience\n",
    "batch_size = 200\n",
    "\n",
    "# Allocate batch files\n",
    "X_batch_64 = np.empty((batch_size, 64, 64, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch_64[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# Model check-point info\n",
    "model_name = model_prefix_save\n",
    "model_path = temp_dir + model_name\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "tol = 0 # initial tol\n",
    "\n",
    "filename_pos_train = pos_train_all\n",
    "filename_neg_train = neg_train_all\n",
    "L_pos = len(filename_pos_train)\n",
    "L_neg = len(filename_neg_train)\n",
    "\n",
    "record = record_temp\n",
    "print(\"Initial record: {}\".format(record))\n",
    "\n",
    "mu.set_seeds(seeds)\n",
    "    \n",
    "for i in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        N_pos = 20\n",
    "        N_neg = batch_size - N_pos\n",
    "\n",
    "        ind_neg = du.shuffle_ind(L_neg)\n",
    "        ind_pos = du.shuffle_ind(L_pos)\n",
    "        \n",
    "        # neg batches from this training rotation \n",
    "        file_pick_neg = []\n",
    "        for ind_temp in ind_neg[:N_neg]:\n",
    "            file_pick_neg.append(filename_neg_train[ind_temp])\n",
    "        # pos batches from this training rotation \n",
    "        file_pick_pos = []\n",
    "        for ind_temp in ind_pos[:N_pos]:\n",
    "            file_pick_pos.append(filename_pos_train[ind_temp])\n",
    "            \n",
    "        # get all the batch filenames for checking labels\n",
    "        file_pick = file_pick_neg + file_pick_pos\n",
    "\n",
    "#         if len(file_pick) != batch_size:\n",
    "#             sregwet # number of available files = batch size\n",
    "\n",
    "        # Assign labels based on batch filenames\n",
    "        for k in range(batch_size):\n",
    "            data = np.load(file_pick[k])\n",
    "            for l, c in enumerate(N_vars):\n",
    "                temp = data[..., c] \n",
    "                X_batch_64[k, ..., l] = temp\n",
    "\n",
    "            if 'pos' in file_pick[k]:\n",
    "                Y_batch[k, :] = 1.0 #np.random.uniform(0.9, 0.99)\n",
    "            elif 'neg_neg_neg' in file_pick[k]:\n",
    "                Y_batch[k, :] = 0.0 #np.random.uniform(0.01, 0.05)\n",
    "            else:\n",
    "                werhgaer\n",
    "        # ------------------------------------------------- #\n",
    "        # batch input and label from this training rotation \n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch_64 = X_batch_64[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "\n",
    "        # train on batch\n",
    "        model_final.train_on_batch(X_batch_64, Y_batch);\n",
    "\n",
    "    # epoch end operations\n",
    "    Y_pred = model_final.predict([VALID_input_64])\n",
    "    record_temp = mu.verif_metric(VALID_target, Y_pred)\n",
    "\n",
    "    if (record - record_temp > min_del):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model_final.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        if record_temp >= 2.0:\n",
    "            print('Early stopping')\n",
    "            break;\n",
    "        else:\n",
    "            tol += 1\n",
    "            if tol >= max_tol:\n",
    "                print('Early stopping')\n",
    "                break;\n",
    "            else:\n",
    "                continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153e75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920441c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcc4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2be21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65a950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
