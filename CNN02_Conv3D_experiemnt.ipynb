{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59173556",
   "metadata": {},
   "source": [
    "Not the best option for this problem, because of the mapping from 3d input to 2d output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import re\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f680819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CONV_stack(X, channel, kernel_size=3, stack_num=2, \n",
    "               dilation_rate=1, activation='ReLU', \n",
    "               batch_norm=False, name='conv_stack'):\n",
    "    '''\n",
    "    Stacked convolutional layers:\n",
    "    (Convolutional layer --> batch normalization --> Activation)*stack_num\n",
    "    \n",
    "    CONV_stack(X, channel, kernel_size=3, stack_num=2, dilation_rate=1, activation='ReLU', \n",
    "               batch_norm=False, name='conv_stack')\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "        X: input tensor.\n",
    "        channel: number of convolution filters.\n",
    "        kernel_size: size of 2-d convolution kernels.\n",
    "        stack_num: number of stacked Conv2D-BN-Activation layers.\n",
    "        dilation_rate: optional dilated convolution kernel.\n",
    "        activation: one of the `tensorflow.keras.layers` interface, e.g., ReLU.\n",
    "        batch_norm: True for batch normalization, False otherwise.\n",
    "        name: prefix of the created keras layers.\n",
    "        \n",
    "    Output\n",
    "    ----------\n",
    "        X: output tensor\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    bias_flag = not batch_norm\n",
    "    \n",
    "    # stacking Convolutional layers\n",
    "    for i in range(stack_num):\n",
    "        \n",
    "        activation_func = eval(activation)\n",
    "        \n",
    "        # linear convolution\n",
    "        X = Conv2D(channel, kernel_size, padding='same', use_bias=bias_flag, \n",
    "                   dilation_rate=dilation_rate, name='{}_{}'.format(name, i))(X)\n",
    "        \n",
    "        # batch normalization\n",
    "        if batch_norm:\n",
    "            X = BatchNormalization(axis=3, name='{}_{}_bn'.format(name, i))(X)\n",
    "        \n",
    "        # activation\n",
    "        activation_func = eval(activation)\n",
    "        X = activation_func(name='{}_{}_activation'.format(name, i))(X)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a589c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True\n",
    "bias_flag = False\n",
    "filter_num = [128, 64, 32]\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0097ddb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15012\\2454637191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_skip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdepth_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "input_tensor = keras.Input((None, None, None, 4, 15))\n",
    "\n",
    "X_skip = []\n",
    "depth_ = len(filter_num)\n",
    "\n",
    "X = input_tensor\n",
    "# stacked conv2d before downsampling\n",
    "# linear convolution\n",
    "X = Conv3D(filter_num[0], kernel_size, padding='same', use_bias=bias_flag,)(X)\n",
    "# batch normalization\n",
    "if batch_norm:\n",
    "    X = keras.layers.BatchNormalization(axis=-1)(X)        \n",
    "# activation\n",
    "X = keras.layers.Activation(\"gelu\")(X)\n",
    "\n",
    "X_skip.append(X)\n",
    "\n",
    "# downsampling blocks\n",
    "for i, f in enumerate(filter_num[1:]):\n",
    "    X = Conv3D(f, kernel_size, strides=(pool_size, pool_size, pool_size), \n",
    "               padding='valid', use_bias=bias_flag,)(X)\n",
    "    # batch normalization\n",
    "    if batch_norm:\n",
    "        X = keras.layers.BatchNormalization(axis=3, name='{}_bn'.format(name))(X)\n",
    "    # activation\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    for j in range(2):\n",
    "    \n",
    "        X = Conv3D(f, kernel_size, padding='same', use_bias=bias_flag,)(X)\n",
    "\n",
    "        # batch normalization\n",
    "        if batch_norm:\n",
    "            X = keras.layers.BatchNormalization(axis=-1)(X)        \n",
    "        # activation\n",
    "        X = keras.layers.Activation(\"gelu\")(X)\n",
    "      \n",
    "    X_skip.append(X)\n",
    "\n",
    "# reverse indexing encoded feature maps\n",
    "X_skip = X_skip[::-1]\n",
    "# upsampling begins at the deepest available tensor\n",
    "X = X_skip[0]\n",
    "# other tensors are preserved for concatenation\n",
    "X_decode = X_skip[1:]\n",
    "depth_decode = len(X_decode)\n",
    "\n",
    "filter_num_decode = filter_num[:-1][::-1]\n",
    "\n",
    "# upsampling with concatenation\n",
    "for i in range(depth_decode):\n",
    "    \n",
    "    X = Conv3DTranspose(filter_num_decode[i], kernel_size, strides=(pool_size, pool_size, pool_size), \n",
    "                        padding='same', name='{}_trans_conv'.format(name))(X)\n",
    "        \n",
    "    # batch normalization\n",
    "    if batch_norm:\n",
    "        X = keras.layers.BatchNormalization(axis=3, name='{}_bn'.format(name))(X)\n",
    "            \n",
    "    # activation\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "    \n",
    "    \n",
    "    X = keras.layers.concatenate([X,]+[X_decode[i],], axis=-1)\n",
    "    \n",
    "    # Stacked convolutions after concatenation \n",
    "    for j in range(2):\n",
    "    \n",
    "        X = Conv3D(f, kernel_size, padding='same', use_bias=bias_flag,)(X)\n",
    "\n",
    "        # batch normalization\n",
    "        if batch_norm:\n",
    "            X = keras.layers.BatchNormalization(axis=-1)(X)        \n",
    "        # activation\n",
    "        X = keras.layers.Activation(\"gelu\")(X)\n",
    "        \n",
    "X = keras.layers.Conv3D(1, kernel_size, padding='same', use_bias=True, name=name)(X)\n",
    "X = keras.layers.Activation('sigmoid', name='{}_activation'.format(name))(X)\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_tensor,], outputs=[X,], name='{}_model'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2dfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b9290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26b0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939affa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c3f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6d8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22319661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
