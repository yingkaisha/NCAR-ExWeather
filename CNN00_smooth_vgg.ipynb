{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1920441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 12:31:01.292770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import re\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred):\n",
    "    BS = np.mean((VALID_target.ravel() - Y_pred.ravel())**2)\n",
    "    metric = BS\n",
    "    return metric\n",
    "\n",
    "def neighbour_leads(lead):\n",
    "    out = [lead-2, lead-1, lead, lead+1]\n",
    "    flag_shift = [0, 0, 0, 0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        if out[i] < 0:\n",
    "            out[i] = 24+out[i]\n",
    "            flag_shift[i] = -1\n",
    "        if out[i] > 23:\n",
    "            out[i] = out[i]-24\n",
    "            flag_shift[i] = +1\n",
    "            \n",
    "    return out, flag_shift\n",
    "\n",
    "\n",
    "def filename_to_loc(filenames):\n",
    "    lead_out = []\n",
    "    indx_out = []\n",
    "    indy_out = []\n",
    "    day_out = []\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        \n",
    "        lead = int(nums[-1])\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "      \n",
    "        indx_out.append(indx)\n",
    "        indy_out.append(indy)\n",
    "        day_out.append(day)\n",
    "        lead_out.append(lead)\n",
    "        \n",
    "    return np.array(indx_out), np.array(indy_out), np.array(day_out), np.array(lead_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9dcc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== #\n",
    "weights_round = 1\n",
    "save_round = 3\n",
    "seeds = 777\n",
    "model_prefix_load = 'RE3_smooth_vgg{}'.format(weights_round) #False\n",
    "model_prefix_save = 'RE3_smooth_vgg{}'.format(save_round)\n",
    "N_vars = L_vars = 15\n",
    "lr = 1e-5\n",
    "# ==================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b2be21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 12:31:35.227947: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-29 12:31:35.229337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-29 12:31:35.318440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-04-29 12:31:35.318485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:31:35.383598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-29 12:31:35.383667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-29 12:31:35.421638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-29 12:31:35.445966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-29 12:31:35.488157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-29 12:31:35.546163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-29 12:31:35.601125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-29 12:31:35.602338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-29 12:31:35.602976: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 12:31:35.603308: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-29 12:31:35.603978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:b3:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-04-29 12:31:35.604012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:31:35.604037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-29 12:31:35.604050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-29 12:31:35.604064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-29 12:31:35.604077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-29 12:31:35.604089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-29 12:31:35.604102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-29 12:31:35.604115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-29 12:31:35.605149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-29 12:31:35.605194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:31:36.230258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-29 12:31:36.230298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-04-29 12:31:36.230316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-04-29 12:31:36.231960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0)\n",
      "2023-04-29 12:33:02.051222: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-04-29 12:33:02.057872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n",
      "2023-04-29 12:33:03.286280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-29 12:33:03.636692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "vers = ['v3', 'v4x', 'v4'] # HRRR v4, v4x, v4\n",
    "leads = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "filenames_pos_train = np.load(save_dir_campaign+'HRRR_filenames_pos_train.npy', allow_pickle=True)[()]\n",
    "filenames_neg_train = np.load(save_dir_campaign+'HRRR_filenames_neg_train.npy', allow_pickle=True)[()]\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# Merge train/valid and pos/neg batch files from multiple lead times\n",
    "pos_train_all = []\n",
    "neg_train_all = []\n",
    "\n",
    "for ver in vers:\n",
    "    for lead in leads:\n",
    "        pos_train_all += filenames_pos_train['{}_lead{}'.format(ver, lead)]\n",
    "        neg_train_all += filenames_neg_train['{}_lead{}'.format(ver, lead)]\n",
    "        \n",
    "pos_train_v3 = []\n",
    "neg_train_v3 = []\n",
    "\n",
    "pos_train_v4x = []\n",
    "neg_train_v4x = []\n",
    "\n",
    "pos_train_v4 = []\n",
    "neg_train_v4 = []\n",
    "\n",
    "for lead in leads:\n",
    "    pos_train_v3 += filenames_pos_train['{}_lead{}'.format('v3', lead)]\n",
    "    neg_train_v3 += filenames_neg_train['{}_lead{}'.format('v3', lead)]\n",
    "    \n",
    "    pos_train_v4x += filenames_pos_train['{}_lead{}'.format('v4x', lead)]\n",
    "    neg_train_v4x += filenames_neg_train['{}_lead{}'.format('v4x', lead)]\n",
    "    \n",
    "    pos_train_v4 += filenames_pos_train['{}_lead{}'.format('v4', lead)]\n",
    "    neg_train_v4 += filenames_neg_train['{}_lead{}'.format('v4', lead)]\n",
    "    \n",
    "# label_smooth_v3 = ()\n",
    "# label_smooth_v4x = ()\n",
    "# label_smooth_v4 = ()\n",
    "\n",
    "# for lead in leads:\n",
    "\n",
    "#     lead_window, flag_shift = neighbour_leads(lead)\n",
    "    \n",
    "#     print('Collect HRRR v3 labels ...')\n",
    "    \n",
    "#     record_all = ()\n",
    "\n",
    "#     for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "#         flag_ = flag_shift[i]\n",
    "\n",
    "#         with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_all.hdf'.format(lead_temp), 'r') as h5io:\n",
    "#             record_temp = h5io['record_v3'][...]\n",
    "\n",
    "#         if flag_shift[i] == 0:\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == -1:\n",
    "#             record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "#             record_temp[0, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == +1:\n",
    "#             record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "#             record_temp[-1, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "\n",
    "#     shape_record = record_temp.shape      \n",
    "#     record_v3 = np.empty(shape_record)\n",
    "#     record_v3[...] = 0.0 #np.nan\n",
    "\n",
    "#     for i in range(4):\n",
    "#         record_temp = record_all[i]\n",
    "#         for day in range(shape_record[0]):\n",
    "#             for ix in range(shape_record[1]):\n",
    "#                 for iy in range(shape_record[2]):\n",
    "#                     for event in range(shape_record[3]):\n",
    "#                         if record_temp[day, ix, iy, event] > 0:\n",
    "#                             record_v3[day, ix, iy, event] = 1.0\n",
    "#                         elif record_v3[day, ix, iy, event] == 1.0:\n",
    "#                             record_v3[day, ix, iy, event] = 1.0\n",
    "#                         else:\n",
    "#                             record_v3[day, ix, iy, event] = 0.0\n",
    "    \n",
    "#     label_smooth_v3 += (record_v3[None, ...],)\n",
    "    \n",
    "#     print('Collect HRRR v4x labels ...')\n",
    "    \n",
    "#     record_all = ()\n",
    "\n",
    "#     for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "#         flag_ = flag_shift[i]\n",
    "\n",
    "#         with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_v4x.hdf'.format(lead_temp), 'r') as h5io:\n",
    "#             record_temp = h5io['record_v4x'][...]\n",
    "\n",
    "#         if flag_shift[i] == 0:\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == -1:\n",
    "#             record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "#             record_temp[0, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == +1:\n",
    "#             record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "#             record_temp[-1, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "\n",
    "#     shape_record = record_temp.shape      \n",
    "#     record_v4x = np.empty(shape_record)\n",
    "#     record_v4x[...] = np.nan\n",
    "\n",
    "#     for i in range(4):\n",
    "#         record_temp = record_all[i]\n",
    "#         for day in range(shape_record[0]):\n",
    "#             for ix in range(shape_record[1]):\n",
    "#                 for iy in range(shape_record[2]):\n",
    "#                     for event in range(shape_record[3]):\n",
    "#                         if record_temp[day, ix, iy, event] > 0:\n",
    "#                             record_v4x[day, ix, iy, event] = 1.0\n",
    "#                         elif record_v4x[day, ix, iy, event] == 1.0:\n",
    "#                             record_v4x[day, ix, iy, event] = 1.0\n",
    "#                         else:\n",
    "#                             record_v4x[day, ix, iy, event] = 0.0\n",
    "    \n",
    "#     label_smooth_v4x += (record_v4x[None, ...],)\n",
    "    \n",
    "#     print('Collect HRRR v4 labels ...')\n",
    "    \n",
    "#     record_all = ()\n",
    "    \n",
    "#     for i, lead_temp in enumerate(lead_window):\n",
    "\n",
    "#         flag_ = flag_shift[i]\n",
    "\n",
    "#         with h5py.File(save_dir_scratch+'SPC_to_lead{}_72km_all.hdf'.format(lead_temp), 'r') as h5io:\n",
    "#             record_temp = h5io['record_v4'][...]\n",
    "\n",
    "#         if flag_shift[i] == 0:\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == -1:\n",
    "#             record_temp[1:, ...] = record_temp[:-1, ...]\n",
    "#             record_temp[0, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "\n",
    "#         if flag_shift[i] == +1:\n",
    "#             record_temp[:-1, ...] = record_temp[1:, ...]\n",
    "#             record_temp[-1, ...] = np.nan\n",
    "#             record_all = record_all + (record_temp,)\n",
    "            \n",
    "            \n",
    "#     shape_record = record_temp.shape      \n",
    "#     record_v4 = np.empty(shape_record)\n",
    "#     record_v4[...] = 0.0 #np.nan\n",
    "\n",
    "#     for i in range(4):\n",
    "#         record_temp = record_all[i]\n",
    "#         for day in range(shape_record[0]):\n",
    "#             for ix in range(shape_record[1]):\n",
    "#                 for iy in range(shape_record[2]):\n",
    "#                     for event in range(shape_record[3]):\n",
    "#                         if record_temp[day, ix, iy, event] > 0:\n",
    "#                             record_v4[day, ix, iy, event] = 1.0\n",
    "#                         elif record_v4[day, ix, iy, event] == 1.0:\n",
    "#                             record_v4[day, ix, iy, event] = 1.0\n",
    "#                         else:\n",
    "#                             record_v4[day, ix, iy, event] = 0.0\n",
    "                            \n",
    "#     label_smooth_v4 += (record_v4[None, ...],)\n",
    "    \n",
    "#     print('... Done')\n",
    "    \n",
    "# label_concat_v3 = np.concatenate(label_smooth_v3, axis=0)\n",
    "# label_concat_v4x = np.concatenate(label_smooth_v4x, axis=0)\n",
    "# label_concat_v4 = np.concatenate(label_smooth_v4, axis=0)\n",
    "\n",
    "# label_concat_v3 = np.sum(label_concat_v3, axis=-1)\n",
    "# label_concat_v3[label_concat_v3>1] = 1\n",
    "\n",
    "# label_concat_v4 = np.sum(label_concat_v4, axis=-1)\n",
    "# label_concat_v4[label_concat_v4>1] = 1\n",
    "\n",
    "# label_concat_v4x = np.sum(label_concat_v4x, axis=-1)\n",
    "# label_concat_v4x[label_concat_v4x>1] = 1\n",
    "\n",
    "# shape_label_v3 = label_concat_v3.shape\n",
    "# shape_label_v4 = label_concat_v4.shape\n",
    "# shape_label_v4x = label_concat_v4x.shape\n",
    "\n",
    "# label_final_v3 = np.empty(shape_label_v3)\n",
    "# label_final_v4 = np.empty(shape_label_v4)\n",
    "# label_final_v4x = np.empty(shape_label_v4x)\n",
    "\n",
    "# for i in range(shape_label_v3[0]):\n",
    "#     for j in range(shape_label_v3[1]):\n",
    "#         label_final_v3[i, j, ...] = scipy.ndimage.gaussian_filter(label_concat_v3[i, j], sigma=2.5)\n",
    "        \n",
    "# for i in range(shape_label_v4[0]):\n",
    "#     for j in range(shape_label_v4[1]):\n",
    "#         label_final_v4[i, j, ...] = scipy.ndimage.gaussian_filter(label_concat_v4[i, j], sigma=2.5)\n",
    "        \n",
    "# for i in range(shape_label_v4x[0]):\n",
    "#     for j in range(shape_label_v4x[1]):\n",
    "#         label_final_v4x[i, j, ...] = scipy.ndimage.gaussian_filter(label_concat_v4x[i, j], sigma=2.5)\n",
    "        \n",
    "# indx_pos_train_v3, indy_pos_train_v3, day_pos_train_v3, lead_pos_train_v3 = filename_to_loc(pos_train_v3)\n",
    "# indx_neg_train_v3, indy_neg_train_v3, day_neg_train_v3, lead_neg_train_v3 = filename_to_loc(neg_train_v3)\n",
    "\n",
    "# lead_pos_train_v3 = lead_pos_train_v3 - 2\n",
    "# lead_neg_train_v3 = lead_neg_train_v3 - 2\n",
    "\n",
    "# y_pos_train_v3 = label_final_v3[lead_pos_train_v3, day_pos_train_v3, indx_pos_train_v3, indy_pos_train_v3]\n",
    "# y_neg_train_v3 = label_final_v3[lead_neg_train_v3, day_neg_train_v3, indx_neg_train_v3, indy_neg_train_v3]   \n",
    "\n",
    "# indx_pos_train_v4x, indy_pos_train_v4x, day_pos_train_v4x, lead_pos_train_v4x = filename_to_loc(pos_train_v4x)\n",
    "# indx_neg_train_v4x, indy_neg_train_v4x, day_neg_train_v4x, lead_neg_train_v4x = filename_to_loc(neg_train_v4x)\n",
    "\n",
    "# lead_pos_train_v4x = lead_pos_train_v4x - 2\n",
    "# lead_neg_train_v4x = lead_neg_train_v4x - 2\n",
    "\n",
    "# y_pos_train_v4x = label_final_v4x[lead_pos_train_v4x, day_pos_train_v4x, indx_pos_train_v4x, indy_pos_train_v4x]\n",
    "# y_neg_train_v4x = label_final_v4x[lead_neg_train_v4x, day_neg_train_v4x, indx_neg_train_v4x, indy_neg_train_v4x]\n",
    "\n",
    "# y_pos_train_all = np.concatenate((y_pos_train_v3, y_pos_train_v4x,), axis=0)\n",
    "# y_neg_train_all = np.concatenate((y_neg_train_v3, y_neg_train_v4x,), axis=0)\n",
    "\n",
    "# y_pos_train_all_adjust = np.copy(y_pos_train_all) + 0.75\n",
    "# y_pos_train_all_adjust[y_pos_train_all_adjust>0.99] = 0.99\n",
    "\n",
    "# y_neg_train_all_adjust = np.copy(y_neg_train_all)\n",
    "# # y_neg_train_all_adjust[y_neg_train_all_adjust>0.49] = 0.49\n",
    "\n",
    "y_pos_train_all_adjust = np.load(save_dir_campaign+'y_pos_train_all_adjust.npy')\n",
    "y_neg_train_all_adjust = np.load(save_dir_campaign+'y_neg_train_all_adjust.npy')\n",
    "\n",
    "ind_pick_from_batch = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "with h5py.File(save_dir+'CNN_Validation_basic.hdf', 'r') as h5io:\n",
    "    VALID_input_64 = h5io['VALID_input_64'][...]\n",
    "    VALID_target = h5io['VALID_target'][...]\n",
    "    \n",
    "    \n",
    "# ----------------------------------------------------------------- #\n",
    "# model and weights\n",
    "model_head = mu.create_model_head(input_shape=(512,), N_node=64)\n",
    "model_base = mu.create_model_vgg(input_shape=(64, 64, 15), channels=[96, 128, 256, 512])\n",
    "\n",
    "IN = keras.layers.Input(shape=(64, 64, 15))\n",
    "\n",
    "VEC = model_base(IN)\n",
    "OUT = model_head(VEC)\n",
    "\n",
    "model_final = keras.models.Model(inputs=IN, outputs=OUT)\n",
    "\n",
    "\n",
    "# ============================================= #\n",
    "# Weights\n",
    "if weights_round > 0:\n",
    "    if model_prefix_load:\n",
    "        W_old = mu.dummy_loader('/glade/work/ksha/NCAR/Keras_models/{}/'.format(model_prefix_load))\n",
    "        model_final.set_weights(W_old)\n",
    "    \n",
    "model_final.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(lr=lr))\n",
    "\n",
    "# ----------------------------------------------------------------- #\n",
    "# model training loop\n",
    "Y_pred = model_final.predict([VALID_input_64])\n",
    "record_temp = verif_metric(VALID_target, Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b65a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record: 0.023378238273538306\n",
      "Validation loss 0.0251104149111698 NOT improved\n",
      "Validation loss 0.024037616747677647 NOT improved\n",
      "Validation loss improved from 0.023378238273538306 to 0.023062724512688475\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/RE3_smooth_vgg3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 13:00:50.721078: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/RE3_smooth_vgg3/assets\n",
      "--- 424.2179741859436 seconds ---\n",
      "Validation loss 0.02396934839914213 NOT improved\n",
      "Validation loss 0.02446751173428698 NOT improved\n",
      "Validation loss 0.02577227945009807 NOT improved\n",
      "Validation loss improved from 0.023062724512688475 to 0.02300267408809093\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/RE3_smooth_vgg3\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/RE3_smooth_vgg3/assets\n",
      "--- 441.55326437950134 seconds ---\n",
      "Validation loss 0.02402442865680988 NOT improved\n",
      "Validation loss 0.023389829876336452 NOT improved\n",
      "Validation loss 0.023827664843499775 NOT improved\n",
      "Validation loss 0.02311087507676882 NOT improved\n",
      "Validation loss 0.023956357628906574 NOT improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "min_del = 0.0\n",
    "max_tol = 100 # early stopping with patience\n",
    "batch_size = 200\n",
    "\n",
    "# Allocate batch files\n",
    "X_batch_64 = np.empty((batch_size, 64, 64, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch_64[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# Model check-point info\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "model_name = model_prefix_save\n",
    "model_path = temp_dir + model_name\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "tol = 0 # initial tol\n",
    "\n",
    "filename_pos_train = pos_train_all\n",
    "filename_neg_train = neg_train_all\n",
    "L_pos = len(filename_pos_train)\n",
    "L_neg = len(filename_neg_train)\n",
    "\n",
    "record = record_temp\n",
    "print(\"Initial record: {}\".format(record))\n",
    "\n",
    "mu.set_seeds(seeds)\n",
    "    \n",
    "for i in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        N_pos = 20\n",
    "        N_neg = batch_size - N_pos\n",
    "\n",
    "        ind_neg = du.shuffle_ind(L_neg)\n",
    "        ind_pos = du.shuffle_ind(L_pos)\n",
    "        \n",
    "        # neg batches from this training rotation \n",
    "        file_pick_neg = []\n",
    "        file_label_neg = []\n",
    "        for ind_temp in ind_neg[:N_neg]:\n",
    "            file_pick_neg.append(filename_neg_train[ind_temp])\n",
    "            file_label_neg.append(y_neg_train_all_adjust[ind_temp])\n",
    "            \n",
    "        # pos batches from this training rotation \n",
    "        file_pick_pos = []\n",
    "        file_label_pos = []\n",
    "        for ind_temp in ind_pos[:N_pos]:\n",
    "            file_pick_pos.append(filename_pos_train[ind_temp])\n",
    "            file_label_pos.append(y_pos_train_all_adjust[ind_temp])\n",
    "            \n",
    "        # get all the batch filenames for checking labels\n",
    "        file_pick = file_pick_neg + file_pick_pos\n",
    "        file_label = file_label_neg + file_label_pos\n",
    "        Y_batch = np.array(file_label)[:, None]\n",
    "\n",
    "        # Assign labels based on batch filenames\n",
    "        for k in range(batch_size):\n",
    "            #print(file_pick[k])\n",
    "            data = np.load(file_pick[k])\n",
    "            for l, c in enumerate(ind_pick_from_batch):\n",
    "                temp = data[..., c] \n",
    "                X_batch_64[k, ..., l] = temp\n",
    "                \n",
    "        # ------------------------------------------------- #\n",
    "        # batch input and label from this training rotation \n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch_64 = X_batch_64[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "\n",
    "        # train on batch\n",
    "        model_final.train_on_batch(X_batch_64, Y_batch);\n",
    "\n",
    "    # epoch end operations\n",
    "    Y_pred = model_final.predict([VALID_input_64])\n",
    "    record_temp = verif_metric(VALID_target, Y_pred)\n",
    "\n",
    "    if (record - record_temp > min_del):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model_final.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        if record_temp >= 2.0:\n",
    "            print('Early stopping')\n",
    "            break;\n",
    "        else:\n",
    "            tol += 1\n",
    "            if tol >= max_tol:\n",
    "                print('Early stopping')\n",
    "                break;\n",
    "            else:\n",
    "                continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f27a2-84cb-4dc1-b9b1-036389e8b205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
