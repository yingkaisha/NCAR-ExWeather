{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf179e2-3bad-4c48-81c1-2a43b404537b",
   "metadata": {},
   "source": [
    "# Pre-process SPC strom reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eac6a22-a283-4b10-951d-5e25bf48ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364dd02f-1606-4374-a4c1-e0bba7fdbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import preprocess_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38c13c3-622d-41a0-92fb-aceca6a59836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f739e3e-9195-413c-947a-2e62df53f103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_utils' from '/glade/u/home/ksha/NCAR/libs/data_utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd29a500-0cc5-431c-a4f0-23c8f4f59910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/work/ksha/NCAR/storm_report/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d322a4-35a8-4b4d-8f62-fedfe9893287",
   "metadata": {},
   "source": [
    "### Domain info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6258e53c-b972-4869-8a49-52c58a3e90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_72km = h5io['lon_80km'][...]\n",
    "    lat_72km = h5io['lat_80km'][...]\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c024c6f-1716-496c-befe-d3094fc047a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preserve_inds = [4, 5, 6, 10, 15, 16]\n",
    "column_names = ['date', 'time', 'tz', 'mag', 'slat', 'slon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f0aa29-a1af-4595-9940-aba6bf683762",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "file_torn = sorted(glob(report_dir+'{}_torn.csv'.format(year)))[0]\n",
    "df_torn = pd.read_csv(file_torn)\n",
    "df_torn = df_torn.iloc[:, preserve_inds]\n",
    "df_torn.columns = column_names\n",
    "\n",
    "file_wind = sorted(glob(report_dir+'{}_wind.csv'.format(year)))[0]\n",
    "df_wind = pd.read_csv(file_wind)\n",
    "df_wind = df_wind.iloc[:, preserve_inds]\n",
    "df_wind.columns = column_names\n",
    "\n",
    "file_hail = sorted(glob(report_dir+'{}_hail.csv'.format(year)))[0]\n",
    "df_hail = pd.read_csv(file_hail)\n",
    "df_hail = df_hail.iloc[:, preserve_inds]\n",
    "df_hail.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541f0844-ae47-4d6d-a2b5-42dea29cfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88358e3f-cd80-464f-8ac1-97d705b94e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [df_torn, df_wind, df_hail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915fa309-3cec-4994-a781-9762cdb9e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1219: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_merged = reduce(lambda  left,right: pd.merge(left, right, how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edb175d-ccc6-4128-9818-f68942384960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b80c1-a0a1-4d5c-852e-3a1d7ee84191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba293d3-f754-4aa1-b6e8-ecba9cda398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_v3_s = datetime(2018, 7, 15)\n",
    "base_v3_e = datetime(2020, 12, 2)\n",
    "\n",
    "base_v4_s = datetime(2020, 12, 3)\n",
    "base_v4_e = datetime(2022, 7, 15)\n",
    "\n",
    "base_ref = datetime(2010, 1, 1)\n",
    "\n",
    "date_list_v3 = [base_v3_s + timedelta(days=day) for day in range(365+365+142)]\n",
    "date_list_v4 = [base_v4_s + timedelta(days=day) for day in range(365+180-151)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed919a68-abb6-45b8-a419-8145b8494d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 12, 31, 0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list_v4[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e51aec5-df7f-4c4c-9b36-8e6257a84c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = ['torn', 'hail', 'wind']\n",
    "# folds = [30, 60, 150]\n",
    "\n",
    "# for k, key in enumerate(keys):\n",
    "\n",
    "#     L_v3 = len(date_list_v3)\n",
    "#     L_v4 = len(date_list_v3)\n",
    "\n",
    "#     for lead in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]:\n",
    "\n",
    "#         #print('========== Processing lead time = {} =========='.format(lead))\n",
    "\n",
    "#         record_v3 = np.empty((L_v3, 3*folds[k]))\n",
    "#         record_v3[...] = np.nan\n",
    "#         record_v4 = np.empty((L_v3, 3*folds[k]))\n",
    "#         record_v4[...] = np.nan\n",
    "\n",
    "#         for y in range(2010, 2021):\n",
    "#             temp_day_old = 9999\n",
    "#             # Year info\n",
    "#             year_int = int(y)\n",
    "#             year = str(year_int)\n",
    "\n",
    "#             # Raw tornado files\n",
    "#             file_torn = sorted(glob(report_dir+'{}_{}.csv'.format(year, key)))[0]\n",
    "\n",
    "#             # import csv to pandas and then np.array\n",
    "#             df = pd.read_csv(file_torn)\n",
    "#             temp_array = df.iloc[:, preserve_inds].values\n",
    "\n",
    "#             # datetime and timezone processing\n",
    "#             L = len(temp_array)\n",
    "#             temp_tz = temp_array[:, 2]\n",
    "#             temp_dt_list = []\n",
    "#             flag_badboy = False\n",
    "\n",
    "#             for i in range(L):\n",
    "#                 try:\n",
    "#                     # the string can be converted to datetime object\n",
    "#                     temp_localtime = datetime.strptime(temp_array[i, 0]+'|'+temp_array[i, 1], '%Y-%m-%d|%H:%M:%S')\n",
    "#                     flag_badboy = False\n",
    "#                 except:\n",
    "#                     # the string cannot be converted; typically a \"?\"\n",
    "#                     temp_localtime = np.nan\n",
    "#                     flag_badboy = True\n",
    "\n",
    "#                 # adjust timezones to UTC/GMT \n",
    "#                 if flag_badboy is False:\n",
    "#                     temp_tz = temp_array[i, 2]\n",
    "#                     if temp_tz == 3:\n",
    "#                         temp_localtime = temp_localtime + timedelta(hours=6) # <--- !!! \"3\" means CST\n",
    "#                     elif temp_tz == 9:\n",
    "#                         temp_localtime = temp_localtime # \"9\" means GMT\n",
    "#                     else:\n",
    "#                         temp_localtime = np.nan # otherwise doint know\n",
    "\n",
    "#                 temp_dt_list.append(temp_localtime)\n",
    "\n",
    "#             # Insert in-situ reports into hourly, gridded data frames    \n",
    "#             ## convert slat slon to domain indices\n",
    "\n",
    "#             slon = temp_array[:, 5]\n",
    "#             slat = temp_array[:, 4]\n",
    "#             mag = temp_array[:, 3]\n",
    "\n",
    "#             flag_pick = np.logical_and(slon<-20, slat>5)\n",
    "\n",
    "#             slon = slon[flag_pick]\n",
    "#             slat = slat[flag_pick]\n",
    "#             mag = mag[flag_pick]\n",
    "\n",
    "#             L = len(slon)\n",
    "\n",
    "#             for i in range(L):\n",
    "\n",
    "#                 # the time of a single record\n",
    "#                 temp_datetime = temp_dt_list[i]\n",
    "#                 temp_day = temp_datetime.day\n",
    "#                 temp_hour = temp_datetime.hour\n",
    "\n",
    "#                 temp_datetime_day = datetime(temp_datetime.year, temp_datetime.month, temp_day)\n",
    "\n",
    "#                 if (temp_day_old == temp_day) is False:\n",
    "#                     count_v3 = 0\n",
    "#                     count_v4 = 0\n",
    "#                     temp_day_old = temp_day\n",
    "\n",
    "#                 if temp_hour == lead:\n",
    "#                     diff_days = (temp_datetime_day - base_v4_s).days\n",
    "\n",
    "#                     if diff_days > 0:\n",
    "#                         #print('adding: {}'.format(temp_datetime))\n",
    "#                         record_v4[diff_days, 3*count_v4] = slon[i]\n",
    "#                         record_v4[diff_days, 3*count_v4+1] = slat[i]\n",
    "#                         record_v4[diff_days, 3*count_v4+2] = mag[i]\n",
    "#                         count_v4 += 1\n",
    "\n",
    "#                     else:\n",
    "#                         diff_days = (temp_datetime_day - base_v3_s).days\n",
    "#                         if diff_days > 0:\n",
    "#                             #print('adding: {}'.format(temp_datetime))\n",
    "#                             record_v3[diff_days, 3*count_v3] = slon[i]\n",
    "#                             record_v3[diff_days, 3*count_v3+1] = slat[i]\n",
    "#                             record_v3[diff_days, 3*count_v3+2] = mag[i]\n",
    "#                             count_v3 += 1\n",
    "\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#         tuple_save = (record_v3, record_v4)\n",
    "#         label_save = ['record_v3', 'record_v4']\n",
    "#         du.save_hdf5(tuple_save, label_save, save_dir_scratch, 'SPC_{}_lead{}.hdf'.format(key, lead))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e22df1-df13-4346-a039-ef351520dba1",
   "metadata": {},
   "source": [
    "**Merged version of all hazards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "498e63b1-bbf9-4cfc-9f77-5a1c16548384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead0.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead1.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead2.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead3.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead4.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead5.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead6.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead7.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead8.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead9.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead10.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead11.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead12.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead13.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead14.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead15.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead16.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead17.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead18.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead19.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead20.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead21.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead22.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_all_lead23.hdf\n"
     ]
    }
   ],
   "source": [
    "preserve_inds = [4, 5, 6, 15, 16]\n",
    "column_names = ['date', 'time', 'tz', 'slat', 'slon']\n",
    "\n",
    "L_v3 = len(date_list_v3)\n",
    "L_v4 = len(date_list_v4)\n",
    "\n",
    "folds = 300\n",
    "\n",
    "for lead in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]:\n",
    "\n",
    "    #print('========== Processing lead time = {} =========='.format(lead))\n",
    "\n",
    "    record_v3 = np.empty((L_v3, 2*folds))\n",
    "    record_v3[...] = np.nan\n",
    "    record_v4 = np.empty((L_v3, 2*folds))\n",
    "    record_v4[...] = np.nan\n",
    "\n",
    "    for y in range(2010, 2022):\n",
    "        temp_day_old = 9999\n",
    "        # Year info\n",
    "        year_int = int(y)\n",
    "        year = str(year_int)\n",
    "\n",
    "        # Raw tornado files\n",
    "        file_torn = sorted(glob(report_dir+'{}_torn.csv'.format(year)))[0]\n",
    "        file_wind = sorted(glob(report_dir+'{}_wind.csv'.format(year)))[0]\n",
    "        file_hail = sorted(glob(report_dir+'{}_hail.csv'.format(year)))[0]\n",
    "        # import csv to pandas and then np.array\n",
    "        df_torn = pd.read_csv(file_torn)\n",
    "        df_torn = df_torn.iloc[:, preserve_inds]\n",
    "        df_torn.columns = column_names\n",
    "        \n",
    "        df_wind = pd.read_csv(file_wind)\n",
    "        df_wind = df_wind.iloc[:, preserve_inds]\n",
    "        df_wind.columns = column_names\n",
    "        \n",
    "        df_hail = pd.read_csv(file_hail)\n",
    "        df_hail = df_hail.iloc[:, preserve_inds]\n",
    "        df_hail.columns = column_names\n",
    "        \n",
    "        data_frames = [df_torn, df_wind, df_hail]\n",
    "        df_merged = reduce(lambda  left,right: pd.merge(left, right, how='outer'), data_frames)\n",
    "        \n",
    "        temp_array = df_merged.values\n",
    "\n",
    "        # datetime and timezone processing\n",
    "        L = len(temp_array)\n",
    "        temp_tz = temp_array[:, 2]\n",
    "        temp_dt_list = []\n",
    "        flag_badboy = False\n",
    "\n",
    "        for i in range(L):\n",
    "            try:\n",
    "                # the string can be converted to datetime object\n",
    "                temp_localtime = datetime.strptime(temp_array[i, 0]+'|'+temp_array[i, 1], '%Y-%m-%d|%H:%M:%S')\n",
    "                flag_badboy = False\n",
    "            except:\n",
    "                # the string cannot be converted; typically a \"?\"\n",
    "                temp_localtime = np.nan\n",
    "                flag_badboy = True\n",
    "\n",
    "            # adjust timezones to UTC/GMT \n",
    "            if flag_badboy is False:\n",
    "                temp_tz = temp_array[i, 2]\n",
    "                if temp_tz == 3:\n",
    "                    temp_localtime = temp_localtime + timedelta(hours=6) # <--- !!! \"3\" means CST\n",
    "                elif temp_tz == 9:\n",
    "                    temp_localtime = temp_localtime # \"9\" means GMT\n",
    "                else:\n",
    "                    temp_localtime = np.nan # otherwise doint know\n",
    "\n",
    "            temp_dt_list.append(temp_localtime)\n",
    "\n",
    "        # Insert in-situ reports into hourly, gridded data frames    \n",
    "        ## convert slat slon to domain indices\n",
    "\n",
    "        slon = temp_array[:, 4]\n",
    "        slat = temp_array[:, 3]\n",
    "        #mag = temp_array[:, 3]\n",
    "\n",
    "        flag_pick = np.logical_and(slon<-20, slat>5)\n",
    "\n",
    "        slon = slon[flag_pick]\n",
    "        slat = slat[flag_pick]\n",
    "        #mag = mag[flag_pick]\n",
    "\n",
    "        L = len(slon)\n",
    "\n",
    "        for i in range(L):\n",
    "\n",
    "            # the time of a single record\n",
    "            temp_datetime = temp_dt_list[i]\n",
    "            temp_day = temp_datetime.day\n",
    "            temp_hour = temp_datetime.hour\n",
    "\n",
    "            temp_datetime_day = datetime(temp_datetime.year, temp_datetime.month, temp_day)\n",
    "\n",
    "            if (temp_day_old == temp_day) is False:\n",
    "                count_v3 = 0\n",
    "                count_v4 = 0\n",
    "                temp_day_old = temp_day\n",
    "\n",
    "            if temp_hour == lead:\n",
    "                diff_days = (temp_datetime_day - base_v4_s).days\n",
    "\n",
    "                if diff_days > 0:\n",
    "                    #print('adding: {}'.format(temp_datetime))\n",
    "                    record_v4[diff_days, 2*count_v4] = slon[i]\n",
    "                    record_v4[diff_days, 2*count_v4+1] = slat[i]\n",
    "                    #record_v4[diff_days, 3*count_v4+2] = mag[i]\n",
    "                    count_v4 += 1\n",
    "\n",
    "                else:\n",
    "                    diff_days = (temp_datetime_day - base_v3_s).days\n",
    "                    if diff_days > 0:\n",
    "                        #print('adding: {}'.format(temp_datetime))\n",
    "                        record_v3[diff_days, 2*count_v3] = slon[i]\n",
    "                        record_v3[diff_days, 2*count_v3+1] = slat[i]\n",
    "                        #record_v3[diff_days, 3*count_v3+2] = mag[i]\n",
    "                        count_v3 += 1\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    tuple_save = (record_v3, record_v4)\n",
    "    label_save = ['record_v3', 'record_v4']\n",
    "    du.save_hdf5(tuple_save, label_save, save_dir_scratch, 'SPC_all_lead{}.hdf'.format(lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c579196-aea0-443c-8abc-5e5499ede92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e065cd14-6398-4544-a6c9-e29ad90c4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridTree = cKDTree(list(zip(lon_72km.ravel(), lat_72km.ravel()))) #KDTree_wraper(xgrid, ygrid)\n",
    "grid_shape = lon_72km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfe1206a-a4ce-4682-be7b-0093f5f18962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 93)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_72km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f15ee270-cdb0-46e8-b728-c99b32b10528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing lead time = 0 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead0_72km_all.hdf\n",
      "========== Processing lead time = 1 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead1_72km_all.hdf\n",
      "========== Processing lead time = 2 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead2_72km_all.hdf\n",
      "========== Processing lead time = 3 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead3_72km_all.hdf\n",
      "========== Processing lead time = 4 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead4_72km_all.hdf\n",
      "========== Processing lead time = 5 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead5_72km_all.hdf\n",
      "========== Processing lead time = 6 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead6_72km_all.hdf\n",
      "========== Processing lead time = 7 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead7_72km_all.hdf\n",
      "========== Processing lead time = 8 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead8_72km_all.hdf\n",
      "========== Processing lead time = 9 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead9_72km_all.hdf\n",
      "========== Processing lead time = 10 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead10_72km_all.hdf\n",
      "========== Processing lead time = 11 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead11_72km_all.hdf\n",
      "========== Processing lead time = 12 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead12_72km_all.hdf\n",
      "========== Processing lead time = 13 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead13_72km_all.hdf\n",
      "========== Processing lead time = 14 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead14_72km_all.hdf\n",
      "========== Processing lead time = 15 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead15_72km_all.hdf\n",
      "========== Processing lead time = 16 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead16_72km_all.hdf\n",
      "========== Processing lead time = 17 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead17_72km_all.hdf\n",
      "========== Processing lead time = 18 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead18_72km_all.hdf\n",
      "========== Processing lead time = 19 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead19_72km_all.hdf\n",
      "========== Processing lead time = 20 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead20_72km_all.hdf\n",
      "========== Processing lead time = 21 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead21_72km_all.hdf\n",
      "========== Processing lead time = 22 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead22_72km_all.hdf\n",
      "========== Processing lead time = 23 ==========\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_to_lead23_72km_all.hdf\n"
     ]
    }
   ],
   "source": [
    "preserve_inds = [4, 5, 6, 15, 16]\n",
    "column_names = ['date', 'time', 'tz', 'slat', 'slon']\n",
    "\n",
    "# ['date', 'time', 'tz', 'slat', 'slon']\n",
    "\n",
    "L_v3 = len(date_list_v3)\n",
    "L_v4 = len(date_list_v4)\n",
    "\n",
    "for lead in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]:\n",
    "    \n",
    "    torn_grid_v3 = np.empty((L_v3,)+lon_72km.shape+(3,))\n",
    "    torn_grid_v4 = np.empty((L_v4,)+lon_72km.shape+(3,))\n",
    "\n",
    "    print('========== Processing lead time = {} =========='.format(lead))\n",
    "\n",
    "    record_v3 = np.empty((L_v3, 3*30))*np.nan\n",
    "    record_v4 = np.empty((L_v3, 3*30))*np.nan\n",
    "\n",
    "    for y in range(2010, 2022):\n",
    "        \n",
    "        #temp_day_old = 9999\n",
    "        \n",
    "        # Year info\n",
    "        year_int = int(y)\n",
    "        year = str(year_int)\n",
    "\n",
    "        # Raw tornado files\n",
    "        file_torn = sorted(glob(report_dir+'{}_torn.csv'.format(year)))[0]\n",
    "        file_wind = sorted(glob(report_dir+'{}_wind.csv'.format(year)))[0]\n",
    "        file_hail = sorted(glob(report_dir+'{}_hail.csv'.format(year)))[0]\n",
    "        \n",
    "        # import csv to pandas and then np.array\n",
    "        df_torn = pd.read_csv(file_torn)\n",
    "        df_torn = df_torn.iloc[:, preserve_inds]\n",
    "        df_torn.columns = column_names\n",
    "        \n",
    "        df_wind = pd.read_csv(file_wind)\n",
    "        df_wind = df_wind.iloc[:, preserve_inds]\n",
    "        df_wind.columns = column_names\n",
    "        \n",
    "        df_hail = pd.read_csv(file_hail)\n",
    "        df_hail = df_hail.iloc[:, preserve_inds]\n",
    "        df_hail.columns = column_names\n",
    "        \n",
    "        data_frames = [df_torn, df_wind, df_hail]\n",
    "        #df_merged = reduce(lambda  left,right: pd.merge(left, right, how='outer'), data_frames)\n",
    "        \n",
    "        for c, df in enumerate(data_frames):\n",
    "        \n",
    "            temp_array = df.values\n",
    "\n",
    "            # datetime and timezone processing\n",
    "            L = len(temp_array)\n",
    "            temp_tz = temp_array[:, 2]\n",
    "            temp_dt_list = []\n",
    "            flag_badboy = False\n",
    "\n",
    "            for i in range(L):\n",
    "                try:\n",
    "                    # the string can be converted to datetime object\n",
    "                    temp_localtime = datetime.strptime(temp_array[i, 0]+'|'+temp_array[i, 1], '%Y-%m-%d|%H:%M:%S')\n",
    "                    flag_badboy = False\n",
    "                except:\n",
    "                    # the string cannot be converted; typically a \"?\"\n",
    "                    temp_localtime = np.nan\n",
    "                    flag_badboy = True\n",
    "\n",
    "                # adjust timezones to UTC/GMT \n",
    "                if flag_badboy is False:\n",
    "                    temp_tz = temp_array[i, 2]\n",
    "                    if temp_tz == 3:\n",
    "                        temp_localtime = temp_localtime + timedelta(hours=6) # <--- !!! \"3\" means CST\n",
    "                    elif temp_tz == 9:\n",
    "                        temp_localtime = temp_localtime # \"9\" means GMT\n",
    "                    else:\n",
    "                        temp_localtime = np.nan # otherwise doint know\n",
    "\n",
    "                temp_dt_list.append(temp_localtime)\n",
    "\n",
    "            # Insert in-situ reports into hourly, gridded data frames    \n",
    "            ## convert slat slon to domain indices\n",
    "\n",
    "            slon = temp_array[:, 4]\n",
    "            slat = temp_array[:, 3]\n",
    "\n",
    "            flag_pick = np.logical_and(slon<-20, slat>5)\n",
    "\n",
    "            slon = slon[flag_pick]\n",
    "            slat = slat[flag_pick]\n",
    "\n",
    "            L = len(slon)\n",
    "        \n",
    "            if L > 0:\n",
    "            \n",
    "                dist, indexes = gridTree.query(list(zip(np.array(slon), np.array(slat))))\n",
    "                indx, indy = np.unravel_index(indexes, grid_shape)\n",
    "            \n",
    "                for i in range(L):\n",
    "\n",
    "                    # the time of a single record\n",
    "                    temp_datetime = temp_dt_list[i]\n",
    "                    temp_day = temp_datetime.day\n",
    "                    temp_hour = temp_datetime.hour\n",
    "\n",
    "                    temp_datetime_day = datetime(temp_datetime.year, temp_datetime.month, temp_day)\n",
    "\n",
    "                    # if (temp_day_old == temp_day) is False:\n",
    "                    #     count_v3 = 0\n",
    "                    #     count_v4 = 0\n",
    "                    #     temp_day_old = temp_day\n",
    "\n",
    "                    if temp_hour == lead:\n",
    "                        diff_days = (temp_datetime_day - base_v4_s).days\n",
    "\n",
    "                        if diff_days > 0:\n",
    "                            #print('adding: {}'.format(temp_datetime))\n",
    "                            torn_grid_v4[diff_days, indx[i], indy[i], c] = 1.0\n",
    "                            #count_v4 += 1\n",
    "\n",
    "                        else:\n",
    "                            diff_days = (temp_datetime_day - base_v3_s).days\n",
    "                            if diff_days > 0:\n",
    "                                #print('adding: {}'.format(temp_datetime))\n",
    "                                torn_grid_v3[diff_days, indx[i], indy[i], c] = 1.0\n",
    "                                #count_v3 += 1\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    tuple_save = (torn_grid_v3, torn_grid_v4)\n",
    "    label_save = ['record_v3', 'record_v4']\n",
    "    du.save_hdf5(tuple_save, label_save, save_dir_scratch, 'SPC_to_lead{}_72km_all.hdf'.format(lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16a8789d-15cc-4644-943d-b839292add74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 65, 93, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torn_grid_v4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e05365af-867a-4260-90c9-d848a490896f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f8b4dc-c33b-4946-a423-40e8ddc870e6",
   "metadata": {},
   "source": [
    "**Use wind/hail as negatives of tornado**\n",
    "\n",
    "lat/lon locatinos will be defined based on 72-km grid cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e450ca6e-205b-4516-86b9-7c197b15be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4e22fbe-8286-430b-ba3c-bfbc1e423c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridTree = cKDTree(list(zip(lon_72km.ravel(), lat_72km.ravel()))) #KDTree_wraper(xgrid, ygrid)\n",
    "\n",
    "# for xi in range(shape_72km[0]):\n",
    "#     for yi in range(shape_72km[1]):\n",
    "        \n",
    "#         temp_lon = lon_72km[xi, yi]\n",
    "#         temp_lat = lat_72km[xi, yi]\n",
    "        \n",
    "#         dist, indexes = gridTree.query(list(zip(np.array(temp_lon)[None], np.array(temp_lat)[None])))\n",
    "#         indx_3km, indy_3km = np.unravel_index(indexes, grid_shape_hrrr)\n",
    "        \n",
    "#         indx_array[xi, yi] = indx_3km[0]\n",
    "#         indy_array[xi, yi] = indy_3km[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "834aa9b4-1eff-45c9-a551-daed272616fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nan_remove(lon, lat):\n",
    "#     lon_clean = []\n",
    "#     lat_clean = []\n",
    "#     L = len(lon)\n",
    "#     for i in range(L):\n",
    "#         lon_ = lon[i]        \n",
    "#         if np.isnan(lon_):\n",
    "#             break\n",
    "#         else:\n",
    "#             lon_clean.append(lon_)\n",
    "#             lat_clean.append(lat[i])\n",
    "            \n",
    "#     return np.array(lon_clean), np.array(lat_clean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f0e1d2-94f1-4846-acf1-00efc75696c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def index_match(indx, indy, indx_pool, indy_pool):\n",
    "#     out = []\n",
    "#     for i in range(len(indx)):\n",
    "#         indx0 = indx[i]\n",
    "#         indy0 = indy[i]\n",
    "#         #matchx = np.where(indx0==indx_pool)\n",
    "#         matchx = np.argwhere((indx_pool-indx0) == 0)\n",
    "#         matchx = matchx[:, 0]\n",
    "#         if len(matchx) > 0:\n",
    "#             for j in range(len(matchx)):\n",
    "#                 indy1 = indy_pool[matchx[j]]\n",
    "#                 if indy1 == indy0:\n",
    "#                     out.append(i)\n",
    "#     return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3932fd8b-b51b-4a11-bdc7-af39fbf3bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead0.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead0.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead1.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead1.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead2.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead2.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead3.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead3.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead4.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead4.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead5.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead5.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead6.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead6.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead7.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead7.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead8.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead8.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead9.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead9.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead10.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead10.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead11.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead11.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead12.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead12.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead13.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead13.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead14.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead14.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead15.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead15.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead16.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead16.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead17.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead17.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead18.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead18.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead19.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead19.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead20.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead20.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead21.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead21.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead22.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead22.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_wind_non-torn_lead23.hdf\n",
      "Save to /glade/scratch/ksha/DRIVE/SPC_hail_non-torn_lead23.hdf\n"
     ]
    }
   ],
   "source": [
    "# L_v3 = len(date_list_v3)\n",
    "\n",
    "# shape_72km = lon_72km.shape\n",
    "\n",
    "# for lead in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]:\n",
    "\n",
    "#     with h5py.File(save_dir_scratch+'SPC_torn_lead{}.hdf'.format(lead), 'r') as h5io:\n",
    "#         record_v3_torn = h5io['record_v3'][...]\n",
    "\n",
    "#     with h5py.File(save_dir_scratch+'SPC_wind_lead{}.hdf'.format(lead), 'r') as h5io:\n",
    "#         record_v3_wind = h5io['record_v3'][...]\n",
    "\n",
    "#     with h5py.File(save_dir_scratch+'SPC_hail_lead{}.hdf'.format(lead), 'r') as h5io:\n",
    "#         record_v3_hail = h5io['record_v3'][...]\n",
    "\n",
    "#     for day in range(L_v3):\n",
    "\n",
    "#         temp_torn = record_v3_torn[day, :]\n",
    "#         temp_wind = record_v3_wind[day, :]\n",
    "#         temp_hail = record_v3_hail[day, :]\n",
    "\n",
    "#         lon_torn_ = temp_torn[0::3]\n",
    "#         lat_torn_ = temp_torn[1::3]\n",
    "#         lon_torn, lat_torn = nan_remove(lon_torn_, lat_torn_)\n",
    "\n",
    "#         if len(lon_torn) == 0:\n",
    "#             continue;\n",
    "\n",
    "#         dist, indexes = gridTree.query(list(zip(np.array(lon_torn), np.array(lat_torn))))\n",
    "#         indx_torn, indy_torn = np.unravel_index(indexes, shape_72km)\n",
    "\n",
    "#         lon_wind_ = temp_wind[0::3]\n",
    "#         lat_wind_ = temp_wind[1::3]\n",
    "#         lon_wind, lat_wind = nan_remove(lon_wind_, lat_wind_)\n",
    "\n",
    "#         if len(lon_wind) > 0:\n",
    "#             dist, indexes = gridTree.query(list(zip(np.array(lon_wind), np.array(lat_wind))))\n",
    "#             indx_wind, indy_wind = np.unravel_index(indexes, shape_72km)\n",
    "\n",
    "#             ind_match_wind = index_match(indx_wind, indy_wind, indx_torn, indy_torn)\n",
    "#             if len(ind_match_wind) > 0:\n",
    "#                 # print(indx_wind)\n",
    "#                 # print(indy_wind)\n",
    "#                 # print(indx_torn)\n",
    "#                 # print(indy_torn)\n",
    "#                 # print(ind_match_wind)\n",
    "#                 for ind_ in ind_match_wind:\n",
    "#                     # print(temp_wind[3*ind_])\n",
    "#                     # print(temp_wind[3*ind_+1])\n",
    "#                     # print(lon_torn)\n",
    "#                     # print(lat_torn)\n",
    "\n",
    "#                     temp_wind[3*ind_] = np.nan\n",
    "#                     temp_wind[3*ind_+1] = np.nan\n",
    "#                     temp_wind[3*ind_+2] = np.nan\n",
    "#                 record_v3_wind[day, :] = temp_wind\n",
    "\n",
    "#         lon_hail_ = temp_hail[0::3]\n",
    "#         lat_hail_ = temp_hail[1::3]\n",
    "#         lon_hail, lat_hail = nan_remove(lon_hail_, lat_hail_)\n",
    "\n",
    "#         if len(lon_hail) > 0:\n",
    "#             dist, indexes = gridTree.query(list(zip(np.array(lon_hail), np.array(lat_hail))))\n",
    "#             indx_hail, indy_hail = np.unravel_index(indexes, shape_72km)\n",
    "\n",
    "#             ind_match_hail = index_match(indx_hail, indy_hail, indx_torn, indy_torn)\n",
    "#             if len(ind_match_hail) > 0:\n",
    "#                 for ind_ in ind_match_hail:\n",
    "#                     temp_hail[3*ind_] = np.nan\n",
    "#                     temp_hail[3*ind_+1] = np.nan\n",
    "#                     temp_hail[3*ind_+2] = np.nan\n",
    "#                 record_v3_hail[day, :] = temp_hail\n",
    "\n",
    "#     tuple_save = (record_v3_wind,); label_save = ['record_v3',]\n",
    "#     du.save_hdf5(tuple_save, label_save, save_dir_scratch, 'SPC_wind_non-torn_lead{}.hdf'.format(lead))\n",
    "\n",
    "#     tuple_save = (record_v3_hail,); label_save = ['record_v3',]\n",
    "#     du.save_hdf5(tuple_save, label_save, save_dir_scratch, 'SPC_hail_non-torn_lead{}.hdf'.format(lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24137c-db46-47d5-9ede-1b2c583d5aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d066e34-65fc-40cd-a2c9-def416ea0759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20321630-3a13-42ea-9af7-b52083a85d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6616c6-e24a-4092-9581-6a8e70394d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64254d34-b7d3-4347-bb35-35a880eec252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
