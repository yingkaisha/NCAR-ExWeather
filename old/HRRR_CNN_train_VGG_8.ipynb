{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2691f0a5-e348-4592-a238-9c6858792779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:27:09.159367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# general tools\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras_unet_collection import models as k_models\n",
    "from keras_unet_collection import utils as k_utils\n",
    "from keras_unet_collection import layer_utils as k_layers\n",
    "from keras_unet_collection.activations import GELU\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "from sklearn.metrics import classification_report, auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred, thres=0.5):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(VALID_target.ravel(), Y_pred.ravel()>thres).ravel()\n",
    "\n",
    "    CSI = tp/(tp+fn+fp)\n",
    "    CSI_metric = 1 - CSI\n",
    "    \n",
    "    POFD = fp/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(VALID_target.ravel(), Y_pred.ravel())\n",
    "    AUC = auc(fpr, tpr)\n",
    "    AUC_metric = 1 - AUC\n",
    "    \n",
    "    freq = (tp+fp)/(tp+fn)\n",
    "    freq_metric = np.abs(freq-1.0)\n",
    "    \n",
    "    print('{} {} {} {}'.format(CSI, POFD, AUC, freq))\n",
    "    metric = 0.2*CSI_metric + 0.8*freq_metric\n",
    "\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9d0511-ac88-4a24-8a29-7863dfcf51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== training/validation split ========== #\n",
    "\n",
    "filename_aug = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_aug/*.npy\"))\n",
    "filename_full = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08650a34-57d2-4b79-b1d5-f000bf771a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_train_aug = 50000\n",
    "cut_train_full = 600000\n",
    "\n",
    "filename_train_aug = filename_aug[:cut_train_aug]\n",
    "filename_train_full = filename_full[:cut_train_full]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2a4d818-939f-4c9b-8946-9cfe383dbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 8\n",
    "\n",
    "L_valid_aug = int(50*factor)\n",
    "L_valid_full = int(3000*factor)\n",
    "\n",
    "filename_valid_aug = filename_aug[cut_train_aug:]\n",
    "filename_valid_full = filename_full[cut_train_full:]\n",
    "\n",
    "shuffle(filename_valid_aug)\n",
    "shuffle(filename_valid_full)\n",
    "\n",
    "filename_valid_aug = filename_aug[-L_valid_aug:]\n",
    "filename_valid_full = filename_full[-L_valid_full:]\n",
    "\n",
    "# ========== Validation set ========== #\n",
    "\n",
    "ind_pick_from_batch = [1, 2, 5, 10, 11, 12, 13, 14, 15, 17]\n",
    "\n",
    "L_vars = len(ind_pick_from_batch)\n",
    "\n",
    "grid_shape = (128, 128)\n",
    "\n",
    "L_valid = L_valid_aug+L_valid_full\n",
    "\n",
    "VALID_input = np.empty((L_valid,)+grid_shape+(L_vars,))\n",
    "VALID_target = np.empty(L_valid)\n",
    "\n",
    "for i, filename in enumerate(filename_valid_aug+filename_valid_full):\n",
    "    data = np.load(filename)\n",
    "    \n",
    "    for c, v in enumerate(ind_pick_from_batch):\n",
    "    \n",
    "        VALID_input[i, ..., c] = data[..., v]\n",
    "        \n",
    "    if 'pos' in filename:\n",
    "        VALID_target[i] = True\n",
    "    elif 'neg' in filename:\n",
    "        VALID_target[i] = False\n",
    "    else:\n",
    "        aergheagtha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd15d7-7032-4853-8bcb-51402c30d859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3519c468-8301-4d80-b085-bcb0741cdf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:39:38.495419: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-22 20:39:38.524012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-22 20:39:38.674124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-08-22 20:39:38.674219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-22 20:39:38.805115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-22 20:39:38.805190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-22 20:39:38.906754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-22 20:39:39.012967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-22 20:39:39.135708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-22 20:39:39.211303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-22 20:39:39.351936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-22 20:39:39.352722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-22 20:39:39.353282: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-22 20:39:39.353492: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-22 20:39:39.353913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-08-22 20:39:39.353946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-22 20:39:39.353979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-22 20:39:39.353990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-22 20:39:39.354000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-22 20:39:39.354011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-22 20:39:39.354021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-22 20:39:39.354031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-22 20:39:39.354043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-22 20:39:39.354557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-22 20:39:39.354610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-22 20:39:42.389605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-22 20:39:42.389648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-22 20:39:42.389676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-22 20:39:42.390868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# ========== Model ========== #\n",
    "\n",
    "# ---------- Layers ---------- #\n",
    "\n",
    "IN = tf.keras.Input((128, 128, 10))\n",
    "\n",
    "X = IN\n",
    "\n",
    "X = k_layers.CONV_stack(X, 32, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack1')\n",
    "X = tf.keras.layers.Conv2D(32, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv1')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 64, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack2')\n",
    "X = tf.keras.layers.Conv2D(64, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv2')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 128, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack3')\n",
    "X = tf.keras.layers.Conv2D(128, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv3')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 256, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack4')\n",
    "X = tf.keras.layers.Conv2D(256, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv4')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 512, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack5')\n",
    "X = tf.keras.layers.Conv2D(512, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv5')(X)\n",
    "\n",
    "D = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "D = tf.keras.layers.Dense(512, use_bias=False, name='dense1')(D)\n",
    "D = tf.keras.layers.BatchNormalization(axis=-1, name='dense_bn1')(D)\n",
    "D = GELU()(D)\n",
    "\n",
    "D = tf.keras.layers.Dense(128, use_bias=False, name='dense2')(D)\n",
    "D = tf.keras.layers.BatchNormalization(axis=-1, name='dense_bn2')(D)\n",
    "D = GELU()(D)\n",
    "\n",
    "D = tf.keras.layers.Dense(1, activation='sigmoid', name='head')(D)\n",
    "\n",
    "OUT = D\n",
    "\n",
    "model = keras.models.Model(inputs=[IN,], outputs=[OUT,])\n",
    "\n",
    "W_new = model.get_weights()\n",
    "\n",
    "# ---------- Weights ---------- #\n",
    "\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'BIG10'\n",
    "\n",
    "model_name = '{}_tornado_tune'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "model_path_backup = temp_dir+model_name+'_backup'\n",
    "\n",
    "#W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "#W_old = k_utils.dummy_loader(temp_dir+'VGG_X_pp20_tune2')\n",
    "W_new = k_utils.dummy_loader(temp_dir+'BIG10_tornado')\n",
    "#W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "# for l in range(len(W_old)):\n",
    "#     if W_old[l].shape == W_new[l].shape:\n",
    "#         W_new[l] = W_old[l]\n",
    "\n",
    "# ---------- Compile ---------- #\n",
    "\n",
    "model.set_weights(W_new)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=1e-5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98ca9fe-612c-4ced-9003-ca941c391887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:39:52.956735: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-22 20:39:52.961891: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2022-08-22 20:39:54.306905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-22 20:39:54.788027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23873873873873874 0.019352686019352687 0.8719859796903822 1.5943396226415094\n",
      "Initial record 0.6277239503654598\n",
      "0.2864583333333333 0.01434768101434768 0.8824358950145114 1.330188679245283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 20:45:03.308422: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss improved from 0.6277239503654598 to 0.4068592767295598\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune/assets\n",
      "--- 310.3586049079895 seconds ---\n",
      "0.3271604938271605 0.009342676009342675 0.8954851077492587 1.028301886792453\n",
      "Validation loss improved from 0.4068592767295598 to 0.15720941066853025\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune/assets\n",
      "--- 252.381334066391 seconds ---\n",
      "0.33505154639175255 0.014681348014681348 0.9040628678993459 1.4433962264150944\n",
      "Validation loss 0.487706671853725 NOT improved\n",
      "0.33974358974358976 0.008341675008341674 0.9064646407413702 0.9716981132075472\n",
      "Validation loss improved from 0.15720941066853025 to 0.1546927914852443\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune/assets\n",
      "--- 260.20809745788574 seconds ---\n",
      "0.3924050632911392 0.008675342008675343 0.9069478283314761 1.0754716981132075\n",
      "Validation loss 0.18189634583233819 NOT improved\n",
      "0.3897058823529412 0.005005005005005005 0.918442026932593 0.7830188679245284\n",
      "Validation loss 0.2956437291897891 NOT improved\n",
      "0.35714285714285715 0.012679346012679346 0.9222980842477698 1.330188679245283\n",
      "Validation loss 0.392722371967655 NOT improved\n",
      "0.33962264150943394 0.008842175508842176 0.9284237067255936 1.009433962264151\n",
      "Validation loss improved from 0.1546927914852443 to 0.13962264150943407\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune/assets\n",
      "--- 259.9306116104126 seconds ---\n",
      "0.4166666666666667 0.006339673006339673 0.9336797489313212 0.9245283018867925\n",
      "Validation loss 0.17704402515723267 NOT improved\n",
      "0.34375 0.009009009009009009 0.9339984638726777 1.028301886792453\n",
      "Validation loss 0.15389150943396235 NOT improved\n",
      "0.34972677595628415 0.01284617951284618 0.9491755906850247 1.330188679245283\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss 0.39420558820496965 NOT improved\n",
      "0.3525641025641026 0.008341675008341674 0.9415500406066444 0.9905660377358491\n",
      "Validation loss improved from 0.13962264150943407 to 0.13703434929850022\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune/assets\n",
      "--- 247.63790464401245 seconds ---\n",
      "0.3382352941176471 0.005005005005005005 0.9309529655441605 0.7169811320754716\n",
      "Validation loss 0.35876803551609326 NOT improved\n",
      "0.28994082840236685 0.010510510510510511 0.9308624662398247 1.0566037735849056\n",
      "Validation loss 0.18729485318745118 NOT improved\n",
      "0.375 0.011678345011678345 0.9378726210487216 1.2830188679245282\n",
      "Validation loss 0.3514150943396226 NOT improved\n",
      "0.391304347826087 0.005338672005338672 0.9317367682147555 0.8113207547169812\n",
      "Validation loss 0.2726825266611977 NOT improved\n",
      "0.32934131736526945 0.010176843510176843 0.9285795229191456 1.0943396226415094\n",
      "Validation loss 0.20960343464015363 NOT improved\n",
      "0.31176470588235294 0.010677344010677344 0.9300519072531651 1.1037735849056605\n",
      "Validation loss 0.2206659267480578 NOT improved\n",
      "0.2903225806451613 0.008174841508174841 0.9286802525796237 0.8867924528301887\n",
      "Validation loss 0.23250152160681678 NOT improved\n",
      "0.3652694610778443 0.010176843510176843 0.9329140461215933 1.150943396226415\n",
      "Validation loss 0.24770082476556318 NOT improved\n",
      "0.30303030303030304 0.015348682015348681 0.9349561825976921 1.4339622641509433\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss 0.48656375071469404 NOT improved\n",
      "0.3163265306122449 0.015015015015015015 0.9356006950346573 1.4339622641509433\n",
      "Validation loss 0.48390450519830563 NOT improved\n",
      "0.32019704433497537 0.01618284951618285 0.9324584017980244 1.528301886792453\n",
      "Validation loss 0.5586021005669674 NOT improved\n",
      "0.37640449438202245 0.012012012012012012 0.9325158491825158 1.3113207547169812\n",
      "Validation loss 0.3737757048971805 NOT improved\n",
      "0.31100478468899523 0.017183850517183852 0.9359965311223173 1.5849056603773586\n",
      "Validation loss 0.6057235713640878 NOT improved\n",
      "0.3413173652694611 0.010176843510176843 0.9314715659055282 1.1132075471698113\n",
      "Validation loss 0.22230256468195683 NOT improved\n",
      "0.37748344370860926 0.0075075075075075074 0.9410597704622862 0.9622641509433962\n",
      "Validation loss 0.1546919905035612 NOT improved\n",
      "0.3431952662721893 0.010510510510510511 0.938299935155281 1.1415094339622642\n",
      "Validation loss 0.24456849391537355 NOT improved\n",
      "0.31210191082802546 0.00850850850850851 0.9355046870770141 0.9433962264150944\n",
      "Validation loss 0.18286263670231945 NOT improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x2b6673067a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/ksha/anaconda3/lib/python3.9/weakref.py\", line 370, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x2b666ed93310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/c_api_util.py\", line 58, in __del__\n",
      "    self.deleter(self.graph)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain_on_batch([X_batch,], [Y_batch,]);\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# epoch end operations\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mVALID_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m record_temp \u001b[38;5;241m=\u001b[39m verif_metric(VALID_target, Y_pred, thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1598\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1592\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1593\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1594\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1595\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1596\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1598\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1100\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1099\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1115\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:263\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    253\u001b[0m              x,\n\u001b[1;32m    254\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    261\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 263\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    265\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[1;32m    267\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1016\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1016\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py:1011\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1009\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m   1010\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m-> 1011\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor_v2_with_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scipy_sparse \u001b[38;5;129;01mand\u001b[39;00m scipy_sparse\u001b[38;5;241m.\u001b[39missparse(x):\n\u001b[1;32m   1013\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1404\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m   1343\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1344\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1404\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1410\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1409\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1410\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1540\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1537\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1540\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1543\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    275\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    279\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    300\u001b[0m   \u001b[38;5;124;03m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========== Initial record ========== #\n",
    "\n",
    "Y_pred = model.predict([VALID_input,])\n",
    "record = verif_metric(VALID_target, Y_pred)\n",
    "print('Initial record {}'.format(record))\n",
    "\n",
    "# ========== Training hyper parameters ========== #\n",
    "\n",
    "tol = 0\n",
    "min_del = 0\n",
    "max_tol = 500 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "batch_size = 100\n",
    "batch_size_half = 50\n",
    "\n",
    "valid_size = 1\n",
    "\n",
    "X_batch = np.empty((batch_size, 128, 128, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "\n",
    "L_full = len(filename_train_full)\n",
    "L_aug = len(filename_train_aug)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i <= 10:\n",
    "        batch_size_full = 70\n",
    "    if i > 10 and i <= 35:\n",
    "        batch_size_full = 85\n",
    "    if i > 35:\n",
    "        batch_size_full = 95\n",
    "    \n",
    "    batch_size_aug = batch_size - batch_size_full\n",
    "    \n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        ind_full = du.shuffle_ind(L_full)\n",
    "        ind_aug = du.shuffle_ind(L_aug)\n",
    "        \n",
    "        file_pick_full = []\n",
    "        for ind_temp in ind_full[:batch_size_full]:\n",
    "            file_pick_full.append(filename_train_full[ind_temp])\n",
    "\n",
    "        file_pick_aug = []\n",
    "        for ind_temp in ind_aug[:batch_size_aug]:\n",
    "            file_pick_aug.append(filename_train_aug[ind_temp])\n",
    "        \n",
    "        file_pick = file_pick_full + file_pick_aug\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            \n",
    "            data = np.load(file_pick[k])\n",
    "            \n",
    "            for c, v in enumerate(ind_pick_from_batch):\n",
    "                \n",
    "                X_batch[k, ..., c] = data[..., v]\n",
    "            \n",
    "            if 'pos' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.95, 0.99)\n",
    "            elif 'neg' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.01, 0.05)\n",
    "            else:\n",
    "                werhgaer\n",
    "        \n",
    "        # # add noise within sparse inputs\n",
    "        # for v in flag_sparse:\n",
    "        #     X_batch[..., v] += np.random.uniform(0, 0.01, size=(batch_size, 128, 128))\n",
    "\n",
    "        # shuffle indices\n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "        \n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input,])\n",
    "    record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        model.save(model_path_backup)\n",
    "    \n",
    "    if (record - record_temp > min_del) and (np.max(Y_pred) > 0.6):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcb796-c614-4fae-871e-cfc9fadd324c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4aa6cda4-1594-4b14-b2ad-97b80936f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'BIG10'\n",
    "\n",
    "model_name = '{}_tornado_tune3'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "model.set_weights(W_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c2a4002-27e1-492b-af4e-3ac30528d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model.predict([VALID_input,])\n",
    "# record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2f0a8e2-ca24-4110-be82-4d4f33e9a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'BIG10'\n",
    "\n",
    "model_name = '{}_tornado_tune4'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f17ccbf-e25b-480d-9aeb-1f338eea1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17687074829931973 0.01906152241918665 0.9026405937557505 1.4423529411764706\n",
      "Initial record 0.5185082032813126\n"
     ]
    }
   ],
   "source": [
    "# ========== Initial record ========== #\n",
    "\n",
    "Y_pred = model.predict([VALID_input,])\n",
    "record = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "print('Initial record {}'.format(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af8db8-a88e-49b2-b54b-4522134440d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17587373167981962 0.01927007299270073 0.9025079065202725 1.4541176470588235\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss 0.528119371311095 NOT improved\n",
      "0.17567567567567569 0.019311783107403547 0.9016580997362447 1.4564705882352942\n",
      "Validation loss 0.5300413354531003 NOT improved\n",
      "0.17848970251716248 0.01872784150156413 0.9013394835306385 1.423529411764706\n",
      "Validation loss improved from 0.5185082032813126 to 0.5031255889083323\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4/assets\n",
      "--- 558.9445395469666 seconds ---\n",
      "0.1791569086651054 0.01789363920750782 0.9019445255474452 1.3694117647058823\n",
      "Validation loss improved from 0.5031255889083323 to 0.4596980300316848\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4/assets\n",
      "--- 548.3636150360107 seconds ---\n",
      "0.17819460726846426 0.017851929092805006 0.9023446972949764 1.3647058823529412\n",
      "Validation loss improved from 0.4596980300316848 to 0.45612578442866014\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4/assets\n",
      "--- 548.4164078235626 seconds ---\n",
      "0.18105515587529977 0.017059436913451513 0.9024503956327056 1.3176470588235294\n",
      "Validation loss improved from 0.45612578442866014 to 0.41790661588376354\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune4/assets\n",
      "--- 550.2921328544617 seconds ---\n",
      "0.1769499417927823 0.018102189781021898 0.90256620253941 1.3788235294117648\n",
      "Validation loss 0.46766883517085533 NOT improved\n",
      "0.17626728110599077 0.018477580813347237 0.9028343740415875 1.4023529411764706\n",
      "Validation loss 0.48662889671997833 NOT improved\n",
      "0.176878612716763 0.01835245046923879 0.9027962460896767 1.3952941176470588\n",
      "Validation loss 0.4808595715742945 NOT improved\n",
      "0.17819460726846426 0.017851929092805006 0.9022282033981476 1.3647058823529412\n",
      "Validation loss 0.45612578442866014 NOT improved\n",
      "0.179456906729634 0.017601668404588114 0.9025365638226093 1.3505882352941176\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss 0.44457920688936736 NOT improved\n",
      "0.15350877192982457 0.029822732012513033 0.8965642642458442 2.0941176470588236\n",
      "Validation loss 1.044592363261094 NOT improved\n",
      "0.13742690058479531 0.039332638164754956 0.8940123903576029 2.6611764705882353\n",
      "Validation loss 1.5014557963536292 NOT improved\n",
      "0.13221476510067115 0.044421272158498434 0.8924371710728087 2.969411764705882\n",
      "Validation loss 1.7490864587445716 NOT improved\n",
      "0.12911235257603973 0.0494681960375391 0.8916019382935656 3.28\n",
      "Validation loss 1.9981775294847919 NOT improved\n",
      "0.12901234567901235 0.04984358706986444 0.8915620928663436 3.303529411764706\n",
      "Validation loss 2.0170210602759626 NOT improved\n",
      "0.1278648974668275 0.05142857142857143 0.8913425504508373 3.4\n",
      "Validation loss 2.094427020506634 NOT improved\n",
      "0.12903225806451613 0.05209593326381647 0.8913602159111821 3.447058823529412\n",
      "Validation loss 2.1318406072106266 NOT improved\n",
      "0.12717770034843207 0.054098018769551615 0.8906738637060663 3.5670588235294116\n",
      "Validation loss 2.228211518753843 NOT improved\n",
      "0.12703962703962704 0.053847758081334726 0.8910020977734159 3.550588235294118\n",
      "Validation loss 2.2150626628273686 NOT improved\n",
      "0.1272515979081929 0.0540563086548488 0.8907450653254002 3.5647058823529414\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/BIG10_tornado_tune_backup/assets\n",
      "Validation loss 2.226314386300715 NOT improved\n",
      "0.12695652173913044 0.054223149113660066 0.8912585413727534 3.5741176470588236\n",
      "Validation loss 2.233902813299233 NOT improved\n",
      "0.12585812356979406 0.055182481751824816 0.8910984726737411 3.6305882352941174\n",
      "Validation loss 2.279298963521335 NOT improved\n",
      "0.12600690448791715 0.054765380604796667 0.8910548488008343 3.604705882352941\n",
      "Validation loss 2.2585633249847694 NOT improved\n",
      "0.12521246458923513 0.05589155370177268 0.8907565478746242 3.672941176470588\n",
      "Validation loss 2.3133104482586235 NOT improved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== Training hyper parameters ========== #\n",
    "\n",
    "tol = 0\n",
    "min_del = 0\n",
    "max_tol = 500 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "batch_size = 100\n",
    "batch_size_half = 50\n",
    "\n",
    "valid_size = 1\n",
    "\n",
    "X_batch = np.empty((batch_size, 128, 128, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "\n",
    "L_full = len(filename_train_full)\n",
    "L_aug = len(filename_train_aug)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i <= 10:\n",
    "        batch_size_full = 70\n",
    "    if i > 10 and i <= 35:\n",
    "        batch_size_full = 85\n",
    "    if i > 35:\n",
    "        batch_size_full = 95\n",
    "    \n",
    "    batch_size_aug = batch_size - batch_size_full\n",
    "    \n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        ind_full = du.shuffle_ind(L_full)\n",
    "        ind_aug = du.shuffle_ind(L_aug)\n",
    "        \n",
    "        file_pick_full = []\n",
    "        for ind_temp in ind_full[:batch_size_full]:\n",
    "            file_pick_full.append(filename_train_full[ind_temp])\n",
    "\n",
    "        file_pick_aug = []\n",
    "        for ind_temp in ind_aug[:batch_size_aug]:\n",
    "            file_pick_aug.append(filename_train_aug[ind_temp])\n",
    "        \n",
    "        file_pick = file_pick_full + file_pick_aug\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            \n",
    "            data = np.load(file_pick[k])\n",
    "            \n",
    "            for c, v in enumerate(ind_pick_from_batch):\n",
    "                \n",
    "                X_batch[k, ..., c] = data[..., v]\n",
    "            \n",
    "            if 'pos' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.95, 0.99)\n",
    "            elif 'neg' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.01, 0.05)\n",
    "            else:\n",
    "                werhgaer\n",
    "        \n",
    "        # # add noise within sparse inputs\n",
    "        # for v in flag_sparse:\n",
    "        #     X_batch[..., v] += np.random.uniform(0, 0.01, size=(batch_size, 128, 128))\n",
    "\n",
    "        # shuffle indices\n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "        \n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input,])\n",
    "    record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        model.save(model_path_backup)\n",
    "    \n",
    "    if (record - record_temp > min_del) and (np.max(Y_pred) > 0.6):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "949c295b-e524-46b5-804d-b1737d404f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b6906da4310>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdd747-e1f4-42a3-a018-f43d1ba30c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
