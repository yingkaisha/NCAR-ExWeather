{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce76310e-2358-43eb-ba0c-188a45af0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2f455b-7a16-4d6c-b673-ff37e482f46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-06 17:23:49.814251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras_unet_collection import models as k_models\n",
    "from keras_unet_collection import utils as k_utils\n",
    "from keras_unet_collection import layer_utils as k_layers\n",
    "from keras_unet_collection.activations import GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a4ac9a-f7f6-4dbb-a676-c787f2c01f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329c3d14-edd9-49fa-a0b6-c112ea9c7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ee330-cf69-4ead-aa86-42cb0aeec11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c181e0e9-cf6a-4fc9-a913-97562ce045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train_pos = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*TRAIN*.npy\"))\n",
    "filename_train_neg = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_neg/*TRAIN*.npy\"))\n",
    "\n",
    "filename_valid_pos = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*VALID*.npy\"))[::10]\n",
    "filename_valid_neg = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_neg/*VALID*.npy\"))[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1ca07d-9a52-4d14-94ca-060782457026",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_shape = (128, 128)\n",
    "\n",
    "label_pos = np.ones(len(filename_valid_pos))\n",
    "label_neg = np.zeros(len(filename_valid_neg))\n",
    "VALID_label = np.hstack([label_pos, label_neg])\n",
    "\n",
    "L_valid = len(VALID_label)\n",
    "\n",
    "VALID_input = np.empty((L_valid,)+grid_shape+(5,))\n",
    "\n",
    "for i, filename in enumerate(filename_valid_pos+filename_valid_neg):\n",
    "    data = np.load(filename)\n",
    "    VALID_input[i, ...] = data[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6b2f42-6554-4934-a99d-31da92f18145",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_label_cate = to_categorical(VALID_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3668142d-fef2-498e-89c2-ec7efe6e161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b21ea30-fb99-45e6-8c3d-b5c423b9d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 5 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    }
   ],
   "source": [
    "model = Xception(include_top=True,\n",
    "                 weights=None,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=(128, 128, 5),\n",
    "                 pooling=None,\n",
    "                 classes=2,\n",
    "                 classifier_activation=\"softmax\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb49538d-f688-48cb-b35d-17c4ead379c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd91c3ed-4f9e-4d56-8c0a-1b74c820906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8e6183-6964-467a-8ebe-01b822b8b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0\n",
    "min_del = 0\n",
    "max_tol = 500 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "batch_size = 100\n",
    "batch_size_half = 50\n",
    "\n",
    "valid_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67244080-0104-4922-9543-941d6318f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_dir = '/glade/scratch/ksha/DATA/NCAR_batch/'\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'Xcept_chad'\n",
    "\n",
    "model_name = '{}_pp5'.format(key)\n",
    "model_path = temp_dir+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6bf49a3-1b86-484a-b8e2-94cadceb6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.empty((batch_size, 128, 128, 5))*np.nan\n",
    "# Y_batch = np.empty((batch_size, 1))*np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9c63cfd-6675-4ed1-a369-0e11a0d75f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Y_pred = model.predict([VALID_X])\n",
    "record = 1.0 #np.nanmean(np.abs(Y_pred-VALID_Y))\n",
    "print(\"Initial record: {}\".format(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "842940ff-c806-4094-96e5-71b903fe9276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bc8fcbf-6dfa-4d4f-bb1c-b8d00f4070d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9808d29-697e-4831-bd18-db6c6c65cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved from 1.0 to 0.3718861354831119\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5/assets\n",
      "--- 198.77639651298523 seconds ---\n",
      "Validation loss improved from 0.3718861354831119 to 0.35009164450075214\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5/assets\n",
      "--- 193.4740068912506 seconds ---\n",
      "Validation loss improved from 0.35009164450075214 to 0.3416244752666213\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5/assets\n",
      "--- 193.4643280506134 seconds ---\n",
      "Validation loss improved from 0.3416244752666213 to 0.2965750116607416\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5/assets\n",
      "--- 190.80728816986084 seconds ---\n",
      "Validation loss improved from 0.2965750116607416 to 0.25366164361831767\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5/assets\n",
      "--- 194.14038276672363 seconds ---\n",
      "Validation loss 0.5227603759591223 NOT improved\n",
      "Validation loss 0.5800953108060409 NOT improved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m file_pick \u001b[38;5;241m=\u001b[39m file_pick_pos\u001b[38;5;241m+\u001b[39mfile_pick_neg\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_pick\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     X_batch[k, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     26\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py:423\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    421\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    422\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 423\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    426\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(N, \u001b[38;5;28mlen\u001b[39m(magic)), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# back-up\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------- #\n",
    "# loop of epoch\n",
    "#filenames = glob(batch_dir+'TRAIN*.npy')\n",
    "\n",
    "for i in range(epochs):\n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    shuffle(filename_train_pos)\n",
    "    shuffle(filename_train_neg)\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        shuffle(filename_train_pos)\n",
    "        shuffle(filename_train_neg)\n",
    "        \n",
    "        file_pick_pos = filename_train_pos[:batch_size_half]\n",
    "        file_pick_neg = filename_train_neg[:batch_size_half]\n",
    "        \n",
    "        file_pick = file_pick_pos+file_pick_neg\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            data = np.load(file_pick[k])\n",
    "            X_batch[k, ...] = data[...]\n",
    "        \n",
    "        Y_batch = np.ones((batch_size, 1))\n",
    "        Y_batch[batch_size_half:, :] = 0\n",
    "        \n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = to_categorical(Y_batch[ind_, :])\n",
    "        Y_batch = Y_batch*0.9\n",
    "        Y_batch[Y_batch==0]=0.09\n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input])\n",
    "    Y_pred = Y_pred[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(VALID_label.ravel(), Y_pred.ravel())\n",
    "    record_temp = auc(fpr, tpr)\n",
    "    record_temp = 1 - record_temp\n",
    "    \n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fe17f-d2c1-4be8-bb57-29104540dcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd24f2-f431-4f19-be68-5a74451ff3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacdadc-43a1-4777-b3f0-69c09503d772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32328d12-868e-4e4f-b1c2-d9b08c6d82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39573720-8d53-45ce-b96c-1dea0485acd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "910249a6-ead0-426b-9508-ef1c670e402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'Xcept_chad'\n",
    "model_name = '{}_pp5'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "W = k_utils.dummy_loader(model_path)\n",
    "model.set_weights(W)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=1e-5))\n",
    "\n",
    "model_name = '{}_pp5_tune'.format(key)\n",
    "model_path = temp_dir+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d88473a6-83c9-403c-9ba1-83d76e5daf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25366164361831767\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict([VALID_input])\n",
    "Y_pred = Y_pred[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(VALID_label.ravel(), Y_pred.ravel())\n",
    "record_temp = auc(fpr, tpr)\n",
    "record_temp = 1 - record_temp\n",
    "\n",
    "print(record_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "712dd196-b125-4909-8c11-6b61c31324a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss 0.3245193620838901 NOT improved\n",
      "Validation loss 0.44887880917563805 NOT improved\n",
      "Validation loss 0.652474112628058 NOT improved\n",
      "Validation loss 0.7714807802612006 NOT improved\n",
      "Validation loss 0.8062652456319492 NOT improved\n",
      "Validation loss 0.6124312173814386 NOT improved\n",
      "Validation loss 0.4598206688223281 NOT improved\n",
      "Validation loss 0.30587445320575857 NOT improved\n",
      "Validation loss 0.2539610410416089 NOT improved\n",
      "Validation loss improved from 0.25366164361831767 to 0.23196898715427472\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 188.93584656715393 seconds ---\n",
      "Validation loss improved from 0.23196898715427472 to 0.21977287553891545\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 181.80476450920105 seconds ---\n",
      "Validation loss improved from 0.21977287553891545 to 0.2133669525124171\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 179.82111382484436 seconds ---\n",
      "Validation loss improved from 0.2133669525124171 to 0.2107387552630915\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 178.88134598731995 seconds ---\n",
      "Validation loss improved from 0.2107387552630915 to 0.2096447071788149\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 183.54113745689392 seconds ---\n",
      "Validation loss 0.21120702333829167 NOT improved\n",
      "Validation loss improved from 0.2096447071788149 to 0.208038728895108\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/Xcept_chad_pp5_tune/assets\n",
      "--- 189.316339969635 seconds ---\n",
      "Validation loss 0.20850896669019825 NOT improved\n",
      "Validation loss 0.2107707303826405 NOT improved\n",
      "Validation loss 0.2104993686391179 NOT improved\n",
      "Validation loss 0.21199090619721161 NOT improved\n",
      "Validation loss 0.2108694790064628 NOT improved\n",
      "Validation loss 0.2089400727168057 NOT improved\n",
      "Validation loss 0.2097244808343629 NOT improved\n",
      "Validation loss 0.21041362016656995 NOT improved\n",
      "Validation loss 0.21181284351914886 NOT improved\n",
      "Validation loss 0.21293308887796347 NOT improved\n",
      "Validation loss 0.21453263274336276 NOT improved\n",
      "Validation loss 0.21305672162973055 NOT improved\n",
      "Validation loss 0.2151234173957256 NOT improved\n",
      "Validation loss 0.2146362400095807 NOT improved\n",
      "Validation loss 0.2163391285118792 NOT improved\n",
      "Validation loss 0.21766941166830556 NOT improved\n",
      "Validation loss 0.21778726657506153 NOT improved\n",
      "Validation loss 0.21652566098546933 NOT improved\n",
      "Validation loss 0.21701809095798774 NOT improved\n",
      "Validation loss 0.21935831515938442 NOT improved\n",
      "Validation loss 0.21786165632957666 NOT improved\n",
      "Validation loss 0.21892720913277697 NOT improved\n",
      "Validation loss 0.22008553574279976 NOT improved\n",
      "Validation loss 0.2219356936355461 NOT improved\n",
      "Validation loss 0.22110755773642943 NOT improved\n",
      "Validation loss 0.22031770006050977 NOT improved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m file_pick \u001b[38;5;241m=\u001b[39m file_pick_pos\u001b[38;5;241m+\u001b[39mfile_pick_neg\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_pick\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     X_batch[k, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     26\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py:423\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    421\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    422\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 423\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    426\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(N, \u001b[38;5;28mlen\u001b[39m(magic)), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# back-up\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------- #\n",
    "# loop of epoch\n",
    "#filenames = glob(batch_dir+'TRAIN*.npy')\n",
    "\n",
    "for i in range(epochs):\n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    shuffle(filename_train_pos)\n",
    "    shuffle(filename_train_neg)\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        shuffle(filename_train_pos)\n",
    "        shuffle(filename_train_neg)\n",
    "        \n",
    "        file_pick_pos = filename_train_pos[:batch_size_half]\n",
    "        file_pick_neg = filename_train_neg[:batch_size_half]\n",
    "        \n",
    "        file_pick = file_pick_pos+file_pick_neg\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            data = np.load(file_pick[k])\n",
    "            X_batch[k, ...] = data[...]\n",
    "        \n",
    "        Y_batch = np.ones((batch_size, 1))\n",
    "        Y_batch[batch_size_half:, :] = 0\n",
    "        \n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = to_categorical(Y_batch[ind_, :])\n",
    "        Y_batch = Y_batch*0.9\n",
    "        Y_batch[Y_batch==0]=0.09\n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input])\n",
    "    Y_pred = Y_pred[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(VALID_label.ravel(), Y_pred.ravel())\n",
    "    record_temp = auc(fpr, tpr)\n",
    "    record_temp = 1 - record_temp\n",
    "    \n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b23baaa-074e-469c-b70c-0d62bb2017b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'Xcept_chad'\n",
    "model_name = '{}_pp5_tune'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "W = k_utils.dummy_loader(model_path)\n",
    "model.set_weights(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ad74d-a79e-4e17-8114-21a96b97d675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a58e8ce-edd1-4847-ad19-5381d63790f7",
   "metadata": {},
   "source": [
    "### Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b99b905-5d90-4c77-90f2-12fd1e73dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99e261c3-c989-4332-b3e2-874e9b65a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train_pos = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*TRAIN*.npy\"))\n",
    "filename_train_neg = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_neg/*TRAIN*.npy\"))\n",
    "\n",
    "filename_valid_pos = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*VALID*.npy\"))\n",
    "filename_valid_neg = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_neg/*VALID*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c1cadcb-7898-4e91-b679-278abbb6b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_shape = (128, 128)\n",
    "\n",
    "label_pos = np.ones(len(filename_valid_pos))\n",
    "label_neg = np.zeros(len(filename_valid_neg))\n",
    "VALID_label = np.hstack([label_pos, label_neg])\n",
    "\n",
    "L_valid = len(VALID_label)\n",
    "\n",
    "VALID_input = np.empty((L_valid,)+grid_shape+(5,))\n",
    "\n",
    "for i, filename in enumerate(filename_valid_pos+filename_valid_neg):\n",
    "    data = np.load(filename)\n",
    "    VALID_input[i, ...] = data[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9888419f-5dab-425f-a7a4-88d31b8d1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_valid_pos = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*VALID*.npy\"))[::10]\n",
    "label_pos = np.ones(len(filename_valid_pos))\n",
    "label_neg = np.zeros(len(filename_valid_neg))\n",
    "VALID_label_skew = np.hstack([label_pos, label_neg])\n",
    "\n",
    "L_valid = len(VALID_label_skew)\n",
    "\n",
    "VALID_skew = np.empty((L_valid,)+grid_shape+(5,))\n",
    "\n",
    "for i, filename in enumerate(filename_valid_pos+filename_valid_neg):\n",
    "    data = np.load(filename)\n",
    "    VALID_skew[i, ...] = data[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc6866-d00f-4013-bd6b-663632c5002a",
   "metadata": {},
   "source": [
    "**Balanced verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d4368dc-01e6-47d4-b8f9-7878e0549921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict([VALID_input])\n",
    "Y_pred_label = Y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a6a3bbd-b744-41de-9ae7-fe8acc561e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.72      0.83     38948\n",
      "        True       0.59      0.93      0.72     16348\n",
      "\n",
      "    accuracy                           0.78     55296\n",
      "   macro avg       0.77      0.83      0.77     55296\n",
      "weighted avg       0.85      0.78      0.79     55296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_pred_label[:, 1].ravel(), VALID_label.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4489ecb-95ee-4ffe-9517-3c4bfa224b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371623946030101"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(VALID_label.ravel(), Y_pred[:, 1].ravel())\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f0611-6e2f-4dda-af69-a1e549607af4",
   "metadata": {},
   "source": [
    "**Natural verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "771cfcc6-5925-4495-94ce-7a2bb24f7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict([VALID_skew])\n",
    "Y_pred_label = Y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db07630c-19ae-4dfa-b798-4888e2c04078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.96      0.96     29372\n",
      "        True       0.55      0.55      0.55      2596\n",
      "\n",
      "    accuracy                           0.93     31968\n",
      "   macro avg       0.75      0.75      0.75     31968\n",
      "weighted avg       0.93      0.93      0.93     31968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_pred_label[:, 1].ravel(), VALID_label_skew.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46ef4168-9f8a-4eea-ad16-9538bb378bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977736100709574"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(VALID_label_skew.ravel(), Y_pred[:, 1].ravel())\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b0ae141-1281-49d9-b907-d53534521e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2adb6f642b80>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred[:, 1].ravel()[:10000])\n",
    "plt.plot(VALID_label_skew.ravel()[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63261176-3bb0-4bc2-afd4-e7c683cfb326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
