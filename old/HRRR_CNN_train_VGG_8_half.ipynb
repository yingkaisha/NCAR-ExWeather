{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2691f0a5-e348-4592-a238-9c6858792779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 12:36:06.423839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# general tools\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# data tools\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras_unet_collection import models as k_models\n",
    "from keras_unet_collection import utils as k_utils\n",
    "from keras_unet_collection import layer_utils as k_layers\n",
    "from keras_unet_collection.activations import GELU\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "from sklearn.metrics import classification_report, auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def verif_metric(VALID_target, Y_pred, thres=0.5):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(VALID_target.ravel(), Y_pred.ravel()>thres).ravel()\n",
    "\n",
    "    CSI = tp/(tp+fn+fp)\n",
    "    CSI_metric = 1 - CSI\n",
    "    \n",
    "    POFD = fp/(tn+fp)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(VALID_target.ravel(), Y_pred.ravel())\n",
    "    AUC = auc(fpr, tpr)\n",
    "    AUC_metric = 1 - AUC\n",
    "    \n",
    "    freq = (tp+fp)/(tp+fn)\n",
    "    freq_metric = np.abs(freq-1.0)\n",
    "    \n",
    "    print('{} {} {} {}'.format(CSI, POFD, AUC, freq))\n",
    "    metric = 0.2*CSI_metric + 0.8*freq_metric\n",
    "\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9d0511-ac88-4a24-8a29-7863dfcf51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== training/validation split ========== #\n",
    "\n",
    "filename_aug = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch_aug/*.npy\"))\n",
    "filename_full = sorted(glob(\"/glade/scratch/ksha/DATA/NCAR_batch/*.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08650a34-57d2-4b79-b1d5-f000bf771a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_train_aug = 50000\n",
    "cut_train_full = 600000\n",
    "\n",
    "filename_train_aug = filename_aug[:cut_train_aug]\n",
    "filename_train_full = filename_full[:cut_train_full]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a4d818-939f-4c9b-8946-9cfe383dbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4\n",
    "\n",
    "L_valid_aug = int(50*factor)\n",
    "L_valid_full = int(3000*factor)\n",
    "\n",
    "filename_valid_aug = filename_aug[cut_train_aug:]\n",
    "filename_valid_full = filename_full[cut_train_full:]\n",
    "\n",
    "shuffle(filename_valid_aug)\n",
    "shuffle(filename_valid_full)\n",
    "\n",
    "filename_valid_aug = filename_aug[-L_valid_aug:]\n",
    "filename_valid_full = filename_full[-L_valid_full:]\n",
    "\n",
    "# ========== Validation set ========== #\n",
    "\n",
    "ind_pick_from_batch = [1, 2, 5, 10, 11, 12, 13, 14, 15, 17]\n",
    "\n",
    "L_vars = len(ind_pick_from_batch)\n",
    "\n",
    "grid_shape = (64, 64)\n",
    "\n",
    "L_valid = L_valid_aug+L_valid_full\n",
    "\n",
    "VALID_input = np.empty((L_valid,)+grid_shape+(L_vars,))\n",
    "VALID_target = np.empty(L_valid)\n",
    "\n",
    "for i, filename in enumerate(filename_valid_aug+filename_valid_full):\n",
    "    data = np.load(filename)\n",
    "    \n",
    "    for c, v in enumerate(ind_pick_from_batch):\n",
    "    \n",
    "        VALID_input[i, ..., c] = data[:, 32:-32, 32:-32, v]\n",
    "        \n",
    "    if 'pos' in filename:\n",
    "        VALID_target[i] = True\n",
    "    elif 'neg' in filename:\n",
    "        VALID_target[i] = False\n",
    "    else:\n",
    "        aergheagtha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd15d7-7032-4853-8bcb-51402c30d859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3519c468-8301-4d80-b085-bcb0741cdf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model ========== #\n",
    "\n",
    "# ---------- Layers ---------- #\n",
    "\n",
    "IN = tf.keras.Input((64, 64, 10))\n",
    "\n",
    "X = IN\n",
    "\n",
    "X = k_layers.CONV_stack(X, 32, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack1')\n",
    "X = tf.keras.layers.Conv2D(32, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv1')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 64, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack2')\n",
    "X = tf.keras.layers.Conv2D(64, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv2')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 128, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack3')\n",
    "X = tf.keras.layers.Conv2D(128, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv3')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 256, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack4')\n",
    "X = tf.keras.layers.Conv2D(256, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv4')(X)\n",
    "\n",
    "X = k_layers.CONV_stack(X, 512, kernel_size=3, stack_num=2, dilation_rate=1, activation='GELU', batch_norm=True, name='conv_stack5')\n",
    "X = tf.keras.layers.Conv2D(512, kernel_size=2, strides=(2, 2), padding='valid', use_bias=True, name='stride_conv5')(X)\n",
    "\n",
    "D = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "D = tf.keras.layers.Dense(512, use_bias=False, name='dense1')(D)\n",
    "D = tf.keras.layers.BatchNormalization(axis=-1, name='dense_bn1')(D)\n",
    "D = GELU()(D)\n",
    "\n",
    "D = tf.keras.layers.Dense(128, use_bias=False, name='dense2')(D)\n",
    "D = tf.keras.layers.BatchNormalization(axis=-1, name='dense_bn2')(D)\n",
    "D = GELU()(D)\n",
    "\n",
    "D = tf.keras.layers.Dense(1, activation='sigmoid', name='head')(D)\n",
    "\n",
    "OUT = D\n",
    "\n",
    "model = keras.models.Model(inputs=[IN,], outputs=[OUT,])\n",
    "\n",
    "W_new = model.get_weights()\n",
    "\n",
    "# ---------- Weights ---------- #\n",
    "\n",
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'SMALL10'\n",
    "\n",
    "model_name = '{}_tornado_tune'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "model_path_backup = temp_dir+model_name+'_backup'\n",
    "\n",
    "#W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "#W_old = k_utils.dummy_loader(temp_dir+'VGG_X_pp20_tune2')\n",
    "W_old = k_utils.dummy_loader(temp_dir+'BIG10_tornado')\n",
    "#W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "for l in range(len(W_old)):\n",
    "    if W_old[l].shape == W_new[l].shape:\n",
    "        W_new[l] = W_old[l]\n",
    "\n",
    "# ---------- Compile ---------- #\n",
    "\n",
    "model.set_weights(W_new)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=1e-5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98ca9fe-612c-4ced-9003-ca941c391887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 12:52:45.629669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-23 12:52:45.630488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n",
      "2022-08-23 12:52:46.121887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-23 12:52:46.834969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.2594056320471415 0.0\n",
      "Initial record 1.0\n",
      "0.19827586206896552 0.001668335001668335 0.8602958304216166 0.3113207547169811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 12:56:18.073277: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune_backup/assets\n",
      "Validation loss improved from 1.0 to 0.711288223812622\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune/assets\n",
      "--- 213.0487241744995 seconds ---\n",
      "0.2671232876712329 0.00667334000667334 0.8688436864537495 0.7452830188679245\n",
      "Validation loss improved from 0.711288223812622 to 0.3503489273714139\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune/assets\n",
      "--- 205.42806386947632 seconds ---\n",
      "0.2247191011235955 0.012012012012012012 0.8843025415352458 1.0566037735849056\n",
      "Validation loss improved from 0.3503489273714139 to 0.20033919864320543\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune/assets\n",
      "--- 224.26278471946716 seconds ---\n",
      "0.2033898305084746 0.021688355021688355 0.897813694197342 1.679245283018868\n",
      "Validation loss 0.7027182603133996 NOT improved\n",
      "0.27325581395348836 0.011011011011011011 0.9026912132258045 1.0660377358490567\n",
      "Validation loss improved from 0.20033919864320543 to 0.1981790258885477\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune/assets\n",
      "--- 217.2609362602234 seconds ---\n",
      "0.2413793103448276 0.021021021021021023 0.9000667334000668 1.7169811320754718\n",
      "Validation loss 0.7253090435914119 NOT improved\n",
      "0.23577235772357724 0.02335669002335669 0.9093551098268079 1.8679245283018868\n",
      "Validation loss 0.847185151096794 NOT improved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m file_pick \u001b[38;5;241m=\u001b[39m file_pick_full \u001b[38;5;241m+\u001b[39m file_pick_aug\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 62\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_pick\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ind_pick_from_batch):\n\u001b[1;32m     66\u001b[0m         X_batch[k, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, c] \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;241m32\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m32\u001b[39m, v]\n",
      "File \u001b[0;32m/glade/work/ksha/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py:423\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    421\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    422\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 423\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# If the file size is less than N, we need to make sure not\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# to seek past the beginning of the file\u001b[39;00m\n\u001b[1;32m    426\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(N, \u001b[38;5;28mlen\u001b[39m(magic)), \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# back-up\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========== Initial record ========== #\n",
    "\n",
    "Y_pred = model.predict([VALID_input,])\n",
    "record = verif_metric(VALID_target, Y_pred)\n",
    "print('Initial record {}'.format(record))\n",
    "\n",
    "# ========== Training hyper parameters ========== #\n",
    "\n",
    "tol = 0\n",
    "min_del = 0\n",
    "max_tol = 500 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "batch_size = 100\n",
    "batch_size_half = 50\n",
    "\n",
    "valid_size = 1\n",
    "\n",
    "X_batch = np.empty((batch_size, 64, 64, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "\n",
    "L_full = len(filename_train_full)\n",
    "L_aug = len(filename_train_aug)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i <= 10:\n",
    "        batch_size_full = 70\n",
    "    if i > 10 and i <= 35:\n",
    "        batch_size_full = 85\n",
    "    if i > 35:\n",
    "        batch_size_full = 95\n",
    "    \n",
    "    batch_size_aug = batch_size - batch_size_full\n",
    "    \n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        ind_full = du.shuffle_ind(L_full)\n",
    "        ind_aug = du.shuffle_ind(L_aug)\n",
    "        \n",
    "        file_pick_full = []\n",
    "        for ind_temp in ind_full[:batch_size_full]:\n",
    "            file_pick_full.append(filename_train_full[ind_temp])\n",
    "\n",
    "        file_pick_aug = []\n",
    "        for ind_temp in ind_aug[:batch_size_aug]:\n",
    "            file_pick_aug.append(filename_train_aug[ind_temp])\n",
    "        \n",
    "        file_pick = file_pick_full + file_pick_aug\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            \n",
    "            data = np.load(file_pick[k])\n",
    "            \n",
    "            for c, v in enumerate(ind_pick_from_batch):\n",
    "                \n",
    "                X_batch[k, ..., c] = data[:, 32:-32, 32:-32, v]\n",
    "            \n",
    "            if 'pos' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.95, 0.99)\n",
    "            elif 'neg' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.01, 0.05)\n",
    "            else:\n",
    "                werhgaer\n",
    "        \n",
    "        # # add noise within sparse inputs\n",
    "        # for v in flag_sparse:\n",
    "        #     X_batch[..., v] += np.random.uniform(0, 0.01, size=(batch_size, 128, 128))\n",
    "\n",
    "        # shuffle indices\n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "        \n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input,])\n",
    "    record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        model.save(model_path_backup)\n",
    "    \n",
    "    if (record - record_temp > min_del) and (np.max(Y_pred) > 0.6):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcb796-c614-4fae-871e-cfc9fadd324c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa6cda4-1594-4b14-b2ad-97b80936f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'SMALL10'\n",
    "\n",
    "model_name = '{}_tornado_tune'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "W_new = k_utils.dummy_loader(model_path)\n",
    "\n",
    "model.set_weights(W_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2a4002-27e1-492b-af4e-3ac30528d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model.predict([VALID_input,])\n",
    "# record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f0a8e2-ca24-4110-be82-4d4f33e9a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = '/glade/work/ksha/NCAR/Keras_models/'\n",
    "\n",
    "key = 'SMALL10'\n",
    "\n",
    "model_name = '{}_tornado_tune2'.format(key)\n",
    "model_path = temp_dir+model_name\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f17ccbf-e25b-480d-9aeb-1f338eea1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1561822125813449 0.020852448077404287 0.8786575292754535 1.5260663507109005\n",
      "Initial record 0.5896166380524515\n"
     ]
    }
   ],
   "source": [
    "# ========== Initial record ========== #\n",
    "\n",
    "Y_pred = model.predict([VALID_input,])\n",
    "record = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "print('Initial record {}'.format(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af8db8-a88e-49b2-b54b-4522134440d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15242494226327943 0.018516973892735007 0.8803747431986431 1.3649289099526067\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune_backup/assets\n",
      "Validation loss improved from 0.5896166380524515 to 0.4614581395094295\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2/assets\n",
      "--- 231.24105525016785 seconds ---\n",
      "0.15261958997722094 0.01901743264659271 0.8814402934127215 1.3981042654028435\n",
      "Validation loss 0.48795949432683067 NOT improved\n",
      "0.15192743764172337 0.019184252231211944 0.8813645921083268 1.4075829383886256\n",
      "Validation loss 0.4956808631825559 NOT improved\n",
      "0.1558139534883721 0.018266744515806156 0.881536353031353 1.3554502369668247\n",
      "Validation loss improved from 0.4614581395094295 to 0.4531973988757853\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2/assets\n",
      "--- 242.08805322647095 seconds ---\n",
      "0.15227272727272728 0.019100842438902327 0.8812382914986447 1.4028436018957346\n",
      "Validation loss 0.4918203360620423 NOT improved\n",
      "0.15124153498871332 0.019351071815831178 0.8813319792748409 1.4170616113744077\n",
      "Validation loss 0.5034009821017835 NOT improved\n",
      "0.15192743764172337 0.019184252231211944 0.8813383041880017 1.4075829383886256\n",
      "Validation loss 0.4956808631825559 NOT improved\n",
      "0.1572769953051643 0.017933105346567686 0.8816075083044134 1.3364928909952607\n",
      "Validation loss improved from 0.4531973988757853 to 0.43773891373517576\n",
      "save to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune2/assets\n",
      "--- 220.7834861278534 seconds ---\n",
      "0.15456674473067916 0.018016515138877306 0.8818282873044366 1.3364928909952607\n",
      "Validation loss 0.43828096385007276 NOT improved\n",
      "0.15331807780320367 0.018850613061973477 0.8815284468899018 1.3886255924170616\n",
      "Validation loss 0.4802368583730086 NOT improved\n",
      "0.15242494226327943 0.018516973892735007 0.8815575019597347 1.3649289099526067\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune_backup/assets\n",
      "Validation loss 0.4614581395094295 NOT improved\n",
      "0.14688427299703263 0.03861873383935274 0.8801221419792787 2.6635071090047395\n",
      "Validation loss 1.5014288326043852 NOT improved\n",
      "0.13773796192609183 0.0568854783551589 0.8779685090479858 3.815165876777251\n",
      "Validation loss 2.424585109036583 NOT improved\n",
      "0.12651821862348178 0.06480940862457253 0.8771848127766408 4.274881516587678\n",
      "Validation loss 2.7946015695454465 NOT improved\n",
      "0.12366114897760468 0.06806239052464759 0.8767899010111561 4.469194312796208\n",
      "Validation loss 2.950623220441446 NOT improved\n",
      "0.12210915818686402 0.07256651930936692 0.876294976556314 4.748815165876778\n",
      "Validation loss 3.1746303010640493 NOT improved\n",
      "0.12087912087912088 0.0734840270247727 0.8763339143029609 4.800947867298579\n",
      "Validation loss 3.2165824696630385 NOT improved\n",
      "0.11894273127753303 0.07707064809408624 0.8760959394452814 5.018957345971564\n",
      "Validation loss 3.3913773305217445 NOT improved\n",
      "0.11754537597234227 0.07890566352489782 0.8756243381077202 5.127962085308057\n",
      "Validation loss 3.478860593051977 NOT improved\n",
      "0.11610169491525424 0.08082408874801902 0.8753071041819931 5.241706161137441\n",
      "Validation loss 3.570144589926902 NOT improved\n",
      "0.11894273127753303 0.07707064809408624 0.8758899844604789 5.018957345971564\n",
      "INFO:tensorflow:Assets written to: /glade/work/ksha/NCAR/Keras_models/SMALL10_tornado_tune_backup/assets\n",
      "Validation loss 3.3913773305217445 NOT improved\n",
      "0.11821366024518389 0.07765451664025357 0.875738977158762 5.052132701421801\n",
      "Validation loss 3.418063429088404 NOT improved\n",
      "0.11724723874256585 0.08057385937109017 0.875407709831959 5.232227488151659\n",
      "Validation loss 3.562332542772814 NOT improved\n",
      "0.11795316565481354 0.07857202435565935 0.8753211375830688 5.109004739336493\n",
      "Validation loss 3.463613158338232 NOT improved\n",
      "0.11724723874256585 0.08057385937109017 0.8750052872320954 5.232227488151659\n",
      "Validation loss 3.562332542772814 NOT improved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== Training hyper parameters ========== #\n",
    "\n",
    "tol = 0\n",
    "min_del = 0\n",
    "max_tol = 500 # early stopping with patience\n",
    "\n",
    "epochs = 500\n",
    "L_train = 64\n",
    "batch_size = 100\n",
    "batch_size_half = 50\n",
    "\n",
    "valid_size = 1\n",
    "\n",
    "X_batch = np.empty((batch_size, 64, 64, L_vars))\n",
    "Y_batch = np.empty((batch_size, 1))\n",
    "X_batch[...] = np.nan\n",
    "Y_batch[...] = np.nan\n",
    "\n",
    "# ========== Training loop ========== #\n",
    "\n",
    "L_full = len(filename_train_full)\n",
    "L_aug = len(filename_train_aug)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i <= 10:\n",
    "        batch_size_full = 70\n",
    "    if i > 10 and i <= 35:\n",
    "        batch_size_full = 85\n",
    "    if i > 35:\n",
    "        batch_size_full = 95\n",
    "    \n",
    "    batch_size_aug = batch_size - batch_size_full\n",
    "    \n",
    "    #print('epoch = {}'.format(i))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # loop of batch\n",
    "    for j in range(L_train):\n",
    "        \n",
    "        ind_full = du.shuffle_ind(L_full)\n",
    "        ind_aug = du.shuffle_ind(L_aug)\n",
    "        \n",
    "        file_pick_full = []\n",
    "        for ind_temp in ind_full[:batch_size_full]:\n",
    "            file_pick_full.append(filename_train_full[ind_temp])\n",
    "\n",
    "        file_pick_aug = []\n",
    "        for ind_temp in ind_aug[:batch_size_aug]:\n",
    "            file_pick_aug.append(filename_train_aug[ind_temp])\n",
    "        \n",
    "        file_pick = file_pick_full + file_pick_aug\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            \n",
    "            data = np.load(file_pick[k])\n",
    "            \n",
    "            for c, v in enumerate(ind_pick_from_batch):\n",
    "                \n",
    "                X_batch[k, ..., c] = data[:, 32:-32, 32:-32, v]\n",
    "            \n",
    "            if 'pos' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.95, 0.99)\n",
    "            elif 'neg' in file_pick[k]:\n",
    "                Y_batch[k, :] = np.random.uniform(0.01, 0.05)\n",
    "            else:\n",
    "                werhgaer\n",
    "        \n",
    "        # # add noise within sparse inputs\n",
    "        # for v in flag_sparse:\n",
    "        #     X_batch[..., v] += np.random.uniform(0, 0.01, size=(batch_size, 128, 128))\n",
    "\n",
    "        # shuffle indices\n",
    "        ind_ = du.shuffle_ind(batch_size)\n",
    "        X_batch = X_batch[ind_, ...]\n",
    "        Y_batch = Y_batch[ind_, :]\n",
    "        \n",
    "        if np.sum(np.isnan(X_batch)) > 0:\n",
    "            asfeargagqarew\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([X_batch,], [Y_batch,]);\n",
    "    \n",
    "    # epoch end operations\n",
    "    Y_pred = model.predict([VALID_input,])\n",
    "    record_temp = verif_metric(VALID_target, Y_pred, thres=0.7)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        model.save(model_path_backup)\n",
    "    \n",
    "    if (record - record_temp > min_del) and (np.max(Y_pred) > 0.6):\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        tol = 0\n",
    "        #print('tol: {}'.format(tol))\n",
    "        # save\n",
    "        print('save to: {}'.format(model_path))\n",
    "        model.save(model_path)\n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        tol += 1\n",
    "        #print('tol: {}'.format(tol))\n",
    "        if tol >= max_tol:\n",
    "            print('Early stopping')\n",
    "            sys.exit();\n",
    "        else:\n",
    "            #print('Pass to the next epoch')\n",
    "            continue;\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949c295b-e524-46b5-804d-b1737d404f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2af93bfebbb0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdd747-e1f4-42a3-a018-f43d1ba30c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
