{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d2e8a2-1a31-424a-9872-fe32226ff756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442434e2-7e7c-467d-a910-14d00af6f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 16:16:27.569768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from keras_unet_collection import utils as k_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa8e225-8128-4d23-a025-dabf9e2847bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9409feb6-4200-4e27-8181-58b633e47378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f62fe63-7f86-45d5-ad5e-ec6a51cabf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0f6a6b-d51c-4dfa-8d83-c34243da2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(filenames, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max, lead_minmax):\n",
    "    \n",
    "    lon_out = []\n",
    "    lat_out = []\n",
    "    elev_out = []\n",
    "    lead_out = []\n",
    "    mon_out = []\n",
    "    \n",
    "    base_v3_s = datetime(2018, 7, 15)\n",
    "    base_v3_e = datetime(2020, 12, 2)\n",
    "\n",
    "    base_v4_s = datetime(2020, 12, 3)\n",
    "    base_v4_e = datetime(2022, 7, 15)\n",
    "\n",
    "    base_ref = datetime(2010, 1, 1)\n",
    "    \n",
    "    date_list_v3 = [base_v3_s + timedelta(days=day) for day in range(365+365+142)]\n",
    "    date_list_v4 = [base_v4_s + timedelta(days=day) for day in range(365+180-151)]\n",
    "    \n",
    "    for i, name in enumerate(filenames):\n",
    "        \n",
    "        if 'v4' in name:\n",
    "            date_list = date_list_v4\n",
    "        else:\n",
    "            date_list = date_list_v3\n",
    "        \n",
    "        nums = re.findall(r'\\d+', name)\n",
    "        lead = int(nums[-1])\n",
    "        indy = int(nums[-2])\n",
    "        indx = int(nums[-3])\n",
    "        day = int(nums[-4])\n",
    "        day = date_list[day]\n",
    "        month = day.month\n",
    "        \n",
    "        month_norm = (month - 1)/(12-1)\n",
    "        \n",
    "        lon = lon_80km[indx, indy]\n",
    "        lat = lat_80km[indx, indy]\n",
    "\n",
    "        lon = (lon - lon_minmax[0])/(lon_minmax[1] - lon_minmax[0])\n",
    "        lat = (lat - lat_minmax[0])/(lat_minmax[1] - lat_minmax[0])\n",
    "\n",
    "        elev = elev_80km[indx, indy]\n",
    "        elev = elev / elev_max\n",
    "\n",
    "        lead = (lead - lead_minmax[0])/(lead_minmax[1] - lead_minmax[0])\n",
    "                \n",
    "        lon_out.append(lon)\n",
    "        lat_out.append(lat)\n",
    "        elev_out.append(elev)\n",
    "        lead_out.append(lead)\n",
    "        mon_out.append(month_norm)\n",
    "        \n",
    "    return np.array(lon_out), np.array(lat_out), np.array(elev_out), np.array(lead_out), np.array(mon_out)\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    \n",
    "    IN_vec = keras.Input((128,))\n",
    "    \n",
    "    IN_elev = keras.Input((4,))\n",
    "    \n",
    "    X_elev = IN_elev\n",
    "    \n",
    "    # X_elev = keras.layers.Dense(32, activity_regularizer=keras.regularizers.L2(1e-2))(X_elev)\n",
    "    # X_elev = keras.layers.BatchNormalization()(X_elev)\n",
    "    # X_elev = keras.layers.Activation(\"gelu\")(X_elev)\n",
    "    \n",
    "    IN = keras.layers.Concatenate()([X_elev, IN_vec])\n",
    "    \n",
    "    X = IN\n",
    "    #\n",
    "    X = keras.layers.Dense(1024, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "\n",
    "    X = keras.layers.Dropout(0.33)(X)\n",
    "\n",
    "    X = keras.layers.Dense(512, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "\n",
    "    X = keras.layers.Dropout(0.33)(X)\n",
    "    #X = keras.layers.GaussianDropout(0.1)(X)\n",
    "\n",
    "    X = keras.layers.Dense(256, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "\n",
    "    X = keras.layers.Dropout(0.33)(X)\n",
    "\n",
    "    X = keras.layers.Dense(128, activity_regularizer=keras.regularizers.L2(1e-2))(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    X = keras.layers.Activation(\"gelu\")(X)\n",
    "\n",
    "    OUT = X\n",
    "    OUT = keras.layers.Dense(1, activation='sigmoid', bias_initializer=keras.initializers.Constant(-10))(OUT)\n",
    "\n",
    "    model = keras.models.Model(inputs=[IN_elev, IN_vec], outputs=OUT)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcea3d9e-ac56-49de-84c4-842b5aba85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]\n",
    "    elev_3km = h5io['elev_3km'][...]\n",
    "    land_mask_80km = h5io['land_mask_80km'][...]\n",
    "    \n",
    "grid_shape = land_mask_80km.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac02622-6bd8-4481-88b8-46e0ee655b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "elev_80km = du.interp2d_wraper(lon_3km, lat_3km, elev_3km, lon_80km, lat_80km, method='linear')\n",
    "\n",
    "elev_80km[np.isnan(elev_80km)] = 0\n",
    "elev_80km[elev_80km<0] = 0\n",
    "elev_max = np.max(elev_80km)\n",
    "\n",
    "lon_80km_mask = lon_80km[land_mask_80km]\n",
    "lat_80km_mask = lat_80km[land_mask_80km]\n",
    "\n",
    "lon_minmax = [np.min(lon_80km_mask), np.max(lon_80km_mask)]\n",
    "lat_minmax = [np.min(lat_80km_mask), np.max(lat_80km_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccc18f6-c4fd-490a-8070-665f448ca0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = \"/glade/scratch/ksha/DATA/NCAR_batch/\"\n",
    "filepath_valid = \"/glade/campaign/cisl/aiml/ksha/NCAR_batch/\"\n",
    "filepath_test = \"/glade/campaign/cisl/aiml/ksha/NCAR_batch_v4/\"\n",
    "filepath_vec = \"/glade/work/ksha/NCAR/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "594a9fd0-dbae-403c-b461-016ee53f48ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process lead2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 16:17:00.648395: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-23 16:17:00.649887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-23 16:17:00.705135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-23 16:17:00.705176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-23 16:17:00.707751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-23 16:17:00.707814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-23 16:17:00.709922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-23 16:17:00.710747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-23 16:17:00.713033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-23 16:17:00.713914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-23 16:17:00.718128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-23 16:17:00.718740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-23 16:17:00.719287: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 16:17:00.719458: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-23 16:17:00.719859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-23 16:17:00.719888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-23 16:17:00.719912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-23 16:17:00.719923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-23 16:17:00.719932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-23 16:17:00.719941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-23 16:17:00.719951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-23 16:17:00.719960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-23 16:17:00.719969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-23 16:17:00.720461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-23 16:17:00.720488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-23 16:17:01.277706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-23 16:17:01.277746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-11-23 16:17:01.277762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-11-23 16:17:01.278765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n",
      "2022-11-23 16:17:02.586428: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-23 16:17:02.586914: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2022-11-23 16:17:02.728176: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "for lead in range(2, 3, 1):\n",
    "    print('Process lead{}'.format(lead))\n",
    "    filename_valid = sorted(glob(\"{}VALID*neg_neg_neg*lead{}.npy\".format(filepath_valid, lead))) + \\\n",
    "                     sorted(glob(\"{}VALID*pos*lead{}.npy\".format(filepath_valid, lead)))\n",
    "\n",
    "    lon_valid, lat_valid, elev_valid, lead_valid, mon_valid = feature_extract(\n",
    "        filename_valid, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max, [lead, lead+2])\n",
    "\n",
    "    VALID_stn = np.concatenate((lon_valid[:, None], \n",
    "                                lat_valid[:, None], \n",
    "                                elev_valid[:, None], \n",
    "                                lead_valid[:, None]), axis=1)\n",
    "\n",
    "    VALID_merge = VALID_stn\n",
    "\n",
    "    data_p_valid = np.load('{}TEST_pp15_pred_lead{}_vec2.npy'.format(filepath_vec, lead), allow_pickle=True)[()]\n",
    "\n",
    "    VALID_256 = data_p_valid['y_vector']\n",
    "    VALID_pred = data_p_valid['y_pred']\n",
    "    VALID_Y = data_p_valid['y_true']\n",
    "\n",
    "    filename_neg_test = sorted(glob(\"{}*neg_neg_neg*lead{}.npy\".format(filepath_test, lead)))\n",
    "    filename_pos_test = sorted(glob(\"{}*pos*lead{}.npy\".format(filepath_test, lead)))\n",
    "\n",
    "    filename_test = filename_neg_test + filename_pos_test\n",
    "\n",
    "    lon_test, lat_test, elev_test, lead_test, mon_test = feature_extract(\n",
    "        filename_test, lon_80km, lon_minmax, lat_80km, lat_minmax, elev_80km, elev_max, [lead, lead+2])\n",
    "\n",
    "    data_p_test = np.load(\"{}TEST_pp15_pred_lead{}_v4_vec2.npy\".format(filepath_vec, lead), allow_pickle=True)[()]\n",
    "\n",
    "    TEST_256 = data_p_test['y_vector']\n",
    "    TEST_pred = data_p_test['y_pred']\n",
    "    TEST_Y = data_p_test['y_true']\n",
    "\n",
    "    TEST_stn = np.concatenate((lon_test[:, None], \n",
    "                               lat_test[:, None], \n",
    "                               elev_test[:, None], \n",
    "                               lead_test[:, None]), axis=1)\n",
    "\n",
    "    TEST_merge = TEST_stn\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=keras.optimizers.Adam(lr=0))\n",
    "\n",
    "    W_old = k_utils.dummy_loader('/glade/work/ksha/NCAR/Keras_models/VALID_Lead{}/'.format(lead))\n",
    "    model.set_weights(W_old)\n",
    "\n",
    "    Y_pred_test = model.predict([TEST_merge, TEST_256])\n",
    "    Y_pred_valid = model.predict([VALID_merge, VALID_256])\n",
    "\n",
    "    save_dict = {}\n",
    "    save_dict['test'] = Y_pred_test\n",
    "    save_dict['valid'] = Y_pred_valid\n",
    "    save_dict['label_test'] = TEST_Y\n",
    "    save_dict['label_valid'] = VALID_Y\n",
    "\n",
    "    np.save('{}RESULT2_pp15_lead{}.npy'.format(filepath_vec, lead), save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e25b095-524b-4407-a8af-0d3e2e848b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94ef11-33cc-4f87-9fa4-8168e9ec1d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b869dd-df2e-4fe1-9b0c-ee3a01eeb7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab0646f5-a6f9-4d65-8f36-5c66e4f3ceac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed265c2-e057-4f0f-909a-6264dc2df8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894508fd-eda0-4313-947a-0cf6f7c5eab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
