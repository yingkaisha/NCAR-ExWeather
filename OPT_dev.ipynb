{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad6be17-5321-4f5c-886b-8ab9f95a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import zarr\n",
    "import pygrib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "508fdfde-0ead-4f0c-8d9d-d800c64b1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04116631-40e1-4b7c-85ad-ca09121d08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0c80fd9-29c1-4531-a7f6-6008ba761da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 09:26:57.109640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# deep learning tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be3435db-736e-44db-b395-a05a34dac8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerScale(layers.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "    References:\n",
    "      - https://arxiv.org/abs/2103.17239\n",
    "    Args:\n",
    "      init_values (float): Initial value for layer scale. Should be within\n",
    "        [0, 1].\n",
    "      projection_dim (int): Projection dimensionality.\n",
    "    Returns:\n",
    "      Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = tf.Variable(\n",
    "            self.init_values * tf.ones((self.projection_dim,))\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "    \n",
    "def create_model(input_shape=(64, 64, 15)):\n",
    "\n",
    "    depths=[3, 3, 27, 3]\n",
    "    projection_dims=[32, 64, 96, 128]\n",
    "    drop_path_rate=0.0\n",
    "    layer_scale_init_value=1e-6\n",
    "\n",
    "\n",
    "    model_name='Branch64X'\n",
    "    IN64 = layers.Input(shape=input_shape)\n",
    "    X = IN64\n",
    "    # ----- convnext block 0 ----- #\n",
    "\n",
    "    X = layers.Conv2D(projection_dims[0], kernel_size=4, strides=4, name=\"{}_down0\".format(model_name))(X)\n",
    "    X = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down0_norm\".format(model_name))(X)\n",
    "\n",
    "    for j in range(depths[0]):\n",
    "\n",
    "        X_convnext = X\n",
    "        X_convnext = layers.Conv2D(filters=projection_dims[0], kernel_size=7, padding=\"same\",\n",
    "                                   groups=projection_dims[0], name=\"{}_down0_dconv{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down0_dconv{}_norm\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(4 * projection_dims[0], name=\"{}_down0_dense{}_p1\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Activation(\"gelu\", name=\"{}_down0_gelu{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(projection_dims[0], name=\"{}_down0_dense{}_p2\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X_convnext = LayerScale(layer_scale_init_value, projection_dims[0], name=\"{}_down0_layerscale{}\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X = X + X_convnext\n",
    "\n",
    "\n",
    "    # ----- convnext block 1 ----- #\n",
    "\n",
    "    X = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down1_norm\".format(model_name))(X)\n",
    "    X = layers.Conv2D(projection_dims[1], kernel_size=2, strides=2, name=\"{}_down1\".format(model_name))(X)\n",
    "\n",
    "    for j in range(depths[1]):\n",
    "\n",
    "        X_convnext = X\n",
    "        X_convnext = layers.Conv2D(filters=projection_dims[1], kernel_size=7, padding=\"same\",\n",
    "                                   groups=projection_dims[1], name=\"{}_down1_dconv{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down1_dconv{}_norm\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(4 * projection_dims[1], name=\"{}_down1_dense{}_p1\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Activation(\"gelu\", name=\"{}_down1_gelu{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(projection_dims[1], name=\"{}_down1_dense{}_p2\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X_convnext = LayerScale(layer_scale_init_value, projection_dims[1], name=\"{}_down1_layerscale{}\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X = X + X_convnext\n",
    "\n",
    "    # ----- convnext block 2 ----- #\n",
    "\n",
    "    X = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down2_norm\".format(model_name))(X)\n",
    "    X = layers.Conv2D(projection_dims[2], kernel_size=2, strides=2, name=\"{}_down2\".format(model_name))(X)\n",
    "\n",
    "    for j in range(depths[2]):\n",
    "\n",
    "        X_convnext = X\n",
    "        X_convnext = layers.Conv2D(filters=projection_dims[2], kernel_size=5, padding=\"same\",\n",
    "                                   groups=projection_dims[2], name=\"{}_down2_dconv{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down2_dconv{}_norm\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(4 * projection_dims[2], name=\"{}_down2_dense{}_p1\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Activation(\"gelu\", name=\"{}_down2_gelu{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(projection_dims[2], name=\"{}_down2_dense{}_p2\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X_convnext = LayerScale(layer_scale_init_value, projection_dims[2], name=\"{}_down2_layerscale{}\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X = X + X_convnext\n",
    "\n",
    "    # ----- convnext block 3 ----- #\n",
    "\n",
    "    X = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down3_norm\".format(model_name))(X)\n",
    "    X = layers.Conv2D(projection_dims[3], kernel_size=2, padding='same', name=\"{}_down3\".format(model_name))(X)\n",
    "\n",
    "    for j in range(depths[3]):\n",
    "\n",
    "        X_convnext = X\n",
    "        X_convnext = layers.Conv2D(filters=projection_dims[3], kernel_size=5, padding=\"same\",\n",
    "                                   groups=projection_dims[3], name=\"{}_down3_dconv{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.LayerNormalization(epsilon=1e-6, name=\"{}_down3_dconv{}_norm\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(4 * projection_dims[3], name=\"{}_down3_dense{}_p1\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Activation(\"gelu\", name=\"{}_down3_gelu{}\".format(model_name, j))(X_convnext)\n",
    "        X_convnext = layers.Dense(projection_dims[3], name=\"{}_down3_dense{}_p2\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X_convnext = LayerScale(layer_scale_init_value, projection_dims[3], name=\"{}_down3_layerscale{}\".format(model_name, j))(X_convnext)\n",
    "\n",
    "        X = X + X_convnext\n",
    "\n",
    "    V1 = X\n",
    "\n",
    "    OUT1 = layers.GlobalMaxPooling2D(name=\"{}_head_pool64\".format(model_name))(V1)\n",
    "    model = Model(inputs=IN64, outputs=OUT1, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91ebe3-b16d-4d5a-accb-001e4e55b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_temp = datetime(2021, 1, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93e385a4-9dfa-44e0-8b71-259c76c99e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRRv4_STATS.hdf', 'r') as h5io:\n",
    "    mean_stats = h5io['mean_stats'][...]\n",
    "    std_stats = h5io['std_stats'][...]\n",
    "    max_stats = h5io['max_stats'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ece2fe6f-dd0e-4c8a-9bac-9b02fc7eaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7f4f11-88f8-45c9-90f8-1c6cc7f023a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEADs = [[2, 3, 4], [3, 4, 5], [4, 5, 6], \n",
    "         [5, 6, 7], [6, 7, 8], [7, 8, 9], \n",
    "         [8, 9, 10], [9, 10, 11], [10, 11, 12], \n",
    "         [11, 12, 13], [12, 13, 14], [13, 14, 15], \n",
    "         [14, 15, 16], [15, 16, 17], [16, 17, 18], \n",
    "         [17, 18, 19], [18, 19, 20], [19, 20, 21], \n",
    "         [20, 21, 22], [21, 22, 23], [22, 23, 24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b927e69-e393-4d51-b426-674c6b2f0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRRR_dir = '/glade/campaign/cisl/aiml/ksha/HRRR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f3e8146-61ba-498d-804c-d82e22e99c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/glade/work/ksha/NCAR/Keras_models/RE2_peak_base5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1ce4214-0595-47ec-a1a5-24fd541ef92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = 64\n",
    "\n",
    "log_norm = [True, False, True, True, True, False, False, True, True, True, True, False, False, False, False]\n",
    "HRRRv4_inds = [1003, 1014, 1018, 1020, 1028, 1041, 1044, 1049, 1060, 1074, 1075, 1097, 1098, 1103, 1104]\n",
    "var_names = ['1003:Maximum/Composite radar reflec',\n",
    "             '1014:MSLP (MAPS System Reduction):P',\n",
    "             '1018:199:199 (max):lambert:heightAb',\n",
    "             '1020:199:199 (max):lambert:heightAb',\n",
    "             '1028:74:74 (max):lambert:atmosphere',\n",
    "             '1041:2 metre temperature:K (instant',\n",
    "             '1044:2 metre dewpoint temperature:K',\n",
    "             '1049:10 metre wind speed:m s**-1 (m',\n",
    "             '1060:Total Precipitation:kg m**-2 (',\n",
    "             '1074:Convective available potential',\n",
    "             '1075:Convective inhibition:J kg**-1',\n",
    "             '1097:Storm relative helicity:J kg**',\n",
    "             '1098:Storm relative helicity:J kg**',\n",
    "             '1103:Vertical u-component shear:s**',\n",
    "             '1104:Vertical v-component shear:s**']\n",
    "\n",
    "N_var = len(var_names)\n",
    "half_margin = int(0.5*input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30af56-e238-453a-8664-5d8bdb94905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_80km = lon_80km.shape\n",
    "shape_3km = lon_3km.shape\n",
    "\n",
    "indx_array = np.empty(shape_80km)\n",
    "indy_array = np.empty(shape_80km)\n",
    "\n",
    "gridTree = cKDTree(list(zip(lon_3km.ravel(), lat_3km.ravel()))) #KDTree_wraper(xgrid, ygrid)\n",
    "\n",
    "for xi in range(shape_80km[0]):\n",
    "    for yi in range(shape_80km[1]):\n",
    "        \n",
    "        temp_lon = lon_80km[xi, yi]\n",
    "        temp_lat = lat_80km[xi, yi]\n",
    "        \n",
    "        dist, indexes = gridTree.query(list(zip(np.array(temp_lon)[None], np.array(temp_lat)[None])))\n",
    "        indx_3km, indy_3km = np.unravel_index(indexes, shape_3km)\n",
    "        \n",
    "        indx_array[xi, yi] = indx_3km[0]\n",
    "        indy_array[xi, yi] = indy_3km[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858340a-9e56-4240-b688-5be4962f327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crerate model\n",
    "model = create_model(input_shape=(64, 64, 15))\n",
    "\n",
    "# get current weights\n",
    "W_new = model.get_weights()\n",
    "\n",
    "# get stored weights\n",
    "W_old = k_utils.dummy_loader(model_name)\n",
    "\n",
    "# update stored weights to new weights\n",
    "for i in range(len(W_new)):\n",
    "    if W_new[i].shape == W_old[i].shape:\n",
    "        W_new[i] = W_old[i]\n",
    "\n",
    "# dump new weights to the model\n",
    "model.set_weights(W_new)\n",
    "\n",
    "# compile just in case\n",
    "model.compile(loss=keras.losses.mean_absolute_error, optimizer=keras.optimizers.SGD(lr=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3437d3-0823-4fc0-88ef-f2d8f6ea251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32a48992-17cb-40ad-bfde-cf5b3802e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARs = np.empty((1059, 1799, 15))\n",
    "VARs[...] = np.nan\n",
    "\n",
    "FEATURE_VEC = np.empty((65, 93, 21, 128))\n",
    "FEATURE_VEC[...] = np.nan\n",
    "\n",
    "input_frame = np.empty((1, 64, 64, 15))\n",
    "input_frame[...] = np.nan\n",
    "\n",
    "for l in range(2):\n",
    "    \n",
    "    leads = LEADs[l]\n",
    "    lead = leads[0]\n",
    "\n",
    "    filename_grib = (datetime.strftime(date_temp, HRRR_dir+'fcst{:02d}hr/HRRR.%Y%m%d.natf{:02d}.grib2')).format(lead, lead)\n",
    "\n",
    "    var_names_temp = []\n",
    "    with pygrib.open(filename_grib) as grbio:\n",
    "        for i, ind in enumerate(HRRRv4_inds):\n",
    "            var_names_temp.append(str(grbio[ind])[:35])\n",
    "\n",
    "    flag_qc = var_names == var_names_temp\n",
    "    \n",
    "    with pygrib.open(filename_grib) as grbio:\n",
    "        for i, ind in enumerate(HRRRv4_inds):\n",
    "            VARs[..., i] = grbio[ind].values\n",
    "        \n",
    "    for ix in range(shape_80km[0]):\n",
    "        for iy in range(shape_80km[1]):\n",
    "\n",
    "            indx = int(indx_array[ix, iy])\n",
    "            indy = int(indy_array[ix, iy])\n",
    "\n",
    "            x_edge_left = indx - half_margin\n",
    "            x_edge_right = indx + half_margin\n",
    "\n",
    "            y_edge_bottom = indy - half_margin\n",
    "            y_edge_top = indy + half_margin\n",
    "\n",
    "            if x_edge_left >= 0 and y_edge_bottom >= 0 and x_edge_right < shape_3km[0] and y_edge_top < shape_3km[1]:\n",
    "\n",
    "                hrrr_temp = VARs[x_edge_left:x_edge_right, y_edge_bottom:y_edge_top, :]\n",
    "\n",
    "                for n in range(N_var):\n",
    "\n",
    "                    means = mean_stats[ix, iy, n, l]\n",
    "                    stds = std_stats[ix, iy, n, l]\n",
    "                    max_vals = max_stats[ix, iy, n, l]\n",
    "\n",
    "                    temp = hrrr_temp[..., n]\n",
    "\n",
    "                    # (n==0) Radar reflectivity, correct negative to 0\n",
    "                    if n == 0:\n",
    "                        temp[temp<0] = 0\n",
    "\n",
    "                    # (n==10) CIN, preserve negative vals only, and convert them to positive \n",
    "                    if n == 10:\n",
    "                        temp = -1*temp\n",
    "                        temp[temp<0] = 0\n",
    "\n",
    "                    # variables that will be normalizaed with log transformation\n",
    "                    if log_norm[n]:\n",
    "                        temp = np.log(np.abs(temp)+1)\n",
    "                        # for CIN and SRH, x3 the value\n",
    "                        if n < 9:\n",
    "                            temp = temp/stds/max_vals\n",
    "                        else:\n",
    "                            temp = 3.0*temp/stds/max_vals\n",
    "\n",
    "                    else:\n",
    "                        temp = (temp - means)/stds\n",
    "\n",
    "                    input_frame[..., n] = temp\n",
    "\n",
    "                # CNN feature vectors\n",
    "\n",
    "                temp_vec = model.predict([input_frame])\n",
    "                FEATURE_VEC[ix, iy, l, :] = temp_vec[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a52c41a-bd42-43b1-b9a6-0e0ca5b7d913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/work/ksha/NCAR/'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eef05be3-70b4-4d14-95b3-3c11fb8c2fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ac9bb-6964-4387-8b8b-80d7c8c90f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e794676-fc2a-4b53-be17-bd838096f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adeb9e-34c9-4b9d-9ae1-af42828df792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a4f1719-7f9a-4aef-9602-85701af94294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe6eea-b89d-4910-a4b3-0d8a487cd2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40316fd5-f966-4ed0-a0ef-e2dba6efccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806c740-d60a-47cb-961e-333976291ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
